---
title: exemplar_baseline
date: last-modified
toc-depth: 4
code-fold: true
code-tools: true
lightbox: true
execute: 
  warning: false
  eval: false
---


```{r}

pacman::p_load(dplyr, purrr, tidyr, ggplot2, here, patchwork, conflicted, knitr, grateful)
conflict_prefer_all("dplyr", quiet = TRUE)

```


```{r}

# Distance function using Euclidean distance
dist.euclidean <- function(e, p) {
  sqrt(sum((e - p)^2))
}

# Similarity function using exponential decay
similarity <- function(e, p, c) {
  exp(-c * dist.euclidean(e, p))
}

# Generating Prototypes
generate_prototypes <- function(num_categories, num_dimensions, between) {
  matrix(runif(num_categories * num_dimensions, min = 0, max = between), 
         nrow = num_categories, ncol = num_dimensions)
}

generate_distorted_patterns <- function(prototype, num_samples, distortion_level, within) {
  num_dimensions <- length(prototype)
  t(sapply(1:num_samples, function(x) {
    noise <- rnorm(num_dimensions) * within * distortion_level
    prototype + noise
  }))
}

# Categorization Probability Function
categorization_probability <- function(test_pattern, training_patterns, gamma, c) {
  # Calculate the summed similarities for each category
  summed_similarities <- apply(training_patterns, 3,function(category_patterns) {
    sum(sapply(1:nrow(category_patterns), function(i) {
      similarity(test_pattern, category_patterns[i, ], c)
    }))
  })
  
  # Raise the summed similarities to the power of gamma
  numerator <- summed_similarities^gamma
  denominator <- sum(summed_similarities^gamma)
  
  # Return the probability of the test_pattern being in category A
  probs <- numerator / denominator
  return (probs)
}


# Simulation Function
simulate <- function(num_categories, num_samples, training_distortion_level, within, c, gamma) {
  prototypes <- generate_prototypes(num_categories, num_dimensions=6, between=2)
  training_patterns <- array(dim = c(num_samples, ncol(prototypes), num_categories))
  
  for (cat in 1:num_categories) {
    training_patterns[,,cat] <- generate_distorted_patterns(prototypes[cat,], num_samples, training_distortion_level, within)
  }
  
  # Assess Testing Performance Here
  test_performance <- list()
  categories <- seq_len(num_categories)
  types_of_patterns <- c("old", "prototype", "new_low", "new_medium", "new_high")
  #distortion_levels_test <- c(1.20, 2.80, 4.60) # low, medium, high distortion levels
  distortion_levels_test <- c(4, 6, 7.7)
  
  for (type in types_of_patterns) {
    for (cat in categories) {
      if (type == "old") {
        test_patterns <- training_patterns[sample(1:num_samples, 27),,cat]
        #colMeans(test_patterns)
      } else if (type == "prototype") {
        test_patterns <- matrix(prototypes[cat,], nrow = 1, ncol = ncol(prototypes), byrow = TRUE)
      } else {
        distortion_level <- switch(type,
                                   "new_low" = distortion_levels_test[1],
                                   "new_medium" = distortion_levels_test[2],
                                   "new_high" = distortion_levels_test[3])
        test_patterns <- generate_distorted_patterns(prototypes[cat,], 27, distortion_level, within)
      }
      # Calculate categorization probabilities for the test patterns
      probs <- apply(test_patterns, 1, categorization_probability, training_patterns = training_patterns, gamma = gamma, c = c)
      # Count correct classifications
      correct_classifications <- sum(apply(probs, 2, which.max) == cat)
      test_performance[[paste(type, "cat", cat, sep = "_")]] <- correct_classifications / nrow(test_patterns)
    }
  }
  
  # Combine results into a single data frame
  test_performance_df <- data.frame(
    type = rep(types_of_patterns, each = num_categories),
    category = rep(categories, times = length(types_of_patterns)),
    correct_classifications = unlist(test_performance)
  )
  
  return(test_performance_df)
}




```



```{r}
#| fig-width: 11
#| fig-height: 6

# Simulation Parameters
num_categories <- 3
num_dimensions <- 6
num_samples <- 90 # number of samples per category
between <- 2
within <- 0.210
gamma <- 5.0
c <- 0.475
distortion_levels <- c(4, 6, 7.7) # low, medium, high distortion levels
nsim <- 1000



# List to store performance results from each distortion level
performance_results <- list()

# Simulate for each distortion level
for (distortion_level in distortion_levels) {
  results <- replicate(nsim, simulate(num_categories, num_samples, distortion_level, within, c, gamma), simplify = FALSE)
  performance_results[[as.character(distortion_level)]] <- do.call(rbind, results)
}

# Combining results
combined_results <- bind_rows(
  lapply(names(performance_results), function(name) {
    transform(performance_results[[name]], distortion_level = as.numeric(name))
  }),
  .id = "distortion_level"
) |> mutate(Pattern_Token = factor(type,levels=c("old","prototype","new_low","new_medium","new_high")))




# Visualizing the results
ggplot(combined_results, aes(x = Pattern_Token, y = correct_classifications, fill = factor(distortion_level))) +
  stat_summary(geom="bar",fun=mean, position=position_dodge())+
  stat_summary(geom="errorbar", fun.data=mean_se, position=position_dodge()) +
  labs(x = "Pattern Type", y = "Correct Classifications (%)", fill = "Training Distortion Level") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1") +ggtitle(paste0("nsim: ",nsim,"; gamma: ",gamma,"; c: ",c,"; within: ",within,"; between: ",between,"; num_samples: ",num_samples))
```

