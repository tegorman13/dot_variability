[
  {
    "objectID": "read_22.html",
    "href": "read_22.html",
    "title": "Process 2022 data",
    "section": "",
    "text": "# packages &lt;- c('plyr','dplyr','tidyr','ggplot2','magrittr',\n#              'psych','data.table','grid','gridExtra','R.matlab','units','readr')\n# have = packages %in% rownames(installed.packages())\n# if ( any(!have) ) { install.packages(packages[!have]) }\n# (lapply(packages, require, character.only = TRUE))\n\n\n# Data variable order, from left to right:\n#   \n# 1. Phase type (1 = Training, 2 = Transfer)\n# 2. Block number (1-15 training, 1 transfer)\n# 3. Trial number (1-15 training, 1-63 transfer)\n# 4. Pattern type (1 = old medium, 2 = prototype, 3 = new low, 4 = new medium, 5 = new high)\n# 5. Category number (1-3)\n# 6. Pattern token* \n#   7. Category response (1-3)\n# 8. Correct/Incorrect (0 = Incorrect, 1 = Correct)\n# 9. Reaction time (in milliseconds)\n# 10-27.Coordinates of nine dots* (-25 through 24)\n# \n# *Pattern token: index of unique tokens for each category of each type of pattern. The numbering of old medium patterns differs for the two conditions.\n# *Coordinates of nine dots: every two columns represent the x and y coordinates of a dot on a 50 x 50 grid\n# \n# file names starting with \"polyrep\" contain data from repeating condtion.\n# file names starting with \"polynrep\" contain data from non-repeating condtion.\n\n\n#rm(list=ls())\n\npacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table,readr,here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\ncol.names = c(\"Phase\",\"Block\",\"BlockTrial\",\"Pattern\",\"Category\",\"Pattern.Token\",\"Response\",\"Corr\",\"rt\",\n              \"x1\",\"y1\",\"x2\",\"y2\",\"x3\",\"y3\",\"x4\",\"y4\",\"x5\",\"y5\",\"x6\",\"y6\",\"x7\",\"y7\",\"x8\",\"y8\",\"x9\",\"y9\")\n\npathLoad=\"data/lmc_2022/Exp2_Classification\"\nloadPattern=\"*.txt\"\npathString=paste(pathLoad,\"/Data/\",sep=\"\")\nmFiles &lt;- list.files(path=pathString,pattern = loadPattern, recursive = FALSE) # should be 89 in exp 2\nnFiles=length(mFiles)\n\ndCat &lt;- data.frame(matrix(ncol=27,nrow=0)) %&gt;% purrr::set_names(col.names)\n\nfor (i in 1:nFiles){\n  ps=paste(pathString,mFiles[i],sep=\"\")\n  sbj = readr::parse_number(mFiles[i])\n  ind1=regexpr(\"y\",mFiles[i])\n  ind2=regexpr(sbj,mFiles[i])\n  d.load=read.table(ps) %&gt;% set_names(col.names) %&gt;% mutate(file=mFiles[i],condit=substr(file,ind1+1,ind2-1),sbjCode=as.factor(sbj))\n  dCat=rbind(dCat,d.load)\n}\n\n\ndCat &lt;- dCat %&gt;% group_by(sbjCode,condit,file) %&gt;% mutate(ind=1,trial=cumsum(ind),id=paste0(sbjCode,\".\",condit))  %&gt;%\n  group_by(sbjCode,condit,Phase) %&gt;%\n  mutate(nPhase=n(),phaseAvg=sum(Corr)/nPhase,\n         Pattern.Type=recode_factor(Pattern,`1` = 'Trained.Med', `2` = 'Prototype',  `3` = 'New.Low', `4` = 'New.Med',`5` = 'New.High'),\n         Stage=car::recode(trial, \"1:75='Start'; 76:150='Med'; 151:225='End';226:288='Test';else='Junk'\"),\n         Phase2=car::recode(trial, \"1:225='Training'; 226:288='Transfer';else='Junk'\"),\n         id=as.factor(id),condit=as.factor(condit)) %&gt;% \n  relocate(id,condit,.before=Phase) %&gt;%\n  relocate(id,trial,Phase,Phase2,Stage,Block,BlockTrial,Pattern.Type,Category,Corr,rt,phaseAvg,Pattern,Pattern.Token,Response,.after=\"condit\") %&gt;%\n  arrange(condit,sbj) %&gt;% \n  as.data.frame()\n\nWarning: There were 356 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `Stage = car::recode(trial, \"1:75='Start'; 76:150='Med';\n  151:225='End';226:288='Test';else='Junk'\")`.\nℹ In group 1: `sbjCode = 1`, `condit = \"nrep\"`, `Phase = 1`.\nCaused by warning in `car::recode()`:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 355 remaining warnings.\n\ndCat &lt;- dCat %&gt;% group_by(sbjCode,Pattern.Type) %&gt;% \n  mutate(patN=cumsum(ind)) %&gt;%\n  group_by(sbjCode,Pattern.Type,Category) %&gt;% \n  mutate(patCatN=cumsum(ind),typeCount=paste0(Pattern.Type,\".\",patCatN)) %&gt;% \n  relocate(typeCount,.after=\"Pattern.Type\") \n\ndCat$Block = ifelse(dCat$Phase==2,16,dCat$Block)\ndCat$Stage = factor(dCat$Stage,levels=c(\"Start\",\"Med\",\"End\",\"Test\")) \n\n\ndCat$Pattern.Type = factor(dCat$Pattern.Type,levels=c(\"Trained.Med\",\"Prototype\",\"New.Low\",\"New.Med\",\"New.High\")) \ndCat$Pattern.Type2 &lt;- ifelse(dCat$Phase==1,\"Training\",dCat$Pattern.Type)\ndCat$Pattern.Type2=recode_factor(dCat$Pattern.Type2,\"Training\"=\"End.Training\",`1` = 'Trained.Med', `2` = 'Prototype',  `3` = 'New.Low', `4` = 'New.Med',`5` = 'New.High')\ndCat$Pattern.Type2 = factor(dCat$Pattern.Type2,levels=c(\"End.Training\",\"Trained.Med\",\"Prototype\",\"New.Low\",\"New.Med\",\"New.High\")) \ndCat$Condition = factor(dCat$condit,levels=c(\"rep\",\"nrep\"))\ndCat$Phase2 = factor(dCat$Phase2,levels=c(\"Training\",\"Transfer\"))\n\n\ndCatTrain &lt;- dCat %&gt;% filter(Phase==1)%&gt;% relocate(sbjCode,condit,file) %&gt;% group_by(id) %&gt;%\n   relocate(trial,phaseAvg,.after=\"condit\") %&gt;% arrange(condit,sbj) %&gt;% mutate(Category=as.factor(Category))\n\n\ndCatTrainAvg=dCatTrain  %&gt;% group_by(id,condit,Condition,Block) %&gt;% \n  summarise(nCorr=sum(Corr),propCor=nCorr/15,rtMean=mean(rt),phaseAvg=mean(phaseAvg),nTrain=max(nPhase)) %&gt;% ungroup() %&gt;% group_by(condit) %&gt;%\n  mutate(grpRank=factor(rank(-phaseAvg)),id=factor(id)) %&gt;% arrange(-phaseAvg) %&gt;% as.data.frame()\n\n`summarise()` has grouped output by 'id', 'condit', 'Condition'. You can\noverride using the `.groups` argument.\n\ndCatTrainAvg$id &lt;-factor(dCatTrainAvg$id,levels=unique(dCatTrainAvg$id))\n\ndCatTrainAvg2=dCatTrain  %&gt;% group_by(id,condit,Condition,Category,Block) %&gt;% \n  summarise(nCorr=sum(Corr),propCor=nCorr/5,rtMean=mean(rt),phaseAvg=mean(phaseAvg),nTrain=max(nPhase)) %&gt;% ungroup() %&gt;% group_by(condit) %&gt;%\n  mutate(grpRank=factor(rank(-phaseAvg)),id=factor(id)) %&gt;% arrange(-phaseAvg) %&gt;% as.data.frame()\n\n`summarise()` has grouped output by 'id', 'condit', 'Condition', 'Category'.\nYou can override using the `.groups` argument.\n\ndCatTrainAvg2$id &lt;-factor(dCatTrainAvg2$id,levels=unique(dCatTrainAvg2$id))\n\n\ndCatAvg &lt;- dCat %&gt;% group_by(id,condit,Condition,Stage,Pattern.Type) %&gt;% \n  dplyr::summarise(nPatStage=n(),nCorr=sum(Corr),propCor=nCorr/nPatStage,rt=mean(rt)) %&gt;% ungroup() \n\n`summarise()` has grouped output by 'id', 'condit', 'Condition', 'Stage'. You\ncan override using the `.groups` argument.\n\ndCatAvg$id &lt;-factor(dCatAvg$id,levels=unique(dCatTrainAvg2$id))\n\n\n\ndCatAvg2 &lt;- dCat %&gt;% filter(trial&gt;=151) %&gt;% group_by(id,condit,Condition,Pattern.Type2,Category) %&gt;% \n  dplyr::summarise(nPatStage=n(),nCorr=sum(Corr),propCor=nCorr/nPatStage,rt=mean(rt)) %&gt;% ungroup() \n\n`summarise()` has grouped output by 'id', 'condit', 'Condition',\n'Pattern.Type2'. You can override using the `.groups` argument.\n\ndCatAvg2$id &lt;-factor(dCatAvg2$id,levels=unique(dCatTrainAvg2$id))\n\n\ndCatAvg3 &lt;- dCatAvg2 %&gt;% group_by(id,condit,Pattern.Type2) %&gt;% \n  dplyr::summarise(propCor=mean(propCor)) %&gt;% ungroup() \n\n`summarise()` has grouped output by 'id', 'condit'. You can override using the\n`.groups` argument.\n\nsbjTrainAvg &lt;- dCatTrainAvg %&gt;% filter(Block&gt;12) %&gt;% \n  group_by(id,condit,Condition) %&gt;% summarise(endTrain=mean(propCor)) %&gt;% ungroup() %&gt;% as.data.frame() %&gt;% group_by(condit,Condition) %&gt;% \n  mutate(conditRank=rank(-endTrain),cq=factor(ntile(endTrain,2))) \n\n`summarise()` has grouped output by 'id', 'condit'. You can override using the\n`.groups` argument.\n\nsbjTrainAvg$cq=recode_factor(sbjTrainAvg$cq,`1` = 'low-Performers', `2` = 'High-Performers')\n\n\n\ndCat &lt;- dCat |&gt; mutate(exp=\"lmc22\") |&gt; \n  relocate(id,sbjCode,exp,condit,Phase,Phase2,Stage,\n           trial,Block,BlockTrial,Pattern.Type,Pattern,Pattern.Token,\n           Category,Response,Corr,rt)\n\n#write out aggregated trial level data\n#write_rds(dCat, \"data/lmc22.rds\")\n\n# dCatBlockAvg &lt;- dCat %&gt;% group_by(id,condit,Block,Pattern.Type) %&gt;% \n#   summarise(nCorr=sum(Corr),propCor=nCorr/15,rtMean=mean(rt),phaseAvg=mean(phaseAvg)) %&gt;% ungroup() %&gt;% group_by(condit) %&gt;%\n#   mutate(grpRank=factor(rank(-phaseAvg)),id=factor(id)) %&gt;% arrange(-phaseAvg) %&gt;% as.data.frame()\n# dCatAvg$id &lt;-factor(dCatAvg$id,levels=unique(dCatAvg$id))\n\n\n# dCatAvg=dCatTrain  %&gt;% group_by(condit,Block) %&gt;%\n#   mutate(group.nCorr=sum(Corr),group.propCor=group.nCorr/15,grp.sd=sd(group.nCorr)) %&gt;% group_by(sbjCode,id,condit,Block) %&gt;% \n#   summarise(nCorr=sum(Corr),propCor=nCorr/15,rtMean=mean(rt),zProp=propCor-(group.propCor*grp.sd),group.nCorr=mean(group.nCorr),\n#             group.propCor=mean(group.propCor),grp.sd=mean(grp.sd))\n\n\n# \n# dCatAvg=dCatTrain %&gt;% group_by(sbjCode,id,condit,Block) %&gt;% \n#   summarise(nCorr=sum(Corr),propCor=nCorr/15,rtMean=mean(rt),trainAvg=mean(trainAvg)) %&gt;% ungroup() %&gt;% group_by(sbjCode,id,condit) %&gt;%\n#   mutate(sbjAvg=mean(propCor)) %&gt;% group_by(condit) %&gt;% mutate(grpRank=rank(sbjAvg)) %&gt;% arrange(grpRank)\n\n# dCatAvg %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+stat_summary(geom=\"point\",fun=\"mean\")+stat_summary(geom=\"line\",fun=\"mean\")\n\n\n\n# We started by conducting preliminary analyses to remove severe outlier subjects. \n# For the learning phase, the performance measure used for identifying outliers was the \n# same as in Experi- ment 1. For the classification-transfer phase, we measured average\n# accuracy computed across all 63 transfer trials. We again removed the data of any \n# subject who performed more than 2.5 standard deviations below the mean in each condition \n# on either measure. We removed four subjects from the REP condition (leaving 39 valid subjects)\n# and two subjects from the NREP condition (leaving 44 valid subjects).\n# \n# Data variable order, from left to right:\n#   \n# 1. Phase type (1 = Training, 2 = Transfer)\n# 2. Block number (1-15 training, 1 transfer)\n# 3. Trial number (1-15 training, 1-39 transfer)\n# 4. Pattern type (1 = old medium, 2 = prototype, 4 = new medium, 6 = Foil)\n# 5. Category number (1-3)\n# 6. Pattern token* \n# 7. Category/Recognition response (1-3 category training; 1 = old 2 = new recognition transfer)\n# 8. Correct/Incorrect (0 = Incorrect, 1 = Correct)\n# 9. Reaction time (in milliseconds)\n# 10-27.Coordinates of nine dots* (-25 through 24)\n# *Pattern token: index of unique tokens for each category of each type of pattern. The numbering of old medium patterns differs across the two conditions.\n# *Coordinates of nine dots: every two columns represent the x and y coordinates of a dot on a 50 x 50 grid\n\n# file names starting with \"polyrep\" contain data from repeating condtion.\n# file names starting with \"polynrep\" contain data from non-repeating condtion.\n\n\n# pathLoad=\"Exp1_Recognition\"\n# loadPattern=\"*.txt\"\n# pathString=paste(pathLoad,\"/Data/\",sep=\"\")\n# mFiles &lt;- list.files(path=\"Exp1_Recognition/Data/\",pattern = loadPattern, recursive = FALSE) # should be 198 in exp1\n# nFiles=length(mFiles)\n# \n# dRec &lt;- data.frame(matrix(ncol=27,nrow=0)) %&gt;% purrr::set_colnames(col.names)\n# \n# for (i in 1:nFiles){\n#   ps=paste(pathString,mFiles[i],sep=\"\")\n#   sbj = readr::parse_number(mFiles[i])\n#   ind1=regexpr(\"y\",mFiles[i])\n#   ind2=regexpr(sbj,mFiles[i])\n#   d.load=read.table(ps) %&gt;% set_names(col.names) %&gt;% mutate(file=mFiles[i],condit=substr(file,ind1+1,ind2-1),sbjCode=as.factor(sbj))\n#   dRec=rbind(dRec,d.load)\n# }\n# \n# dRec &lt;- dRec %&gt;% relocate(sbjCode,condit,file) %&gt;% group_by(sbjCode) %&gt;%\n#   mutate(nTrain=n(),ind=1,trial=cumsum(ind),id=paste0(sbjCode,\".\",condit),trainAvg=sum(Corr)/nTrain) %&gt;% relocate(trial,.after=\"condit\") %&gt;% arrange(condit,sbj)\n\n# we conducted preliminary analyses to identify severe outlier sub- jects within each condition. \n# In the learning phase, we computed mean proportion correct for each subject during \n# the final eight blocks. In the transfer phase, we computed the difference between mean \n# proportion of old judgments on the old learning patterns and the foils. We removed from \n# all subsequently reported analyses the data of any subject who performed more than 2.5 \n# standard deviations below the mean on either measure. We removed seven subjects from \n# the REP condition (leaving 91 valid subjects) and five subjects from the NREP \n# condition (leaving 95 valid subjects).\n\n#library(forcats)\n\n# dRecAvg=dRec %&gt;% filter(Phase==1) %&gt;% group_by(sbjCode,id,condit,Block) %&gt;% \n#   summarise(nCorr=sum(Corr),propCor=nCorr/15,rtMean=mean(rt),trainAvg=mean(trainAvg)) %&gt;% ungroup() %&gt;% group_by(condit) %&gt;%\n#   mutate(sbjAvg=mean(propCor)) %&gt;% \n#   mutate(grpRank=factor(rank(-trainAvg)),id=factor(id)) %&gt;% arrange(-trainAvg) %&gt;% as.data.frame()\n# \n# dRecAvg$id &lt;-factor(dRecAvg$id,levels=unique(dRecAvg$id))\n# \n# dRecAvg %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+stat_summary(geom=\"point\",fun=\"mean\")+stat_summary(geom=\"line\",fun=\"mean\")\n# dRecAvg %&gt;% ggplot(aes(x=Block,y=rtMean,col=condit))+stat_summary(geom=\"point\",fun=\"mean\")+stat_summary(geom=\"line\",fun=\"mean\")\n# dRecAvg %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+\n#   stat_summary(geom=\"point\",fun=\"mean\")+stat_summary(geom=\"line\",fun=\"mean\")+facet_wrap(~sbjCode)"
  },
  {
    "objectID": "dp_24.html",
    "href": "dp_24.html",
    "title": "Hu & Nosofsky 2024",
    "section": "",
    "text": "Codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted, knitr,grateful)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\nsource(\"read_24.R\")\n\n#https://fonts.google.com/specimen/Manrope\n# ~/Library/Fonts\ntheme_nice &lt;- function() {\n  theme_minimal(base_family = \"Manrope\") +\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.title = element_text(family = \"Manrope Extrabold\", face = \"plain\", size = rel(1.35)),\n      plot.subtitle = element_text(family = \"Manrope Medium\", face = \"plain\", size = rel(1.2)),\n      axis.title = element_text(family = \"Manrope SemiBold\", face = \"plain\", size = rel(1)),\n      axis.title.x = element_text(hjust = .5),\n      axis.title.y = element_text(hjust = .5),\n      axis.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(0.8)),\n      strip.text = element_text(\n        family = \"Manrope\", face = \"bold\",\n        size = rel(.75), hjust = 0\n      ),\n      strip.background = element_rect(fill = \"grey90\", color = NA)\n    )\n}\n\ntheme_nice_dist &lt;- function() {\n  theme_nice() +\n    theme(\n      panel.grid = element_blank(),\n      panel.spacing.x = unit(10, units = \"pt\"),\n      axis.ticks.x = element_line(linewidth = 0.25),\n      axis.text.y = element_blank()\n    )\n}\n\ntheme_set(theme_nice())"
  },
  {
    "objectID": "dp_24.html#filter-to-only-include-sbjs.-who-learned-during-training",
    "href": "dp_24.html#filter-to-only-include-sbjs.-who-learned-during-training",
    "title": "Hu & Nosofsky 2024",
    "section": "Filter to only include sbjs. who learned during training",
    "text": "Filter to only include sbjs. who learned during training\n\nCode# dCat |&gt; filter(Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\n# dCat |&gt; filter(finalTrain&gt;.33, Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\n# dCat |&gt; filter(finalTrain&gt;.66, Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\n# dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\ndCat |&gt; \n  filter(Phase == 2) |&gt; \n  group_by(condit) |&gt; \n  summarise(\n    `All Sbjs.` = n_distinct(sbjCode),\n    `&gt;.33` = n_distinct(sbjCode[finalTrain &gt; .35]),\n    `&gt;.50` = n_distinct(sbjCode[finalTrain &gt; .50]),\n    `&gt;.70` = n_distinct(sbjCode[finalTrain &gt; .70])\n  ) |&gt; kable()\n\n\nSubject Counts for each filtering level. Note that the training conditions are disproporionately impacted.\n\ncondit\nAll Sbjs.\n&gt;.33\n&gt;.50\n&gt;.70\n\n\n\nlow\n77\n77\n75\n73\n\n\nmedium\n78\n75\n63\n42\n\n\nmixed\n74\n67\n57\n42\n\n\nhigh\n75\n56\n35\n17\n\n\n\n\n\nIn the full data-set, the high distortion group has the worst performance for all testing patterns, and the low distortion group has performance either better or equal to all other training groups. However if we only include participants who exceeded 50%, or 70% accuracy during training - the patterns become a bit more complex. Considering the new_high distortion testing items, the groups that experienced more training variability now either match or outperform the low distortion group. The effect of filtering out the weaker learners does not influence the ordering of performance for the old items (i.e. The low distortion group remains the best, and the high distortion group remains the worst).\n\n\nMatch # of learners\nGroup by Condition\nGroup by Pattern\n\n\n\n\nCodetrainRanks &lt;- dCat |&gt; group_by(sbjCode,condit) |&gt; \n  select(finalTrain) |&gt; slice(1) |&gt; arrange(-finalTrain)\n\ntop17 &lt;- trainRanks |&gt; group_by(condit) |&gt; slice(1:17)\ntop35 &lt;- trainRanks |&gt; group_by(condit) |&gt; slice(1:35)\ntop56 &lt;- trainRanks |&gt; group_by(condit) |&gt; slice(1:56)\nlow &lt;- trainRanks |&gt; filter(!(sbjCode %in% top56$sbjCode)) \n\n\n#top17 |&gt; gt::gt()\n\nt17 &lt;- dCat |&gt; filter(sbjCode %in% top17$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing - top 17 Sbjs.\", y=\"Accuracy\") \n\n\nt35 &lt;- dCat |&gt; filter(sbjCode %in% top35$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing - top 35 Sbjs.\", y=\"Accuracy\") \n\nt56 &lt;- dCat |&gt; filter(sbjCode %in% top56$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing - top 56 Sbjs.\", y=\"Accuracy\") \n\ntLow56 &lt;- dCat |&gt; filter(sbjCode %in% low$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) + \n  labs(title=\"Testing - lowest Sbjs (all sbj. NOT in top 56)\", y=\"Accuracy\")\n\n\ntLow35 &lt;- dCat |&gt; filter(!(sbjCode %in% (trainRanks |&gt; group_by(condit) |&gt; slice(1:35))$sbjCode)) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) + \n  labs(title=\"Testing - subjects NOT in top 35\", y=\"Accuracy\")\n\ntLow17 &lt;- dCat |&gt; filter(!(sbjCode %in% (trainRanks |&gt; group_by(condit) |&gt; slice(1:17))$sbjCode)) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) + \n  labs(title=\"Testing - subjects NOT in top 17\", y=\"Accuracy\")\n\n\n\n(t17+tLow17) /(t35+tLow35)/(t56+tLow56) + \n  plot_annotation(title=\"Test Accuracy - matching # of subjects\", \n                  caption=\" Only the top 17; top 35; top 56; or lowest performing subjects included. Rankings based on final training accuracy\")\n\n\n\ntest_strong_learners- top\n\n\nCode# (t17+t35) /(t56+tLow) + \n#   plot_annotation(title=\"Test Accuracy - matching # of subjects\", \n#                   caption=\" Only the top 17; top 35; top 56; or lowest performing subjects included. Rankings based on final training accuracy\")\n\n\n\n\n\nCodetAll &lt;- dCat |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \n\nt33 &lt;- dCat |&gt; filter(finalTrain&gt;.35, Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 35%\", y=\"Accuracy\") \n\nt66 &lt;- dCat |&gt; filter(finalTrain&gt;.50, Phase==2) |&gt;\n  group_by(sbjCode, condit,Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 50%\", y=\"Accuracy\") \n\nt80 &lt;- dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt;\n  group_by(sbjCode, condit,  Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 70%\", y=\"Accuracy\") \n\n((tAll + t33)/(t66 + t80)) + \n  plot_annotation(title=\"Test Accuracy - Influence of filtering out weak/non learers\", \n                  caption=\" % values indicate level of final training performance needed to be included. Note that the training conditions are disproporionately impacted by exclusions.\")\n\n\n\ntest_strong_learners\n\n\n\n\n\n\nCodetAll &lt;- dCat |&gt; filter(Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \n\nt33 &lt;- dCat |&gt; filter(finalTrain&gt;.35, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 35%\", y=\"Accuracy\") \n\nt66 &lt;- dCat |&gt; filter(finalTrain&gt;.50, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 50%\", y=\"Accuracy\") \n\nt80 &lt;- dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 70%\", y=\"Accuracy\") \n\n((tAll + t33)/(t66 + t80))\n\n\n\ntest_strong_learners2"
  },
  {
    "objectID": "dp_24.html#split-by-quartiles-end-of-training-performance",
    "href": "dp_24.html#split-by-quartiles-end-of-training-performance",
    "title": "Hu & Nosofsky 2024",
    "section": "Split by Quartiles (end of training performance)",
    "text": "Split by Quartiles (end of training performance)\nWe can also inspect testing performance by splitting the data into quartiles based on the final training performance. This avoids the issue of excluding subjects, but increases the disparity in training performance between groups (i.e. the worst quartile of high distortion sbjs. had much worse training performance than the worst quartile of low distortion sbjs.)\n\n\nGroup by Condit\nQuartile - Group by Pattern\nQuartile_Boxplots\n\n\n\n\nCodetx1 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank())\ntx2 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank(),legend.position = \"none\" )\nyt &lt;- round(seq(0,1,length.out=7), 2)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),scale_y_continuous(breaks=yt))\n\n\ndq1 &lt;- dCat |&gt; filter(Phase==2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit)) +\n  stat_summary(geom=\"bar\",fun=\"mean\", position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge(), width=.9) +\n  eg + labs(x=\"Pattern Token\", y=\"Proportion Correct\", title=\"Testing Accuracy Overall Averages\", \n            fill=\"Training Condition\") \n  \ndq2 &lt;-dCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = Pattern_Token, y = Corr, fill = condit)) +\n  stat_summary(geom = \"bar\", fun = \"mean\", position = position_dodge()) +\n  stat_summary(geom = \"errorbar\", fun.data = mean_se, position = position_dodge(width = 0.9), width = 0.25) +\n  facet_wrap(~quartile) +\n  labs(x = \"Pattern Token\", y = \"Proportion Correct\", title = \"Testing Accuracy by End-Training Quartile\", \n       subtitle=\"Quartiles are based on the final training performance of each subject\", \n       fill=\"Training Condition\") \n  \ndq1/dq2\n\n\n\ntest_quartiles_condit\n\n\n\n\n\n\nCodetx1 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank())\ntx2 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank(),legend.position = \"none\" )\nyt &lt;- round(seq(0,1,length.out=7), 2)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),scale_y_continuous(breaks=yt))\n\n\ndq1 &lt;- dCat |&gt; filter(Phase==2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token)) +\n  stat_summary(geom=\"bar\",fun=\"mean\", position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge(), width=.9) +\n  eg + labs(x=\"Training Condition\", y=\"Proportion Correct\", title=\"Testing Accuracy Overall Averages\") \n  \ndq2 &lt;-dCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = condit, y = Corr, fill = Pattern_Token)) +\n  stat_summary(geom = \"bar\", fun = \"mean\", position = position_dodge()) +\n  stat_summary(geom = \"errorbar\", fun.data = mean_se, position = position_dodge(width = 0.9), width = 0.25) +\n  facet_wrap(~quartile) +\n  labs(x = \"Training Condition\", y = \"Proportion Correct\", title = \"Testing Accuracy by End-Training Quartile\", \n       subtitle=\"Quartiles are based on the final training performance of each subject\") \n  \ndq1/dq2\n\n\n\ntest_quartiles\n\n\n\n\n\n\nCodedCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = condit, y = Corr, fill = Pattern_Token)) +\n  geom_boxplot(position=position_dodge()) +\n  geom_jitter(position = position_jitterdodge(jitter.width = 0.25, dodge.width = 0.9), alpha = .2) +\n  labs(x = \"Training Condition\", y = \"Proportion Correct\", title = \"Testing Accuracy - All\")\n\n\n\ntest_quartiles_boxplots\n\n\nCodedCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = condit, y = Corr, fill = Pattern_Token)) +\n  geom_boxplot(position=position_dodge()) +\n  geom_jitter(position = position_jitterdodge(jitter.width = 0.25, dodge.width = 0.9), alpha = .2) +\n  facet_wrap(~quartile)\n\n\n\ntest_quartiles_boxplots\n\n\nCode  labs(x = \"Training Condition\", y = \"Proportion Correct\", title = \"Testing Accuracy - All\")\n\n$x\n[1] \"Training Condition\"\n\n$y\n[1] \"Proportion Correct\"\n\n$title\n[1] \"Testing Accuracy - All\"\n\nattr(,\"class\")\n[1] \"labels\""
  },
  {
    "objectID": "dp_24.html#testing-reaction-time",
    "href": "dp_24.html#testing-reaction-time",
    "title": "Hu & Nosofsky 2024",
    "section": "Testing Reaction Time",
    "text": "Testing Reaction Time\nWorth comparing the RT’s to the accuracy. In many cases the RT’s show the inverse pattern of accuracy, i.e. slower RT’s for less accurate patterns.But, the weakest quartile for the High and Medium distortion training conditions don’t follow this pattern.\n\n\nFacet by Training Condition\nGroup by Pattern\n\n\n\n\nCodetx1 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank())\ntx2 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank(),legend.position = \"none\" )\nrtfun &lt;- \"median\"\nyt &lt;- round(seq(0,1500,length.out=7), 2)\neg &lt;- list(scale_y_continuous(breaks=yt))\n\n\nhtq &lt;- dCat |&gt; filter(condit==\"high\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"High Training -  Test RT\", y=\"Reaction Time\") +tx2\n\nltq &lt;- dCat |&gt; filter(condit==\"low\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"Low Training -  Test RT\", y=\"Reaction Time\") +tx1\n\nmtq &lt;- dCat |&gt; filter(condit==\"medium\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"Medium Training -  Test RT\", y=\"Reaction Time\") +tx2\n\n\nmxtq &lt;- dCat |&gt; filter(condit==\"mixed\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"Mixed Training -  Test RT\", y=\"Reaction Time\")  + tx1\n  \n\n\n(htq+ltq)/(mtq+mxtq) + plot_annotation(\n  title = 'Testing Reaction Times by Quartile',\n  subtitle = 'Quartiles set by Final TRAINING block',\n  caption = 'bars reflect median reaction times. Quartiles are set by ACCURACY in the final training block. Bar colors are pattern type.'\n)\n\n\n\nReaction Times\n\n\n\n\n\n\nCodetAll &lt;- dCat |&gt; filter(Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing - All Sbjs.\", y=\"Reaction Time\", x=\"Training Condition\") + theme(legend.position = \"top\")\n\nt33 &lt;- dCat |&gt; filter(finalTrain&gt;.35, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing - Only greater than 35%\", y=\"Reaction Time\", x=\"Training Condition\")  + theme(legend.position = \"none\")\n\nt66 &lt;- dCat |&gt; filter(finalTrain&gt;.50, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing - Only greater than 50%\", y=\"Reaction Times\", x=\"Training Condition\") + theme(legend.position = \"none\")\n\nt80 &lt;- dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing- Only greater than 70%\", y=\"Reaction Times\", x=\"Training Condition\") + theme(legend.position = \"none\")\n((tAll + t33)/(t66 + t80)) + plot_annotation(\n  title = 'Testing Reaction Times by Training Accuracy',\n  subtitle = 'Filtering to retain subjects who achieved different performace levels during training',\n  caption = 'bars reflect median reaction times. Quartiles are set by ACCURACY in the final training block. Bar colors are pattern type.'\n)\n\n\n\n\n\n\n\n\n\n\n’"
  },
  {
    "objectID": "dp_24.html#individual-learning-curves",
    "href": "dp_24.html#individual-learning-curves",
    "title": "Hu & Nosofsky 2024",
    "section": "Individual Learning Curves",
    "text": "Individual Learning Curves\n\nfacets sorted by final training accuracy\nclick on plots to enlarge.\n\n\n\nHigh Distortion\nLow Distortion\nMedium Distortion\nMixed Distortion\n\n\n\n\nCodedCat |&gt; filter(condit==\"high\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"High Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves\n\n\n\n\n\n\nCodedCat |&gt; filter(condit==\"low\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Low Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves - Low\n\n\n\n\n\n\nCodedCat |&gt; filter(condit==\"medium\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Medium Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves - Low\n\n\n\n\n\n\nCodedCat |&gt; filter(condit==\"mixed\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Mixed Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves - Low"
  },
  {
    "objectID": "dp_24.html#individual-testing",
    "href": "dp_24.html#individual-testing",
    "title": "Hu & Nosofsky 2024",
    "section": "Individual Testing",
    "text": "Individual Testing\n\nfacets sorted by final training accuracy\nclick on plots to enlarge.\n\n\nCodetx &lt;- theme(axis.text.x=element_blank() )\n\ndht &lt;- dCat |&gt; filter(condit==\"high\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"High Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\") +\n  theme(legend.position = \"top\") + tx\n\ndlt &lt;- dCat |&gt; filter(condit==\"low\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"Low Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\")+\n  tx +theme(legend.position = \"none\")\n\ndmt &lt;- dCat |&gt; filter(condit==\"medium\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"Medium Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\") +\n  theme(legend.position = \"none\")+\n  tx +theme(legend.position = \"none\")\n\ndmxt &lt;- dCat |&gt; filter(condit==\"mixed\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"Mixed Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\")+\n  tx +theme(legend.position = \"none\")\n\n(dht + dlt)/(dmt+dmxt)\n\n\n\nIndividual Testing Performance\n\n\n\nLink to preprocessing code"
  },
  {
    "objectID": "Task/Task.html",
    "href": "Task/Task.html",
    "title": "Task",
    "section": "",
    "text": "A preview of the judgement task is included below. The task can be restarted by refreshing the page.\nClick here to open the task in a new window: dot_task"
  },
  {
    "objectID": "Task/Task.html#pattern-judgement-task",
    "href": "Task/Task.html#pattern-judgement-task",
    "title": "Task",
    "section": "Pattern Judgement Task",
    "text": "Pattern Judgement Task\n\n\n\n\ndot_task"
  },
  {
    "objectID": "Simulation/dp_24_model.html",
    "href": "Simulation/dp_24_model.html",
    "title": "exemplar_baseline",
    "section": "",
    "text": "Codepacman::p_load(dplyr, purrr, tidyr, ggplot2, here, patchwork, conflicted, knitr, grateful)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n\n\nCode# Distance function using Euclidean distance\ndist.euclidean &lt;- function(e, p) {\n  sqrt(sum((e - p)^2))\n}\n\n# Similarity function using exponential decay\nsimilarity &lt;- function(e, p, c) {\n  exp(-c * dist.euclidean(e, p))\n}\n\n# Generating Prototypes\ngenerate_prototypes &lt;- function(num_categories, num_dimensions, between) {\n  matrix(runif(num_categories * num_dimensions, min = 0, max = between), \n         nrow = num_categories, ncol = num_dimensions)\n}\n\ngenerate_distorted_patterns &lt;- function(prototype, num_samples, distortion_level, within) {\n  num_dimensions &lt;- length(prototype)\n  t(sapply(1:num_samples, function(x) {\n    noise &lt;- rnorm(num_dimensions) * within * distortion_level\n    prototype + noise\n  }))\n}\n\n# Categorization Probability Function\ncategorization_probability &lt;- function(test_pattern, training_patterns, gamma, c) {\n  # Calculate the summed similarities for each category\n  summed_similarities &lt;- apply(training_patterns, 3,function(category_patterns) {\n    sum(sapply(1:nrow(category_patterns), function(i) {\n      similarity(test_pattern, category_patterns[i, ], c)\n    }))\n  })\n  # Raise the summed similarities to the power of gamma\n  numerator &lt;- summed_similarities^gamma\n  denominator &lt;- sum(summed_similarities^gamma)\n  \n  # Return the probability of the test_pattern being in category A\n  probs &lt;- numerator / denominator\n  return (probs)\n}\n\n\n# Simulation Function\nsimulate &lt;- function(num_categories, num_samples, training_distortion_level, within, between, c, gamma, nd=6) {\n  prototypes &lt;- generate_prototypes(num_categories, num_dimensions=nd, between=between)\n  training_patterns &lt;- array(dim = c(num_samples, ncol(prototypes), num_categories))\n  \n  for (cat in 1:num_categories) {\n    training_patterns[,,cat] &lt;- generate_distorted_patterns(prototypes[cat,], num_samples, training_distortion_level, within)\n  }\n  \n  # Assess Testing Performance Here\n  test_performance &lt;- list()\n  categories &lt;- seq_len(num_categories)\n  types_of_patterns &lt;- c(\"old\", \"prototype\", \"new_low\", \"new_medium\", \"new_high\")\n  distortion_levels_test &lt;- c(1.20, 2.80, 4.60) # low, medium, high distortion levels\n  #distortion_levels_test &lt;- c(4, 6, 7.7)\n  \n  for (type in types_of_patterns) {\n    for (cat in categories) {\n      if (type == \"old\") {\n        test_patterns &lt;- matrix(training_patterns[sample(1:num_samples, 27),,cat])\n        #colMeans(test_patterns)\n      } else if (type == \"prototype\") {\n        test_patterns &lt;- matrix(prototypes[cat,], nrow = 1, ncol = ncol(prototypes), byrow = TRUE)\n      } else {\n        distortion_level &lt;- switch(type,\n                                   \"new_low\" = distortion_levels_test[1],\n                                   \"new_medium\" = distortion_levels_test[2],\n                                   \"new_high\" = distortion_levels_test[3])\n        test_patterns &lt;- generate_distorted_patterns(prototypes[cat,], 27, distortion_level, within)\n      }\n      # Calculate categorization probabilities for the test patterns\n      probs &lt;- apply(test_patterns, 1, categorization_probability, training_patterns = training_patterns, gamma = gamma, c = c)\n      # Count correct classifications\n      #correct_classifications &lt;- sum(apply(probs, 2, which.max) == cat)\n      prob_cat &lt;- probs[cat,]\n      \n      test_performance[[paste(type, \"cat\", cat, sep = \"_\")]] &lt;- mean(prob_cat) #correct_classifications / nrow(test_patterns)\n    }\n  }\n  \n  # Combine results into a single data frame\n  test_performance_df &lt;- data.frame(\n    type = rep(types_of_patterns, each = num_categories),\n    category = rep(categories, times = length(types_of_patterns)),\n    correct_classifications = unlist(test_performance)\n  )\n  \n  return(test_performance_df)\n}\n\n\n\nCode# Simulation Parameters\nnum_categories &lt;- 3\nnum_dimensions &lt;- 8\nnum_samples &lt;- 300 # number of samples per category\nbetween &lt;- 2\nwithin &lt;- 0.210\ngamma &lt;- 5.0\nc &lt;- 0.475\ndistortion_levels &lt;- c(4, 6, 7.7) # low, medium, high distortion levels\n#distortion_levels &lt;- c(1, 5, 7.7)\nnsim &lt;- 100\n\n\n\n# List to store performance results from each distortion level\nperformance_results &lt;- list()\n\n# Simulate for each distortion level\nfor (distortion_level in distortion_levels) {\n  results &lt;- replicate(nsim, simulate(num_categories, num_samples, distortion_level, within, between, c, gamma, nd=num_dimensions), simplify = FALSE)\n  performance_results[[as.character(distortion_level)]] &lt;- do.call(rbind, results)\n}\n\n# Combining results\ncombined_results &lt;- bind_rows(\n  lapply(names(performance_results), function(name) {\n    transform(performance_results[[name]], distortion_level = as.numeric(name))\n  }),\n  .id = \"distortion_level\"\n) |&gt; mutate(Pattern_Token = factor(type,levels=c(\"old\",\"prototype\",\"new_low\",\"new_medium\",\"new_high\")))\n\n\n\nyt &lt;- round(seq(0,1,length.out=7), 2)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),scale_y_continuous(breaks=yt))\n# Visualizing the results\nggplot(combined_results, aes(x = Pattern_Token, y = correct_classifications, fill = factor(distortion_level))) +\n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(x = \"Pattern Type\", y = \"Correct Classifications (%)\", fill = \"Training Distortion Level\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set1\") +ggtitle(paste0(\"nsim: \",nsim,\"; gamma: \",gamma,\"; c: \",c,\"; within: \",within,\"; between: \",between,\"; num_samples: \",num_samples, \" nd: \", num_dimensions)) +eg\n\n\n\nCodesaveRDS(sim_nosof1000, file = \"sim_nosof1000.rds\")\n\n\ngenerate_distorted_patterns &lt;- function(prototype, num_samples, distortion_level, within) { num_dimensions &lt;- length(prototype) noise &lt;- matrix(rnorm(num_samples * num_dimensions), nrow = num_samples) * within * distortion_level matrix(rep(prototype, each = num_samples), nrow = num_samples, ncol = num_dimensions) + noise }\ncategorization_probability &lt;- function(test_pattern, training_patterns, gamma, c) { # Compute all similarities at once using matrix operations differences = array(dim = dim(training_patterns)) for (i in 1:dim(training_patterns)[3]) { differences[,,i] = training_patterns[,,i] - test_pattern } distances = sqrt(rowSums(differences^2, dims = 2)) summed_similarities = exp(-c * distances) summed_similarities = apply(summed_similarities, 2, sum)\n# Calculate probabilities numerator &lt;- summed_similarities^gamma denominator &lt;- sum(numerator)\nprobs &lt;- numerator / denominator return(probs) }"
  },
  {
    "objectID": "Stimulii/plotDots.html",
    "href": "Stimulii/plotDots.html",
    "title": "Dot Pattern Plots",
    "section": "",
    "text": "Codepacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table,readr,here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\nlmc22 &lt;- readRDS(here(\"data\",\"lmc22.rds\"))\nmc24 &lt;- readRDS(here(\"data\",\"mc24.rds\"))\n\n\n# mc24_patterns &lt;- mc24 |&gt; \n#   ungroup() |&gt;\n#   rename(Pattern.Type=\"Pattern_Token\") |&gt;\n#   mutate(Pattern.Type=forcats::fct_relevel(Pattern.Type,\"prototype\",\"old\",\"new_low\",\"new_med\",\"new_high\")) |&gt;\n#   select(id,sbjCode,condit,exp,file,Phase,trial,Block,Pattern.Type,Category,Response,Corr,x1:y9) |&gt;\n#   arrange(sbjCode,condit,Category)\n# \n# lmc22_patterns &lt;- lmc22 |&gt; \n#   ungroup() |&gt; \n#   mutate(Pattern.Type = as.character(Pattern.Type)) |&gt; # Convert to character first\n#   mutate(Pattern.Type = factor(case_match(Pattern.Type,\n#                                           \"Trained.Med\" ~ \"old\",\n#                                           \"Prototype\" ~ \"prototype\",\n#                                           \"New.Low\" ~ \"new_low\",\n#                                           \"New.Med\" ~ \"new_med\",\n#                                           \"New.High\" ~ \"new_high\",\n#                                           .default = Pattern.Type), # Include a default case\n#                                levels = c(\"prototype\", \"old\", \"new_low\", \"new_med\", \"new_high\"))) |&gt;\n#   select(id,sbjCode,condit,exp,file,Phase,trial,Block,Pattern.Type,Category,Response,Corr,x1:y9) |&gt;\n#   arrange(sbjCode,condit,Category)\n\n\nmc24_patterns &lt;- read.csv(here(\"Stimulii\",\"mc24_patterns.csv\"))\nlmc22_patterns &lt;- read.csv(here(\"Stimulii\",\"lmc22_patterns.csv\"))\n\n  \nmc24_prototypes &lt;- mc24_patterns |&gt; \n  filter(Pattern.Type==\"prototype\") |&gt;\n  select(sbjCode,condit,exp,file,Category,x1:y9)\n\nlmc22_prototypes &lt;- lmc22_patterns |&gt;\n  filter(Pattern.Type==\"prototype\") |&gt;\n  select(sbjCode,condit,exp,file,Category,x1:y9)\n\n\n\nids &lt;- unique(mc24_patterns$id)\npat_themes &lt;- list(theme_minimal(),xlim(-25, 25),ylim(-25, 25),\n                        labs(x = \"X Coordinate\", y = \"Y Coordinate\"),\n                   coord_fixed(),guides(alpha = FALSE))"
  },
  {
    "objectID": "Stimulii/plotDots.html#pattern-visuals",
    "href": "Stimulii/plotDots.html#pattern-visuals",
    "title": "Dot Pattern Plots",
    "section": "Pattern Visuals",
    "text": "Pattern Visuals\n\nCode# mc24_prototypes_long &lt;- mc24_patterns |&gt; \n#   filter(Pattern.Type==\"prototype\") |&gt;\n#   gather(key = \"coordinate\", value = \"value\", -id, -condit, -exp, -file, -Category) %&gt;%\n#   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n#   spread(key = axis, value = value) %&gt;%\n#   mutate(number = as.integer(number))\n# mc24_prototypes_long |&gt;\n#   filter(id %in% c(\"1.low\",\"10.medium\",\"112.high\")) |&gt;\n#   ggplot(aes(x = x, y = y)) +\n#   geom_point() + # Add dots\n#   facet_grid(id ~ Category) + # Create a grid of plots, with subjects by rows and categories by columns\n#   pat_themes\n\n\n\nCode pat_long &lt;- mc24_patterns |&gt; \n   filter(Phase==2) |&gt; \n   select(id, condit, Category, Pattern.Type, x1:y9) |&gt;\n   group_by(id, condit, Category, Pattern.Type) |&gt; \n   slice_head(n=1) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -id, -condit, -Category,-Pattern.Type) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number))\n \n pat_long |&gt; \n   filter(Category==1, id %in%  c(\"1.low\",\"10.medium\",\"112.high\"),\n          Pattern.Type!=\"old\") |&gt;\n   ggplot(aes(x = x, y = y,col=Pattern.Type)) +\n   geom_point() + # Add dots\n   ggh4x::facet_grid2(id ~ Pattern.Type, margins=c(\"Pattern.Type\")) + # Create a grid of plots, with subjects by rows and categories by columns\n   pat_themes + labs(title=\"Prototypes from Category 1 - with distortions\")\n\n\n\nPrototypes and their distortions\n\n\n\n\nCode pat_long |&gt; \n   mutate(Category = as.factor(Category)) |&gt;\n   filter(id %in%  c(\"1.low\",\"10.medium\"),\n          Pattern.Type!=\"old\") |&gt;\n   ggplot(aes(x = x, y = y,col=Category)) +\n   geom_point() + # Add dots\n   #ggh4x::facet_nested_wrap(id~Category~Pattern.Type) + \n   #ggh4x::facet_grid2(id ~ Category ~ Pattern.Type) +\n   ggh4x::facet_nested(~id + Category ~ Pattern.Type) +\n   pat_themes + labs(title=\"all 3 Category Prototypes and their distortions\") \n\n\n\nall 3 Category Prototypes and their distortions\n\n\n\n\nCode pat_long |&gt; \n   filter(id %in%  c(\"1.low\",\"10.medium\",\"112.high\"),\n          Pattern.Type!=\"old\") |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color = Pattern.Type, alpha = Pattern.Type)) + \n   scale_color_manual(values = c(\"prototype\" = \"black\",  # Black for prototype\n                                 \"old\" = \"#E69F00\",      # Orange for old\n                                 \"new_low\" = \"#56B4E9\",  # Blue for new_low\n                                 \"new_med\" = \"#009E73\",  # Green for new_med\n                                 \"new_high\" = \"red\")) +# Yellow for new_high   scale_alpha_manual(values = c(\"prototype\" = 1, \"old\" = 0.5, \"new_low\" = 0.5, \"new_med\" = 0.5, \"new_high\" = 0.5)) +\n   scale_alpha_manual(values = c(\"prototype\" = 1, \"old\" = 0.2, \"new_low\" = 0.6, \"new_med\" = 0.4, \"new_high\" = 0.4)) +\n    facet_grid(id ~ Category) + pat_themes + labs(title=\"Prototypes with 1 disortion overlaid\")\n\n\n\nPrototypes with 1 disortion overlaid\n\n\n\n\nCode pat_long &lt;- mc24_patterns |&gt; \n   filter(Phase==2) |&gt; \n   select(id, condit,trial, item_label,Category, Pattern.Type, x1:y9) |&gt;\n   group_by(id, condit, Category, Pattern.Type) |&gt; \n   slice_head(n=10) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -id, -condit,-trial,-item_label, -Category,-Pattern.Type) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number)) \n\n pat_long |&gt; \n   filter(id %in%  c(\"1.low\",\"10.medium\",\"112.high\"),Pattern.Type!=\"old\") |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color = Pattern.Type, alpha = Pattern.Type, size= Pattern.Type)) + \n   scale_color_manual(values = c(\"prototype\" = \"black\",  # Black for prototype\n                                 \"old\" = \"#E69F00\",      # Orange for old\n                                 \"new_low\" = \"#56B4E9\",  # Blue for new_low\n                                 \"new_med\" = \"#009E73\",  # Green for new_med\n                                 \"new_high\" = \"red\")) +# Yellow for new_high   scale_alpha_manual(values = c(\"prototype\" = 1, \"old\" = 0.5, \"new_low\" = 0.5, \"new_med\" = 0.5, \"new_high\" = 0.5)) +\n   scale_alpha_manual(values = c(\"prototype\" = 4,  \"new_low\" = 0.5, \"new_med\" = 0.4, \"new_high\" = 0.2)) +\n   scale_size_manual(values = c(\"prototype\" = 1.5,  \"new_low\" = 1, \"new_med\" = 1, \"new_high\" = 1)) +\n   facet_grid(id ~ Category) + pat_themes + labs(title=\"Prototypes with 10 disortion overlaid\")\n\n\n\nPrototypes with 10 disortion overlaid\n\n\n\n\nCode pat_long |&gt; \n mutate(Category=as.factor(Category)) |&gt;\n   filter(id %in%  c(\"1.low\",\"10.medium\",\"112.high\"),Pattern.Type!=\"old\") |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color = Category),alpha=.9) + \n   facet_grid(id ~ Pattern.Type) + pat_themes\n\n\n\nPrototype separability\n\n\n\n\nCode pat_long_train &lt;- mc24_patterns |&gt; \n  mutate(Category=as.factor(Category)) |&gt;\n   filter(id %in% ids[1:16]) |&gt;\n   filter(Phase==1) |&gt; \n   select(id, condit,trial, Category, Pattern.Type, x1:y9) |&gt;\n   group_by(id, condit, Category, Pattern.Type) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -id, -condit,-trial, -Category,-Pattern.Type) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number))\n \n pat_long_train |&gt; \n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color = Category),alpha=.7) + \n   facet_wrap(~condit + id,ncol=4) + pat_themes\n\n\n\nTraining exemplar separability - 10 subjects\n\n\n\n\nCodepat_long_train &lt;- mc24_patterns |&gt; \n  mutate(Category=as.factor(Category)) |&gt;\n   filter(id %in% ids[1:3]) |&gt;\n   filter(Phase==1 | Pattern.Type==\"prototype\") |&gt; \n   select(id, condit,trial, Category, Pattern.Type,Phase, x1:y9) |&gt;\n   group_by(id, condit, Category, Pattern.Type,Phase) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -id, -condit,-trial, -Category,-Pattern.Type,-Phase) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number), itemType= case_match(Phase,1 ~\"Trained\",2~\"Prototype\"))\n \n pat_long_train |&gt; \n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color = Category),alpha=.8) + \n   ggh4x::facet_nested_wrap(~condit + id+itemType,ncol=2) + pat_themes\n\n\n\nTraining exemplar separability compared to prototypes\n\n\n\n\nCode pat_long |&gt; ungroup() |&gt;\n  filter(id %in% ids[1:5] & Pattern.Type==\"prototype\") |&gt;\n  droplevels() |&gt;\n mutate(Category=as.factor(Category)) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color=id),alpha=.9) + \n   facet_grid(id ~ Category) + pat_themes + labs(title=\"Prototypes from first 5 subjects - should match first 10 task trials\")\n\n\n\nPrototypes from first 5 subjects - should match first 10 task trials\n\n\nCode  pat_long |&gt; ungroup() |&gt;\n  filter(id %in% ids[1:5] & Pattern.Type==\"prototype\") |&gt;\n  droplevels() |&gt;\n mutate(Category=as.factor(Category)) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color=id),alpha=.9) + \n   ggh4x::facet_wrap2(~id+item_label) + pat_themes + labs(title=\"Prototypes from first 5 subjects - should match first 10 task trials\")\n\n\n\nPrototypes from first 5 subjects - should match first 10 task trials\n\n\nCode  pat_long |&gt; ungroup() |&gt;\n  filter(id==\"57.low\" & Pattern.Type==\"prototype\") |&gt;\n  droplevels() |&gt;\n mutate(Category=as.factor(Category)) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color=id),alpha=.9) + \n   ggh4x::facet_wrap2(~id+item_label) + pat_themes + labs(title=\"Prototypes from first 5 subjects - should match first 10 task trials\")\n\n\n\nPrototypes from first 5 subjects - should match first 10 task trials\n\n\nCode  pat_long |&gt; ungroup() |&gt;\n  filter(id==\"57.low\" & Pattern.Type==\"prototype\") |&gt;\n  droplevels() |&gt;\n mutate(Category=as.factor(Category), y = -y) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color=id),alpha=.9) + \n   ggh4x::facet_wrap2(~id+item_label) + pat_themes + labs(title=\"Prototypes from first 5 subjects - should match first 10 task trials\")  \n\n\n\nPrototypes from first 5 subjects - should match first 10 task trials\n\n\n\n\nlink to instruction examples"
  },
  {
    "objectID": "Stimulii/plotDots.html#task-demo",
    "href": "Stimulii/plotDots.html#task-demo",
    "title": "Dot Pattern Plots",
    "section": "Task Demo",
    "text": "Task Demo\n\n\ndot_task"
  },
  {
    "objectID": "dp_22.html",
    "href": "dp_22.html",
    "title": "Hu & Nosofsky 2022",
    "section": "",
    "text": "Codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted, viridis, gghalves)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\nsource(\"read_22.R\")\n\ntheme_set(theme_bw())\n\ndcp &lt;- merge(dCatAvg2,sbjTrainAvg,by=c(\"id\",\"condit\",\"Condition\"))\n\n\ndc &lt;- dCatAvg2 %&gt;% select(id,condit,Condition,Pattern.Type2,Category,propCor) %&gt;% \n  pivot_wider(names_from = \"Pattern.Type2\",values_from = \"propCor\") %&gt;%\n  mutate(EndTrain.Minus.HighDistort= End.Training-New.High,\n         MedDistort.Minus.HighDistort=New.Med-New.High,\n         LowDistort.Minus.HighDistort=New.Low-New.High,\n         TrainedItem.Minus.HighDistort=Trained.Med-New.High,\n         Prototype.Minus.HighDistort=Prototype-New.High) \n\ndc &lt;- merge(dc,sbjTrainAvg,by=c(\"id\",\"condit\",\"Condition\"))\ndc2 &lt;- dc %&gt;% group_by(id,condit,Condition,cq) %&gt;% summarise(End.Training=mean(End.Training),New.High=mean(New.High)) %&gt;% as.data.frame()"
  },
  {
    "objectID": "dp_22.html#testing---splitting-peformance-by-end-of-training",
    "href": "dp_22.html#testing---splitting-peformance-by-end-of-training",
    "title": "Hu & Nosofsky 2022",
    "section": "Testing - Splitting Peformance by End of Training",
    "text": "Testing - Splitting Peformance by End of Training\n\nCodelibrary(gghalves)\n\nps &lt;- dcp  %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~cq)+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n  xlab(\"Pattern-Type\")+ylab(\"Proportion Correct\")+ggtitle(\"Low vs High Performers (median split within condition - final training block) - Performance x Pattern Type\")\n\nhd&lt;- dcp  %&gt;% filter(Pattern.Type2==\"New-High\")%&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  geom_boxplot(outlier.shape=NA)+geom_jitter(alpha=.5)+facet_wrap(~cq)+xlab(\"Pattern-Type\")+\n  ggtitle(\"Low vs High Performers (median split within condition) - High Distortion Performance\")+ylab(\"Proportion Correct\")\n\n\n# dcp  %&gt;% filter(Pattern.Type2==\"New-High\") %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n#   geom_half_violin()+\n#   geom_jitter(alpha=.5)+\n#   facet_wrap(~cq)+ggtitle(\"Low vs High Performers (median split within condition) - High Distortion Performance\")\n\n#ps\n#gridExtra::grid.arrange(ps,hd)\n\n\np7&lt;- dcp  %&gt;% filter(endTrain&gt;.75) %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n  xlab(\"Pattern-Type\")+ylab(\"Proportion Correct\")+ggtitle(\"Performance x Pattern Type - Only retaining sbjs with &gt;75% accuracy in final training block\")\n\np5 &lt;-  dcp  %&gt;% filter(endTrain&gt;.50) %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n  xlab(\"Pattern-Type\")+ylab(\"Proportion Correct\")+ggtitle(\"Performance x Pattern Type - Only retaining sbjs with &gt;50% accuracy in final training block\")\n\n\ngridExtra::grid.arrange(ps,p7,p5)\n\n\n\n\n\n\nCode# dCatAvg2  %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~cq)+\n#   stat_summary(geom=\"point\")\n#    geom_hline(yintercept = .33,linetype=\"dashed\")+\n#  ggtitle(\"\")+ylab(\"Proportion Correct\")\n\n# dCatAvg2 %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Pattern.Type2))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~condit)+\n#    geom_hline(yintercept = .33,linetype=\"dashed\")+\n#  ggtitle(\"\")+ylab(\"Proportion Correct\")\n# \n# \n# dCatAvg3 %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Pattern.Type2))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~condit)+\n#    geom_hline(yintercept = .33,linetype=\"dashed\")+\n#  ggtitle(\"\")+ylab(\"Proportion Correct\")"
  },
  {
    "objectID": "dp_22.html#controlling-for-end-of-training-performace",
    "href": "dp_22.html#controlling-for-end-of-training-performace",
    "title": "Hu & Nosofsky 2022",
    "section": "Controlling for End of Training Performace",
    "text": "Controlling for End of Training Performace\n\nCodelibrary(rstatix)\nlibrary(ggpubr)\nlibrary(emmeans)\nlibrary(cowplot)\n\n\n# dc2 %&gt;% filter() %&gt;% ggplot(aes(x=End.Training,y=New.High,color=condit))+geom_point()+geom_smooth(method=\"lm\")\n# dc2 %&gt;% filter(End.Training&gt;.33, New.High&gt;.33) %&gt;% ggplot(aes(x=End.Training,y=New.High,color=condit))+geom_point()+geom_smooth(method=\"lm\")\n\n(at1 &lt;- dc2 %&gt;% anova_test(dv=New.High,between=Condition,covariate = End.Training,wid=id,type=3))\n\nANOVA Table (type III tests)\n\n        Effect DFn DFd       F        p p&lt;.05   ges\n1 End.Training   1  86 128.607 9.21e-19     * 0.599\n2    Condition   1  86  12.249 7.40e-04     * 0.125\n\nCode(at2 &lt;- dc2 %&gt;% filter(End.Training&gt;.33) %&gt;% anova_test(dv=New.High,between=Condition,covariate = End.Training,wid=id,type=3))\n\nANOVA Table (type III tests)\n\n        Effect DFn DFd       F        p p&lt;.05   ges\n1 End.Training   1  84 103.961 2.36e-16     * 0.553\n2    Condition   1  84  12.573 6.43e-04     * 0.130\n\nCode(at3 &lt;- dc2 %&gt;% filter(End.Training&gt;.88) %&gt;% anova_test(dv=New.High,between=Condition,covariate = End.Training,wid=id,type=3))\n\nANOVA Table (type III tests)\n\n        Effect DFn DFd      F        p p&lt;.05   ges\n1 End.Training   1  49 13.847 0.000511     * 0.220\n2    Condition   1  49 13.131 0.000689     * 0.211\n\nCode#dc2 %&gt;% anova_test(New.High ~condit*End.Training) # no sig. interaction\npwc1 &lt;- dc2 %&gt;% emmeans_test(New.High ~ Condition,covariate=End.Training,p.adjust.method=\"bonferroni\")%&gt;% add_xy_position(x = \"condit\", fun = \"mean_se\")\nget_emmeans(pwc1)\n\n# A tibble: 2 × 8\n  End.Training Condition emmean     se    df conf.low conf.high method      \n         &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       \n1        0.830 rep        0.673 0.0198    86    0.634     0.713 Emmeans test\n2        0.830 nrep       0.772 0.0191    86    0.734     0.810 Emmeans test\n\nCodepwc2 &lt;- dc2 %&gt;% filter(End.Training&gt;.33) %&gt;% emmeans_test(New.High ~ Condition,covariate=End.Training,p.adjust.method=\"bonferroni\")%&gt;% add_xy_position(x = \"condit\", fun = \"mean_se\")\npwc3 &lt;- dc2 %&gt;% filter(End.Training&gt;.88) %&gt;% emmeans_test(New.High ~ Condition,covariate=End.Training,p.adjust.method=\"bonferroni\")%&gt;% add_xy_position(x = \"condit\", fun = \"mean_se\")\n\n\n\nep1&lt;-ggline(get_emmeans(pwc1), x = \"Condition\", y = \"emmean\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + \n  stat_pvalue_manual(pwc1, hide.ns = TRUE, tip.length = FALSE) +\n  labs(subtitle = get_test_label(at1, detailed = TRUE),caption = get_pwc_label(pwc1),title=\"Estimated Marginal Means from ANCOVA - All Sbj. (n=89)\" )\n\nep2&lt;-ggline(get_emmeans(pwc2), x = \"Condition\", y = \"emmean\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + \n  stat_pvalue_manual(pwc2, hide.ns = TRUE, tip.length = FALSE) +\n  labs(subtitle = get_test_label(at2, detailed = TRUE),caption = get_pwc_label(pwc2), title= \"Estimated Marginal Means from ANCOVA - Only above chance sbj (&gt;.33,n=87)\")\n\nep3&lt;-ggline(get_emmeans(pwc3), x = \"Condition\", y = \"emmean\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + \n  stat_pvalue_manual(pwc3, hide.ns = TRUE, tip.length = FALSE) +\n  labs(subtitle = get_test_label(at3, detailed = TRUE),caption = get_pwc_label(pwc3), title= \"Estimated Marginal Means from ANCOVA - Only strong learners (&gt;.88; n=52)\")\n\n\n\ngg.ac1 &lt;- ggscatter(dc2,x=\"End.Training\",y=\"New.High\",color=\"Condition\",add=\"reg.line\",add.params = list(size=.3))+\n  stat_regline_equation(aes(label=paste(..eq.label.., ..rr.label..,sep=\"~~~~\"),color=Condition))+\n  ggtitle(\"Including All Subjects (n=89)\")+ylab(\"High Distortions - Proportion Correct\")+xlab(\"End of Training - Proportion Correct\")\n\ngg.ac2 &lt;- dc2 %&gt;% filter(End.Training&gt;.33) %&gt;% ggscatter(.,x=\"End.Training\",y=\"New.High\",color=\"Condition\",add=\"reg.line\",add.params = list(size=.3))+\n  stat_regline_equation(aes(label=paste(..eq.label.., ..rr.label..,sep=\"~~~~\"),color=Condition))+\n  ggtitle(\"Retain Sbj's above chance (&gt;.33) at train end (n=87). \")+ylab(\"High Distortions - Proportion Correct\")+xlab(\"End of Training - Proportion Correct\")\n\ngg.ac3 &lt;- dc2 %&gt;% filter(End.Training&gt;.88) %&gt;% ggscatter(.,x=\"End.Training\",y=\"New.High\",color=\"Condition\",add=\"reg.line\",add.params = list(size=.3))+\n  stat_regline_equation(aes(label=paste(..eq.label.., ..rr.label..,sep=\"~~~~\"),color=Condition))+\n  ggtitle(\"Retain only stronger learners (&gt;.88) at train end (n=52). \")+ylab(\"High Distortions - Proportion Correct\")+xlab(\"End of Training - Proportion Correct\")\n\n\n\ngtitle=\" Hu & Nosofsky 2020 - Experiment 2. Effect of Condition on High Distortions - Controlling for End of Training Performance\"\ntitle = ggdraw()+draw_label(gtitle,fontface = 'bold',x=0,hjust=0)+theme(plot.margin = margin(0, 0, 0, 7))\n\nplot_grid(title,NULL,gg.ac1,ep1,gg.ac2,ep2,gg.ac3,ep3,ncol=2,rel_heights=c(.1,1,1,1))"
  },
  {
    "objectID": "dp_22.html#individual-learning-curves",
    "href": "dp_22.html#individual-learning-curves",
    "title": "Hu & Nosofsky 2022",
    "section": "Individual Learning Curves",
    "text": "Individual Learning Curves\n\nCodedCatTrainAvg %&gt;% filter(condit==\"rep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+\n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Hu & Nosofsky Experiment 2 - Learning. Rep Subjects - Average Accuracy Per Block.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))\n\n\n\n\n\n\nCodedCatTrainAvg %&gt;% filter(condit==\"nrep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+\n  stat_summary(shape=2, geom=\"point\",fun=\"mean\",col=\"lightblue\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"lightblue\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  facet_wrap(~id)+ggtitle(\"Hu & Nosofsky Experiment 2 - Learning. NRep Subjects - Average Accuracy Per Block.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))"
  },
  {
    "objectID": "dp_22.html#experiment-2---separate-category---learning-curves",
    "href": "dp_22.html#experiment-2---separate-category---learning-curves",
    "title": "Hu & Nosofsky 2022",
    "section": "Experiment 2 - separate category - learning curves",
    "text": "Experiment 2 - separate category - learning curves\n\nCodedCatTrainAvg2 %&gt;% filter(condit==\"rep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=Category,shape=Category))+\n  stat_summary(geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Hu & Nosofsky Experiment 2 - Learning Curves. Rep Subjects - Separated Categories.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))\n\n\n\n\n\n\nCodedCatTrainAvg2 %&gt;% filter(condit==\"nrep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=Category,shape=Category))+\n  stat_summary(geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  facet_wrap(~id)+ggtitle(\"Hu & Nosofsky Experiment 2 - Learning Curves. NRep Subjects - Separated Categories.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))"
  },
  {
    "objectID": "dp_22.html#experiment-2---3-training-stages-transfer-patterns",
    "href": "dp_22.html#experiment-2---3-training-stages-transfer-patterns",
    "title": "Hu & Nosofsky 2022",
    "section": "Experiment 2 - 3 Training Stages + Transfer Patterns",
    "text": "Experiment 2 - 3 Training Stages + Transfer Patterns\n\nCodedCatAvg %&gt;% filter(condit==\"rep\") %&gt;% ggplot(aes(x=Stage,y=propCor,fill=Pattern.Type))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~id)+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n ggtitle(\"REP - 3 training bins (75 trials each) + Transfer Patterns\")+ylab(\"Proportion Correct\")\n\n\n\n\n\n\nCodedCatAvg %&gt;% filter(condit==\"nrep\") %&gt;% ggplot(aes(x=Stage,y=propCor,fill=Pattern.Type))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~id)+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n ggtitle(\"NREP - 3 training bins (75 trials each) + Transfer Patterns\")+ylab(\"Proportion Correct\")\n\n\n\n\n\n\nCode# \n# dCatAvg %&gt;% filter() %&gt;% ggplot(aes(x=Stage,y=propCor,fill=Pattern.Type))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~condit)+ggtitle(\"nrep\")\n# \n# dCatAvg %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type,y=propCor,fill=condit))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~Stage)+ggtitle(\"\")\n# \n# dCatAvg %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type,y=propCor,col=condit))+\n#   geom_boxplot(position=position_dodge())+facet_wrap(~Stage)"
  },
  {
    "objectID": "read_24.html",
    "href": "read_24.html",
    "title": "Process 24 data",
    "section": "",
    "text": "# 1. Phase type (1 Training, 2 Test)\n# 2. Block number (1-10 Training, 1 Test)\n# 3. Trial number (1-270 Training, 271-354 Test)*\n# 4. Pattern type (1 = old*, 2 = prototype, 3 = new low, 4 = new medium, 5 = new high)\n# 5. Category number (1-3)\n# 6. Pattern token* (1-90 old, 1 prototype, 1-3 new low, 1-6 new med, 1-9 new high)\n# 7. distortion level (1 = low, 2 = med, 3 = high)\n# 8. Category response (1-3)\n# 9. Correct/Incorrect (0 = Incorrect, 1 = Correct)\n# 10. Reaction time (in milliseconds)\n# 11-28. Coordinates of nine dots* (-25 through 24)\n# *Pattern type: All training patterns (including old patterns in the test phase) are coded as 1 regardless of the distortion levels\n# *Pattern token: index of unique tokens for each category of each type of pattern. \n# *Coordinates of nine dots: every two columns represent the x and y coordinates of a dot on a 50 x 50 grid\n# \n# The conditions are indicated in the file names: \n#   file names with \"cond1\", \"cond2\", \"cond3\" and \"cond4\" contain data from the low, medium, high and mixed-distortion training conditions respectively. \n\n\n#rm(list=ls())\n\npacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n\ncol.names = c(\"Phase\",\"Block\",\"BlockTrial\",\"Pattern\",\"Category\",\"Pattern.Token\",\"distortion\",\"Response\",\"Corr\",\"rt\",\n              \"x1\",\"y1\",\"x2\",\"y2\",\"x3\",\"y3\",\"x4\",\"y4\",\"x5\",\"y5\",\"x6\",\"y6\",\"x7\",\"y7\",\"x8\",\"y8\",\"x9\",\"y9\", \"file\", \"condit\", \"sbjCode\")\n\nloadPattern=\"dot_*\"\npathString=paste0(\"data/mc_2024/\",sep=\"\")\nmFiles &lt;- list.files(path=pathString,pattern = loadPattern, recursive = FALSE) # should be 89 in exp 2\nnFiles=length(mFiles)\n# read in each of the txt files in mFiles - into a single tibble\n\nd &lt;- purrr::map2_dfr(mFiles, mFiles, ~ read.table(paste0(pathString, .x, sep = \"\")) %&gt;%\n    mutate(\n      file = .y,\n      condit = stringr::str_extract(.y, \"cond\\\\d+\"),\n      sbjCode = stringr::str_extract(.y, \"sub\\\\d+\")\n    )) %&gt;%\n    purrr::set_names(col.names) |&gt; \n  group_by(sbjCode, condit) |&gt;\n  mutate(trial = row_number()) |&gt; \n  relocate(\"sbjCode\", \"condit\", \"trial\") \n\n\n\ndCat &lt;- d |&gt; \n  mutate(\n    phase = case_when(\n      Phase == \"1\" ~ \"Training\",\n      Phase == \"2\" ~ \"Test\"\n    ), \n    Stage = case_when(\n      trial %in% 1:90 ~ \"Start\",\n      trial %in% 91:180 ~ \"Middle\",\n      trial %in% 181:270 ~ \"End\",\n      trial %in% 271:354 ~ \"Test\"\n    ),\n    pattern = case_when(\n      Pattern == \"1\" ~ \"old\",\n      Pattern == \"2\" ~ \"prototype\",\n      Pattern == \"3\" ~ \"new_low\",\n      Pattern == \"4\" ~ \"new_med\",\n      Pattern == \"5\" ~ \"new_high\"\n    ),\n    distortion = recode(distortion,\n                        `0` = \"prototype\",\n                        `1` = \"low\",\n                        `2` = \"med\",\n                        `3` = \"high\"),\n    Pattern_Token = case_when(\n      pattern == \"old\" & Pattern.Token %in% 1:90 ~ \"old\",\n      pattern == \"prototype\" & Pattern.Token == 0 ~ \"prototype\",\n      pattern == \"new_low\" & Pattern.Token %in% 1:3 ~ \"new_low\",\n      pattern == \"new_med\" & Pattern.Token %in% 1:6 ~ \"new_med\",\n      pattern == \"new_high\" & Pattern.Token %in% 1:9 ~ \"new_high\"\n    ),\n    condit = recode(condit,\n                    \"cond1\" = \"low\",\n                    \"cond2\" = \"medium\",\n                    \"cond3\" = \"high\",\n                    \"cond4\" = \"mixed\")\n  ) |&gt; \n  relocate(Stage, .after=trial) |&gt; relocate(Pattern_Token, pattern, .after=Pattern.Token)\n\ndCat$Pattern_Token = factor(dCat$Pattern_Token,levels=c(\"old\",\"prototype\",\"new_low\",\"new_med\",\"new_high\")) \ndCat$condit = factor(dCat$condit,levels=c(\"low\",\"medium\",\"mixed\",\"high\") )\n\n\ndCatTrainAvg=dCat |&gt; filter(Phase==1)  |&gt; group_by(sbjCode,condit,Block) |&gt; \n  summarise(nCorr=sum(Corr),propCor=nCorr/27,rtMean=mean(rt), n=n(),.groups = 'keep') |&gt; \n  ungroup() |&gt; group_by(condit) |&gt;\n  mutate(grpRank=factor(rank(-propCor)),id=factor(sbjCode)) |&gt; \n   as.data.frame() |&gt; arrange(sbjCode,condit,Block)\n\ndtf &lt;- dCatTrainAvg |&gt; filter(Block==10) |&gt; arrange(-propCor) |&gt;\n  group_by(condit) |&gt; # bin into quartile by propCor\n  mutate(quartile = ntile(propCor, 4), finalTrain=propCor) \n\ndCatTrainAvg$id &lt;-factor(dCatTrainAvg$id,levels=unique(dCatTrainAvg$sbjCode))\n\n\n\ndCatTestAvg=dCat |&gt; filter(Phase==2)  |&gt; group_by(sbjCode,condit,Pattern_Token) |&gt; \n  summarise(Corr=mean(Corr),rtMean=mean(rt), n=n(),.groups = 'keep') |&gt; \n  ungroup() |&gt; group_by(condit) |&gt;\n  mutate(grpRank=factor(rank(-Corr)),id=factor(sbjCode)) |&gt; \n  as.data.frame() |&gt; arrange(sbjCode,condit,Corr)\n\ndte_h &lt;- dCatTestAvg |&gt; filter(Pattern_Token==\"new_high\") |&gt; arrange(-Corr) |&gt;\n  group_by(condit) |&gt; \n  mutate(q_test_high = ntile(Corr, 4), test_high=Corr)\n\ndte_o &lt;- dCatTestAvg |&gt; filter(Pattern_Token==\"old\") |&gt; arrange(-Corr) |&gt;\n  group_by(condit) |&gt; \n  mutate(q_test_old = ntile(Corr, 4), test_old=Corr)\n\ndCat &lt;- dCat |&gt; left_join(dtf |&gt; select(sbjCode,condit,quartile, finalTrain), by=c(\"sbjCode\",\"condit\"))\ndCat &lt;- dCat |&gt; left_join(dte_h |&gt; select(sbjCode,condit,q_test_high, test_high), by=c(\"sbjCode\",\"condit\"))\ndCat &lt;- dCat |&gt; left_join(dte_o |&gt; select(sbjCode,condit,q_test_old, test_old), by=c(\"sbjCode\",\"condit\"))\n\n\n\ndCat$sbjCode &lt;-factor(dCat$sbjCode,levels=unique(dtf$id))\n\n\ndCat &lt;- dCat |&gt; mutate(exp=\"mc24\",\n                       sbjCode=stringr::str_extract(sbjCode, \"\\\\d+\"),\n                       id=paste0(sbjCode,\".\",condit))  |&gt;\n  relocate(id,sbjCode,exp,condit,Phase,phase,Stage,trial,\n           Block,BlockTrial,Pattern_Token,Pattern.Token,Pattern,pattern,distortion,\n           Category,Response,Corr,rt)\n  \n\n#write out aggregated trial level data\n#write_rds(dCat, \"data/mc24.rds\")\n\n\n\n# length(unique(dCat$Pattern.Token))\n\n# dPattern &lt;- dCat |&gt; filter(Phase==2) |&gt; \n#   group_by(Pattern_Token, Pattern.Token) |&gt; \n#   summarise(m=mean(Corr), n=n())\n\n# dPattern &lt;- dCat |&gt; filter(Phase==2) |&gt; \n#   group_by(Pattern_Token, Pattern.Token,x1,y1,x2,y2,x3,y3,x4,y4,x5,y5,x6,y6,x7,y7,x8,y8,x9,y9) |&gt; \n#   dplyr::relocate(Pattern_Token, Pattern.Token, m,n,x1,y1,x2,y2,x3,y3,x4) |&gt;\n#   arrange(n)\n\n# dPattern &lt;- dCat |&gt; filter(Phase==2) |&gt; \n#   group_by(x1,y1,x2,y2,x3,y3,x4,y4,x5,y5,x6,y6,x7,y7,x8,y8,x9,y9) |&gt; \n#   summarise(m=mean(Corr), n=n()) |&gt; \n#   dplyr::relocate(m,n,x1,y1,x2,y2,x3,y3,x4) |&gt;\n#   arrange(n)\n\n\n# dPattern &lt;- dCat |&gt; filter(Phase==2) |&gt; \n#   select(sbjCode,condit,Pattern_Token, Pattern.Token,Corr,\n#   \"x1\",\"y1\",\"x2\",\"y2\",\"x3\",\"y3\",\"x4\",\"y4\",\"x5\",\"y5\",\"x6\",\"y6\",\"x7\",\"y7\",\"x8\",\"y8\",\"x9\",\"y9\") \n  \n\n\ndPattern &lt;- dCat |&gt; filter(Phase==2) |&gt; \n  select(sbjCode,condit,distortion,Pattern_Token,Category,Response,Corr,rt,x1,y1,x2,y2,x3,y3,x4,y4,x5,y5,x6,y6,x7,y7,x8,y8,x9,y9) |&gt; \n  arrange(x1,y1)\n\n#write.csv(dPattern, \"dPattern24.csv\", row.names=FALSE)\n\n\n\n#The attached data is from a Category Learning experiment. Subjects are trained and then tested on dot pattern categories. \n# Patterns are distortions from a generating prototype. Subjects never encounter the prototype during training, \n# but are tested from it. No item is ever repeated (each subject has 3 randomly generated prototypes, \n# and those unique prototypes are used to generate unique training and testing stimuli for each subject).\n\n# Each dot pattern is defined by 9 coordinates. The x and y coordinates are specified by columns in the dataframe (i.e. x1,y1,x2,y2 etc.). \n\n# I want to train a deep learning model that predicts how difficult a new testing pattern will be given 1) the coordinates of the item; \n#2) the coordinates of the prototype; and 3) the coordinates of the training items. \n\n\n# Data dictionary:\n# sbjCode - subect identifier\n# condit: training condition (\"low\",\"medium\",\"high\",\"mixed\") - degree of distortion from prototype of training items\n# Pattern_Token: type of pattern (\"old\",\"prototype\", \"new_low\",\"new_med\",\"new_high\"); old was a training pattern. \n# distortion: (1 = low, 2 = med, 3 = high): degree of distortion from prototype\n# Category: (1-3): Correct category - distinct for each sbjCode\n# Response: which category was selected (1-3): Correct category - distinct for each sbjCode\n# Corr: (0 = Incorrect, 1 = Correct)\n# rt: reaction time\n# x,y,Coordinates of nine dots: every two columns represent the x and y coordinates of a dot on a 50 x 50 grid\n\n# Groups:   sbjCode, condit [5]\n#   sbjCode condit Category distortion Pattern_Token Response  Corr    x1    y1    x2    y2    x3    y3    x4    y4    x5    y5    x6    y6    x7    y7    x8    y8    x9    y9\n#   &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt; &lt;chr&gt;      &lt;fct&gt;            &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n# 1 sub399  medium        1 high       new_high             1     1   -25   -12    10    -3     5   -11    -9    -5   -13     7    -7    -1    24   -12     6   -13     9     7\n# 2 sub399  medium        1 high       new_high             1     1   -25    -9     7    -3     8    -8   -16    -4    -6    18    -4    -2    18   -15    10   -12     3    -1\n# 3 sub214  medium        1 high       new_high             1     1   -25    -8   -13   -11    -4   -15   -11    14    16   -20     3     1    21    14    -8    -9     1    -8\n# 4 sub297  mixed         1 high       new_high             1     1   -25    -4   -11    12     4   -13   -12   -15    17    -1   -13    11    -8    -2   -16    -2     5     7\n# 5 sub109  mixed         3 high       new_high             3     1   -25    -1    12    13     3    11    -9    -6     3    14     2     6    -3     5     0     9    -1   -13\n\n# unique(Pattern_Token)\n# [1] old    new_high  new_med   new_low   prototype\n\n# d1 &lt;- dCat |&gt; filter(sbjCode==\"sub1\")\n# da &lt;- d |&gt; group_by(sbjCode, condit) |&gt; summarise(n = n()) %&gt;% dplyr::arrange(n)\n# sub12 has 708 trials - rest have 354. \n# the two sub12 instances are in different condits"
  },
  {
    "objectID": "Stimulii/instruction_examples.html",
    "href": "Stimulii/instruction_examples.html",
    "title": "Dot Pattern Plots",
    "section": "",
    "text": "Codepacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table,readr,here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n# lmc22 &lt;- readRDS(here(\"data\",\"lmc22.rds\"))\n# mc24 &lt;- readRDS(here(\"data\",\"mc24.rds\"))\n\nlmc22_prototypes &lt;- read.csv(here(\"Stimulii\",\"lmc22_prototypes.csv\"))\nmc24_prototypes &lt;- read.csv(here(\"Stimulii\",\"mc24_prototypes.csv\"))\n\npat_themes &lt;- list(theme_minimal(),xlim(-25, 25),ylim(-25, 25),\n                        labs(x = \"X Coordinate\", y = \"Y Coordinate\"),\n                   coord_fixed(),guides(alpha = FALSE))\n\n\n\n\nCodeproto_long &lt;- lmc22_prototypes |&gt; \n   select(item_label, x1:y9) |&gt;\n   group_by(item_label) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -item_label) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number))\n \nproto_long |&gt; \n  filter(item_label %in% unique(proto_long$item_label)[1:100]) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=.75) + \n   ggh4x::facet_nested_wrap(~item_label) +\n   pat_themes + labs(title=\"Prototypes from Category 1 - with distortions\")\n\n\n\nPrototypes and their distortions\n\n\n\n\n\nCodecircle &lt;- c(\"10_nrep_2_287\",\"12_nrep_3_270\", \"27_rep_3_263\")\nhsplit &lt;- c(\"14_nrep_2_258\",\"13_rep_1_227\", \"2_nrep_3_261\", \"14_nrep_1_245\",\"34_nrep_3_229\")\nvsplit &lt;- c(\"1_rep_2_262\", \"22_nrep_2_239\", \"12_nrep_1_248\", \"11_rep_3_264\",\"38_nrep_3_288\",\"32_rep_3_286\")\ndsplit &lt;- c(\"20_nrep_2_236\", \"20_rep_3_247\")\ntower &lt;- c(\"11_rep_2_281\",\"25_rep_3_248\",\"47_rep_3_235\")\ntree &lt;- c(\"28_nrep_1_234\",\"41_nrep_2_285\",\"40_rep_2_272\")\nqmark &lt;- c(\"12_nrep_2_258\",\"20_nrep_1_267\",\"35_nrep_1_238\")\ndiag &lt;- c(\"24_nrep_1_242\",\"16_nrep_3_276\", \"26_nrep_3_263\",\"48_nrep_3_233\",\"47_nrep_1_227\")\nvert &lt;- c(\"11_rep_1_257\", \"25_rep_2_250\",\"48_nrep_3_233\")\nhoriz &lt;- c(\"22_rep_1_263\",\"4_nrep_2_236\")\nonemass &lt;- c(\"13_rep_1_227\", \"16_rep_1_241\",\"18_nrep_2_253\",\"47_nrep_2_264\")\ntriag &lt;- c(\"18_nrep_3_254\",\"46_rep_3_246\")\nincomp &lt;- c(\"22_nrep_3_235\",\"12_rep_1_282\",\"33_rep_2_282\", \"44_nrep_1_263\")\n\n\nproto_long |&gt; \n  filter(item_label %in% c(circle, hsplit, vsplit, dsplit, tower, \n                           qmark, diag, vert, horiz, onemass, triag, incomp,tree)) |&gt;\n  mutate(plabel = case_when(\n    item_label %in% circle ~ \"Circle\",\n    item_label %in% hsplit ~ \"Horizontal Split\",\n    item_label %in% vsplit ~ \"Vertical Split\",\n    item_label %in% dsplit ~ \"Diagonal Split\",\n    item_label %in% tower ~ \"Tower\",\n    item_label %in% triag ~ \"triag\",\n    item_label %in% tree ~ \"tree\",\n    item_label %in% triag ~ \"Trianglish\",\n    item_label %in% qmark ~ \"Question Mark\",\n    item_label %in% diag ~ \"Diagonal\",\n    item_label %in% vert ~ \"Vertical\",\n    item_label %in% horiz ~ \"Horizontal\",\n    item_label %in% incomp ~ \"incomp\",\n    item_label %in% onemass ~ \"One Mass\")) |&gt;\n   ggplot(aes(x = x, y = y,col=plabel)) +\n   geom_point(size=.75) + \n   ggh4x::facet_nested_wrap(~plabel+item_label) +\n   pat_themes + labs(title=\"Prototypes with Distinctive Patterns\") +\n  theme(legend.position = \"top\")\n\n\n\nPrototypes with distinctive patterns\n\n\n\n\n\nCodehsim1 &lt;- circle[2:3]\nhsim2 &lt;- onemass[3:4]\nmsim1 &lt;- vsplit[1:2]\nlsim1 &lt;- c(diag[1],hsplit[3])\nlsim2 &lt;- c(circle[1],tower[3])\n\nproto_long |&gt; \n  filter(item_label %in% c(hsim1, hsim2, msim1, lsim1, lsim2)) |&gt;\n  mutate(plabel = case_when(\n    item_label %in% hsim1 ~ \"High Similarity 1\",\n    item_label %in% hsim2 ~ \"High Similarity 2\",\n    item_label %in% msim1 ~ \"Slight Similarity\",\n    item_label %in% lsim1 ~ \"Low Similarity 1\",\n    item_label %in% lsim2 ~ \"Low Similarity\")) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n    ggh4x::facet_nested_wrap(~plabel+item_label,ncol=2) + \n    theme(panel.background = element_blank(),\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank()) +xlim(-25, 25) + ylim(-25,25)\n\n\n\nPrototype pairs with different similarity levels\n\n\n\n\n\nCodeblank_theme &lt;- list( theme(panel.background = element_blank(),\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        panel.grid = element_blank(),\n        # no facet labels\n        strip.background = element_blank(),\n        strip.text.x = element_blank(),\n        panel.spacing = unit(12, \"lines\")), \n        xlim(-25, 25), ylim(-25,25))\n\n\nphsim1 &lt;- proto_long |&gt; \n  filter(item_label %in% hsim1) |&gt; \n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme \n  \nphsim2 &lt;- proto_long |&gt;\n  filter(item_label %in% hsim2) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\npmsim1 &lt;- proto_long |&gt;\n  filter(item_label %in% msim1) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\n\nplsim1 &lt;- proto_long |&gt;\n  filter(item_label %in% lsim1) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\nplsim2 &lt;- proto_long |&gt;\n  filter(item_label %in% lsim2) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\n\n\n# phsim1\n# phsim2\n# pmsim1\n# plsim1\n# plsim2\n\n\nvery_similar &lt;- (phsim1/phsim2) \nnot_similar &lt;- (plsim1/plsim2)\n\nvery_similar +  plot_annotation(subtitle = 'Examples of Very Similar Pairs')\n\n\n\n\n\n\nCodenot_similar  +  plot_annotation(subtitle = 'Examples of Not Similar Pairs')\n\n\n\n\n\n\nCode# save_plots\n# ggsave(here(\"Task/assets/high_sim.png\"),very_similar)\n# ggsave(here(\"Task/assets/low_sim.png\"),not_similar)"
  },
  {
    "objectID": "Stimulii/instruction_examples.html#find-instruction-patterns",
    "href": "Stimulii/instruction_examples.html#find-instruction-patterns",
    "title": "Dot Pattern Plots",
    "section": "",
    "text": "Codepacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table,readr,here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n# lmc22 &lt;- readRDS(here(\"data\",\"lmc22.rds\"))\n# mc24 &lt;- readRDS(here(\"data\",\"mc24.rds\"))\n\nlmc22_prototypes &lt;- read.csv(here(\"Stimulii\",\"lmc22_prototypes.csv\"))\nmc24_prototypes &lt;- read.csv(here(\"Stimulii\",\"mc24_prototypes.csv\"))\n\npat_themes &lt;- list(theme_minimal(),xlim(-25, 25),ylim(-25, 25),\n                        labs(x = \"X Coordinate\", y = \"Y Coordinate\"),\n                   coord_fixed(),guides(alpha = FALSE))\n\n\n\n\nCodeproto_long &lt;- lmc22_prototypes |&gt; \n   select(item_label, x1:y9) |&gt;\n   group_by(item_label) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -item_label) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number))\n \nproto_long |&gt; \n  filter(item_label %in% unique(proto_long$item_label)[1:100]) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=.75) + \n   ggh4x::facet_nested_wrap(~item_label) +\n   pat_themes + labs(title=\"Prototypes from Category 1 - with distortions\")\n\n\n\nPrototypes and their distortions\n\n\n\n\n\nCodecircle &lt;- c(\"10_nrep_2_287\",\"12_nrep_3_270\", \"27_rep_3_263\")\nhsplit &lt;- c(\"14_nrep_2_258\",\"13_rep_1_227\", \"2_nrep_3_261\", \"14_nrep_1_245\",\"34_nrep_3_229\")\nvsplit &lt;- c(\"1_rep_2_262\", \"22_nrep_2_239\", \"12_nrep_1_248\", \"11_rep_3_264\",\"38_nrep_3_288\",\"32_rep_3_286\")\ndsplit &lt;- c(\"20_nrep_2_236\", \"20_rep_3_247\")\ntower &lt;- c(\"11_rep_2_281\",\"25_rep_3_248\",\"47_rep_3_235\")\ntree &lt;- c(\"28_nrep_1_234\",\"41_nrep_2_285\",\"40_rep_2_272\")\nqmark &lt;- c(\"12_nrep_2_258\",\"20_nrep_1_267\",\"35_nrep_1_238\")\ndiag &lt;- c(\"24_nrep_1_242\",\"16_nrep_3_276\", \"26_nrep_3_263\",\"48_nrep_3_233\",\"47_nrep_1_227\")\nvert &lt;- c(\"11_rep_1_257\", \"25_rep_2_250\",\"48_nrep_3_233\")\nhoriz &lt;- c(\"22_rep_1_263\",\"4_nrep_2_236\")\nonemass &lt;- c(\"13_rep_1_227\", \"16_rep_1_241\",\"18_nrep_2_253\",\"47_nrep_2_264\")\ntriag &lt;- c(\"18_nrep_3_254\",\"46_rep_3_246\")\nincomp &lt;- c(\"22_nrep_3_235\",\"12_rep_1_282\",\"33_rep_2_282\", \"44_nrep_1_263\")\n\n\nproto_long |&gt; \n  filter(item_label %in% c(circle, hsplit, vsplit, dsplit, tower, \n                           qmark, diag, vert, horiz, onemass, triag, incomp,tree)) |&gt;\n  mutate(plabel = case_when(\n    item_label %in% circle ~ \"Circle\",\n    item_label %in% hsplit ~ \"Horizontal Split\",\n    item_label %in% vsplit ~ \"Vertical Split\",\n    item_label %in% dsplit ~ \"Diagonal Split\",\n    item_label %in% tower ~ \"Tower\",\n    item_label %in% triag ~ \"triag\",\n    item_label %in% tree ~ \"tree\",\n    item_label %in% triag ~ \"Trianglish\",\n    item_label %in% qmark ~ \"Question Mark\",\n    item_label %in% diag ~ \"Diagonal\",\n    item_label %in% vert ~ \"Vertical\",\n    item_label %in% horiz ~ \"Horizontal\",\n    item_label %in% incomp ~ \"incomp\",\n    item_label %in% onemass ~ \"One Mass\")) |&gt;\n   ggplot(aes(x = x, y = y,col=plabel)) +\n   geom_point(size=.75) + \n   ggh4x::facet_nested_wrap(~plabel+item_label) +\n   pat_themes + labs(title=\"Prototypes with Distinctive Patterns\") +\n  theme(legend.position = \"top\")\n\n\n\nPrototypes with distinctive patterns\n\n\n\n\n\nCodehsim1 &lt;- circle[2:3]\nhsim2 &lt;- onemass[3:4]\nmsim1 &lt;- vsplit[1:2]\nlsim1 &lt;- c(diag[1],hsplit[3])\nlsim2 &lt;- c(circle[1],tower[3])\n\nproto_long |&gt; \n  filter(item_label %in% c(hsim1, hsim2, msim1, lsim1, lsim2)) |&gt;\n  mutate(plabel = case_when(\n    item_label %in% hsim1 ~ \"High Similarity 1\",\n    item_label %in% hsim2 ~ \"High Similarity 2\",\n    item_label %in% msim1 ~ \"Slight Similarity\",\n    item_label %in% lsim1 ~ \"Low Similarity 1\",\n    item_label %in% lsim2 ~ \"Low Similarity\")) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n    ggh4x::facet_nested_wrap(~plabel+item_label,ncol=2) + \n    theme(panel.background = element_blank(),\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank()) +xlim(-25, 25) + ylim(-25,25)\n\n\n\nPrototype pairs with different similarity levels\n\n\n\n\n\nCodeblank_theme &lt;- list( theme(panel.background = element_blank(),\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        panel.grid = element_blank(),\n        # no facet labels\n        strip.background = element_blank(),\n        strip.text.x = element_blank(),\n        panel.spacing = unit(12, \"lines\")), \n        xlim(-25, 25), ylim(-25,25))\n\n\nphsim1 &lt;- proto_long |&gt; \n  filter(item_label %in% hsim1) |&gt; \n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme \n  \nphsim2 &lt;- proto_long |&gt;\n  filter(item_label %in% hsim2) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\npmsim1 &lt;- proto_long |&gt;\n  filter(item_label %in% msim1) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\n\nplsim1 &lt;- proto_long |&gt;\n  filter(item_label %in% lsim1) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\nplsim2 &lt;- proto_long |&gt;\n  filter(item_label %in% lsim2) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\n\n\n# phsim1\n# phsim2\n# pmsim1\n# plsim1\n# plsim2\n\n\nvery_similar &lt;- (phsim1/phsim2) \nnot_similar &lt;- (plsim1/plsim2)\n\nvery_similar +  plot_annotation(subtitle = 'Examples of Very Similar Pairs')\n\n\n\n\n\n\nCodenot_similar  +  plot_annotation(subtitle = 'Examples of Not Similar Pairs')\n\n\n\n\n\n\nCode# save_plots\n# ggsave(here(\"Task/assets/high_sim.png\"),very_similar)\n# ggsave(here(\"Task/assets/low_sim.png\"),not_similar)"
  },
  {
    "objectID": "Stimulii/plotDots.html#find-instruction-patterns",
    "href": "Stimulii/plotDots.html#find-instruction-patterns",
    "title": "Dot Pattern Plots",
    "section": "Find Instruction Patterns",
    "text": "Find Instruction Patterns\nView large set of protypes from Hu & Nosofsky 2022\n\n\n\n\n\nPrototypes with distinctive patterns\n\n\n\n\n\nFinalize and save patterns\n\n\n\n\n\nFinal Patterns for instructions"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dot Pattern Similarity Project",
    "section": "",
    "text": "Dot Pattern Plots\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDot Pattern Similarity\n\n\n\n\n\n\n\n\n\n\n\nMar 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHu & Nosofsky 2022\n\n\n\n\n\n\n\n\n\n\n\nJan 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHu & Nosofsky 2024\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "dotSim_Analysis.html",
    "href": "dotSim_Analysis.html",
    "title": "Dot Pattern Similarity",
    "section": "",
    "text": "prototype sets refer to sets of 3 prototypes that correspond to a single participant in the Hu & Nosofsky 2024 study. prototype pairs refer to the specific pairs of prototypes that are displayed together on a rating trial (3 pairs per set).\nCodepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, \n  conflicted, jsonlite,stringr, gt, knitr, kableExtra, lubridate,ggh4x)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\noptions(digits=2, scipen=999, dplyr.summarise.inform=FALSE)\nwalk(c(\"fun_plot\"), ~ source(here::here(paste0(\"R/\", .x, \".R\"))))\nmc24_proto &lt;- read.csv(here(\"Stimulii\",\"mc24_prototypes.csv\")) |&gt; mutate(set=paste0(sbjCode,\"_\",condit)) \nsbj_cat &lt;- read.csv(here(\"data\",\"mc24_sbj_cat.csv\"))\n\ndfiles &lt;- list(path=list.files(here::here(\"data/dotSim_data\"),full.names=TRUE))\n\nd &lt;- map_dfr(dfiles$path, ~read.csv(.x))\n\nd &lt;- map_dfr(dfiles$path, ~{read.csv(.x) |&gt; \n    mutate(sfile=tools::file_path_sans_ext(basename(.x)))}) |&gt; \n  select(-trial_index, -internal_node_id,-trial_type) |&gt;\n   mutate(set = paste(str_extract(item_label_1, \"^\\\\d+\"),\n                     str_extract(item_label_1, \"[a-z]+\"), sep = \"_\")) |&gt;\n  mutate(pair_label = paste0(item_label_1,\"_\",item_label_2)) |&gt;\n  relocate(sbjCode,date,set,pair_label,trial,item_label_1,item_label_2,response,rt)\n\nsetCounts &lt;- d |&gt; \n  pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(set) |&gt; summarise(n=n_distinct(sbjCode),resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n))\n\n# length(unique(mc_proto$set)) # 304\nsetCounts2 &lt;- mc24_proto |&gt; group_by(set) |&gt; \n  slice_head(n=1) |&gt; \n  select(id,file,set) |&gt; \n  left_join(setCounts,by=\"set\") |&gt; \n  mutate(n = ifelse(is.na(n), 0, n), .groups=\"drop\") |&gt; \n  arrange(n) |&gt; ungroup()\n\npairCounts &lt;- d |&gt; \n  group_by(pair_label,set) |&gt; \n  summarise(n=n(),mean_resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n)) |&gt; ungroup()"
  },
  {
    "objectID": "dotSim_Analysis.html#sanity-checks",
    "href": "dotSim_Analysis.html#sanity-checks",
    "title": "Dot Pattern Similarity",
    "section": "Sanity checks",
    "text": "Sanity checks\n\nCoded |&gt; summarize(n=n(), n_distinct(sbjCode), n_distinct(file), n_distinct(set), n_distinct(trial), n_distinct(item_label_1), n_distinct(item_label_2))\n\n     n n_distinct(sbjCode) n_distinct(file) n_distinct(set) n_distinct(trial)\n1 3333                  11              302             302               303\n  n_distinct(item_label_1) n_distinct(item_label_2)\n1                      604                      604\n\nCoded |&gt; group_by(sbjCode, item_label_1, item_label_2) |&gt; summarise(n=n())\n\n# A tibble: 3,333 × 4\n# Groups:   sbjCode, item_label_1 [2,222]\n   sbjCode item_label_1     item_label_2         n\n     &lt;int&gt; &lt;chr&gt;            &lt;chr&gt;            &lt;int&gt;\n 1       2 101_mixed_1_300  101_mixed_2_335      1\n 2       2 101_mixed_1_300  101_mixed_3_316      1\n 3       2 101_mixed_2_335  101_mixed_3_316      1\n 4       2 103_medium_1_312 103_medium_2_329     1\n 5       2 103_medium_1_312 103_medium_3_271     1\n 6       2 103_medium_2_329 103_medium_3_271     1\n 7       2 104_high_1_290   104_high_2_316       1\n 8       2 104_high_1_290   104_high_3_282       1\n 9       2 104_high_2_316   104_high_3_282       1\n10       2 105_mixed_1_296  105_mixed_2_294      1\n# ℹ 3,323 more rows\n\nCode# (1-.33)^8\n# (factorial(8)/(factorial(6)*factorial(8-6))) * (.33^6)*((1-.33)^(8-6))\n# (factorial(8)/(factorial(7)*factorial(8-7))) *(.33^6)*((1-.33)^(8-7))\n# (factorial(8)/(factorial(8)*factorial(8-8))) *(.33^6)*(1-.33)^(8-8)\n\n\nd |&gt; pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(sbjCode, item) |&gt; summarise(n=n())\n\n# A tibble: 3,333 × 3\n# Groups:   sbjCode [11]\n   sbjCode item                 n\n     &lt;int&gt; &lt;chr&gt;            &lt;int&gt;\n 1       2 101_mixed_1_300      2\n 2       2 101_mixed_2_335      2\n 3       2 101_mixed_3_316      2\n 4       2 103_medium_1_312     2\n 5       2 103_medium_2_329     2\n 6       2 103_medium_3_271     2\n 7       2 104_high_1_290       2\n 8       2 104_high_2_316       2\n 9       2 104_high_3_282       2\n10       2 105_mixed_1_296      2\n# ℹ 3,323 more rows\n\nCodepatternCounts &lt;- d |&gt; pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(item) |&gt; summarise(n=n(),resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n))\n\nsetCounts &lt;- d |&gt; pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(set) |&gt; summarise(n=n(),resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n))\n\npairCounts &lt;- d |&gt; \n  group_by(pair_label) |&gt; \n  summarise(n=n(),resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n)) |&gt; ungroup()\n\n\n\npatternCounts\n\n# A tibble: 906 × 4\n   item                 n  resp    sd\n   &lt;chr&gt;            &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 244_mixed_1_342     16  5     2.53\n 2 244_mixed_2_288     16  5.62  1.96\n 3 244_mixed_3_350     16  5.25  2.21\n 4 351_medium_1_330    16  4.25  2.49\n 5 351_medium_2_311    16  3.31  1.96\n 6 351_medium_3_292    16  4.94  2.35\n 7 374_low_1_306       16  4     2.13\n 8 374_low_2_289       16  3.81  2.29\n 9 374_low_3_344       16  4.81  2.43\n10 101_mixed_1_300     14  4.57  2.06\n# ℹ 896 more rows\n\nCoded |&gt; group_by(sbjCode, file) |&gt; summarise(n=n())\n\n# A tibble: 1,111 × 3\n# Groups:   sbjCode [11]\n   sbjCode file                     n\n     &lt;int&gt; &lt;chr&gt;                &lt;int&gt;\n 1       2 dot_cond1_sub114.txt     3\n 2       2 dot_cond1_sub205.txt     3\n 3       2 dot_cond1_sub217.txt     3\n 4       2 dot_cond1_sub229.txt     3\n 5       2 dot_cond1_sub245.txt     3\n 6       2 dot_cond1_sub257.txt     3\n 7       2 dot_cond1_sub265.txt     3\n 8       2 dot_cond1_sub290.txt     3\n 9       2 dot_cond1_sub294.txt     3\n10       2 dot_cond1_sub322.txt     3\n# ℹ 1,101 more rows\n\nCoded |&gt; group_by(sbjCode, set) |&gt; summarise(n=n())\n\n# A tibble: 1,111 × 3\n# Groups:   sbjCode [11]\n   sbjCode set            n\n     &lt;int&gt; &lt;chr&gt;      &lt;int&gt;\n 1       2 101_mixed      3\n 2       2 103_medium     3\n 3       2 104_high       3\n 4       2 105_mixed      3\n 5       2 111_medium     3\n 6       2 114_low        3\n 7       2 116_high       3\n 8       2 18_medium      3\n 9       2 202_medium     3\n10       2 205_low        3\n# ℹ 1,101 more rows\n\nCoded |&gt; group_by(sbjCode) |&gt; summarise(n_distinct(file))\n\n# A tibble: 11 × 2\n   sbjCode `n_distinct(file)`\n     &lt;int&gt;              &lt;int&gt;\n 1       2                101\n 2       3                101\n 3       4                101\n 4       5                101\n 5       7                101\n 6       8                101\n 7       9                101\n 8      10                101\n 9      11                101\n10      12                101\n11      13                101\n\nCoded |&gt; group_by(sbjCode) |&gt; summarise(n_distinct(set))\n\n# A tibble: 11 × 2\n   sbjCode `n_distinct(set)`\n     &lt;int&gt;             &lt;int&gt;\n 1       2               101\n 2       3               101\n 3       4               101\n 4       5               101\n 5       7               101\n 6       8               101\n 7       9               101\n 8      10               101\n 9      11               101\n10      12               101\n11      13               101\n\nCodepairCounts |&gt; \n  mutate(set=reorder(pair_label,n)) |&gt;\n  ggplot(aes(x=set,y=n)) + geom_col()\n\n\n\n\n\n\nCodepairCounts |&gt; \n  ggplot(aes(x=resp))+geom_histogram() \n\n\n\n\n\n\nCoded |&gt; ggplot(aes(x=response))+geom_histogram() + facet_wrap(~sbjCode)\n\n\n\n\n\n\nCoded |&gt; ggplot(aes(x=rt))+geom_density() + facet_wrap(~sbjCode,scale=\"free_x\")\n\n\n\n\n\n\n\n\nCodepatternCounts |&gt; filter(n&gt;=8) |&gt;  slice_min(resp)\n\n# A tibble: 1 × 4\n  item              n  resp    sd\n  &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 265_low_3_315     8  1.38 0.744\n\nCodepatternCounts |&gt; filter(n&gt;=8) |&gt;  slice_max(resp)\n\n# A tibble: 1 × 4\n  item                 n  resp    sd\n  &lt;chr&gt;            &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 279_medium_1_321     8  7.62  1.69\n\nCodesetCounts |&gt; filter(n&gt;=24) |&gt;  slice_min(resp)\n\n# A tibble: 1 × 4\n  set          n  resp    sd\n  &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 120_high    30   2.4  1.52\n\nCodesetCounts |&gt; filter(n&gt;=24) |&gt;  slice_max(resp)\n\n# A tibble: 1 × 4\n  set            n  resp    sd\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 315_medium    30     7  1.29\n\nCodepairCounts |&gt; filter(n&gt;=5) |&gt;  slice_min(resp,n=2)\n\n# A tibble: 6 × 4\n  pair_label                            n  resp    sd\n  &lt;chr&gt;                             &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 54_medium_2_309_54_medium_3_283       7     2 1.91 \n2 288_high_1_291_288_high_3_342         6     2 0.894\n3 332_high_1_297_332_high_3_293         6     2 0.632\n4 103_medium_2_329_103_medium_3_271     5     2 0.707\n5 120_high_2_319_120_high_3_288         5     2 0.707\n6 216_mixed_1_325_216_mixed_2_283       5     2 1.73 \n\nCodepairCounts |&gt; filter(n&gt;=5) |&gt;  slice_max(resp)\n\n# A tibble: 1 × 4\n  pair_label                        n  resp    sd\n  &lt;chr&gt;                         &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 376_high_1_326_376_high_3_324     5   7.8  2.17\n\nCoded %&gt;% filter(pair_label %in% {pairCounts |&gt; filter(n&gt;=7) |&gt;  slice_min(resp,n=5) |&gt; pull(pair_label)} ) |&gt;\n  group_by(pair_label) |&gt;\n  slice_head(n=1) %&gt;%\n  plot_dotsAll()\n\n\n\n\n\n\nCoded %&gt;% filter(pair_label %in% {pairCounts |&gt; filter(n&gt;=7) |&gt;  slice_max(resp,n=5) |&gt; pull(pair_label)} ) |&gt;\n  group_by(pair_label) |&gt;\n  slice_head(n=1) %&gt;%\n  plot_dotsAll()"
  },
  {
    "objectID": "dotSim_Analysis.html#plot-pairs",
    "href": "dotSim_Analysis.html#plot-pairs",
    "title": "Dot Pattern Similarity",
    "section": "Plot Pairs",
    "text": "Plot Pairs\n\nCoded %&gt;% filter(trial==1) %&gt;%\n  plot_dots()\n\n\n\nPrototypes with 10 disortion overlaid\n\n\nCoded %&gt;% filter(trial==1) %&gt;%\n  plot_dots2()\n\n\n\nPrototypes with 10 disortion overlaid\n\n\nCoded %&gt;% filter(trial&lt;2) %&gt;%\n  plot_dotsAll()\n\n\n\nPrototypes with 10 disortion overlaid"
  },
  {
    "objectID": "dotSim_Analysis.html#compare-to-original-prototypes",
    "href": "dotSim_Analysis.html#compare-to-original-prototypes",
    "title": "Dot Pattern Similarity",
    "section": "Compare to original prototypes",
    "text": "Compare to original prototypes\n\nCode#| fig-width: 6\n#| fig-height: 9\n\n\nd %&gt;% filter(file %in% unique(d$file[1])) %&gt;%\n  plot_dotsAll()\n\n\n\n\n\n\nCodeplot_dotsAll_orig &lt;- function(df) {\n  plots &lt;- list()\n\n  for (i in 1:nrow(df)) {\n    p1 &lt;- df[i, ] %&gt;%\n      pivot_longer(cols = starts_with(\"x\"), names_to = \"dot\", values_to = \"x\") %&gt;%\n      mutate(dot = as.numeric(str_remove(dot, \"x\"))) %&gt;%\n      pivot_longer(cols = starts_with(\"y\"), names_to = \"dot2\", values_to = \"y\") %&gt;%\n      mutate(dot2 = as.numeric(str_remove(dot2, \"y\"))) %&gt;%\n      filter(dot == dot2) %&gt;%\n      ggplot(aes(x = x, y = y)) +\n      geom_point() +\n      coord_cartesian(xlim = c(-25, 25), ylim = c(-25, 25)) +\n      theme_minimal() +\n      labs(title = df$id[i]) + theme_blank\n\n    plots &lt;- append(plots, list(p1))\n  }\n\n  patchwork::wrap_plots(plots, ncol = 1)\n}\n\nmc24_proto |&gt; filter(file %in% unique(d$file[1])) %&gt;% plot_dotsAll_orig()\n\n\n\n\n\n\n\n\n\n\n\n\nPrototypes with 10 disortion overlaid\nPrototypes with 10 disortion overlaid\nPrototypes with 10 disortion overlaid"
  },
  {
    "objectID": "dotSim_Analysis.html#data-checks",
    "href": "dotSim_Analysis.html#data-checks",
    "title": "Dot Pattern Similarity",
    "section": "Data Checks",
    "text": "Data Checks\n\nCode# d |&gt; summarize(n=n(), n_distinct(sbjCode), n_distinct(file), n_distinct(set), n_distinct(trial), n_distinct(item_label_1), n_distinct(item_label_2))\n\n\n\nd |&gt; \n  summarize(n_subjects = n_distinct(sbjCode), n_prototype_sets = n_distinct(set)) |&gt; \n  kbl()\n\n\n\n\nn_subjects\nn_prototype_sets\n\n\n11\n302\n\n\n\n\nCode# d %&gt;%\n#   filter(sbjCode == 11) %&gt;%\n#   select(sbjCode, date, trial, set, rt, time) %&gt;%\n#   mutate(time_parsed = parse_date_time(paste(date, time), orders = c(\"mdY IMS p\", \"mdy IMS p\"))) %&gt;%\n#   group_by(sbjCode, date) %&gt;%\n#   summarise(start_time = min(time_parsed), end_time = max(time_parsed)) %&gt;%\n#   mutate(endTimeMinusStart = end_time - start_time)\n\nplot_hist_sbj &lt;- function(id) {\n  d |&gt; filter(sbjCode==id) |&gt;\n    ggplot(aes(x = response)) +\n    geom_histogram(binwidth=1,fill = 'dodgerblue4') +\n    scale_x_continuous(breaks=seq(1, 9, by = 1)) +\n    coord_cartesian(xlim = c(1, 9)) +\n    theme_minimal() +\n    theme(axis.title.x=element_blank(),\n          axis.title.y=element_blank(),\n          axis.text.x=element_text(size=26))  \n}\n\n\nsbj_sum &lt;- d |&gt; group_by(sbjCode) |&gt; \n#filter(sbjCode&lt;5) |&gt;\n  mutate(time_parsed = parse_date_time(paste(date, time), orders = c(\"mdY IMS p\", \"mdy IMS p\"))) |&gt;\n  summarize (\"Mean Rating\"=mean(response),\n  \"SD Rating\"=sd(response), \n  \"Mean RT\"=mean(rt)/1000, \n  #\"Total Time (min)\" = max(time_elapsed)/60000,\n  \"Total Time (min)\" = round(difftime(max(time_parsed), min(time_parsed), units = \"mins\"),1),\n  n_prototype_sets = n_distinct(set), \n  \"N Trials\" = n_distinct(trial)) |&gt; \n  mutate(\"Response_Distribution\"=sbjCode) \n\n  sbj_sum |&gt; gt() |&gt; \n    text_transform(\n    locations = cells_body(columns = 'Response_Distribution'),\n    fn = function(column) {\n      map(column, plot_hist_sbj) |&gt;\n        ggplot_image(height = px(80), aspect_ratio = 3)\n    }\n    )\n\n\n\n\n\n\nsbjCode\nMean Rating\nSD Rating\nMean RT\nTotal Time (min)\nn_prototype_sets\nN Trials\nResponse_Distribution\n\n\n\n2\n6.3\n2.0\n2.2\n14.7\n101\n303\n\n\n\n3\n4.7\n1.6\n1.6\n11.6\n101\n303\n\n\n\n4\n4.5\n1.6\n3.5\n21.1\n101\n303\n\n\n\n5\n4.0\n2.0\n2.0\n13.5\n101\n303\n\n\n\n7\n5.1\n2.8\n2.8\n17.4\n101\n303\n\n\n\n8\n5.0\n2.4\n2.1\n13.9\n101\n303\n\n\n\n9\n4.7\n2.1\n2.8\n17.2\n101\n303\n\n\n\n10\n4.6\n1.7\n2.4\n15.8\n101\n303\n\n\n\n11\n2.8\n1.8\n5.8\n32.4\n101\n303\n\n\n\n12\n4.3\n2.6\n3.8\n22.2\n101\n303\n\n\n\n13\n5.8\n2.4\n1.2\n9.5\n101\n303\n\n\n\n\n\n\n\nCodesbj_sum |&gt; mutate(total_time=as.numeric(`Total Time (min)`)) |&gt; \n  summarize(\"Average Completion Time (min)\" = mean(total_time), \"Min Completion Time (min)\" = min(total_time), \"Max Completion Time (min)\" = max(total_time)) |&gt; kbl()\n\n\n\n\nAverage Completion Time (min)\nMin Completion Time (min)\nMax Completion Time (min)\n\n\n17\n9.5\n32"
  },
  {
    "objectID": "dotSim_Analysis.html#lowest-and-highest-rated-pairs",
    "href": "dotSim_Analysis.html#lowest-and-highest-rated-pairs",
    "title": "Dot Pattern Similarity",
    "section": "Lowest and Highest Rated Pairs",
    "text": "Lowest and Highest Rated Pairs\n\nCode# patternCounts |&gt; filter(n&gt;=8) |&gt;  slice_min(resp)\n# patternCounts |&gt; filter(n&gt;=8) |&gt;  slice_max(resp)\n\n# setCounts |&gt; filter(n&gt;=24) |&gt;  slice_min(resp)\n# setCounts |&gt; filter(n&gt;=24) |&gt;  slice_max(resp)\n\n\n# pairCounts |&gt; filter(n&gt;=5) |&gt;  slice_min(resp,n=2)\n# pairCounts |&gt; filter(n&gt;=5) |&gt;  slice_max(resp)\n\nmin_resp=7\nn_show=3\n\nd %&gt;% filter(pair_label %in% {pairCounts |&gt; filter(n&gt;=min_resp) |&gt;  \n  slice_min(mean_resp,n=n_show, with_ties=FALSE) |&gt; pull(pair_label)} ) |&gt;\n  group_by(pair_label) |&gt;\n  slice_head(n=1) %&gt;%\n  plot_dotsAll() + \n  plot_annotation(title=glue::glue(\"Lowest rated pairs ( out of sets with n&gt;={min_resp} ratings)\"), theme = theme(plot.title = element_text(hjust = 0.4)))\n\n\n\n\n\n\nCoded %&gt;% filter(pair_label %in% {pairCounts |&gt; filter(n&gt;=min_resp) |&gt;  \n  slice_max(mean_resp,n=n_show, with_ties=FALSE) |&gt; pull(pair_label)} ) |&gt;\n  group_by(pair_label) |&gt;\n  slice_head(n=1) %&gt;%\n  plot_dotsAll() +  \n  plot_annotation(title=glue::glue(\"Highest rated pairs ( out of sets with n&gt;={min_resp} ratings)\"), theme = theme(plot.title = element_text(hjust = 0.4)))"
  },
  {
    "objectID": "dotSim_Analysis.html#prototype-set-counts",
    "href": "dotSim_Analysis.html#prototype-set-counts",
    "title": "Dot Pattern Similarity",
    "section": "Prototype Set Counts",
    "text": "Prototype Set Counts\n\nCode# d |&gt; filter(sbjCode==11) |&gt; select(sbjCode,date,trial,pair_label,set,rt,time_elapsed,time)\n\n# d |&gt; group_by(sbjCode,set) |&gt; \n#   summarize (n=n()) |&gt;\n#   gt()\n\n#d |&gt; group_by(sbjCode, item_label_1, item_label_2) |&gt; summarise(n=n())\n\n# (1-.33)^8\n# (factorial(8)/(factorial(6)*factorial(8-6))) * (.33^6)*((1-.33)^(8-6))\n# (factorial(8)/(factorial(7)*factorial(8-7))) *(.33^6)*((1-.33)^(8-7))\n# (factorial(8)/(factorial(8)*factorial(8-8))) *(.33^6)*(1-.33)^(8-8)\n\n\n# d |&gt; pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n#   group_by(sbjCode, item) |&gt; summarise(n=n())\n\n\nPrototype set counts\n\nCode# patternCounts &lt;- d |&gt; pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n#   group_by(item) |&gt; summarise(n=n(),resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n))\n\n\n\n# d |&gt; \n#     pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; select(sbjCode,set,pair_label,item_label,item,response) |&gt;  group_by(set) |&gt;\n#     summarize(n=n_distinct(sbjCode)) |&gt; arrange(desc(n)) \n\n\nsetCounts &lt;- d |&gt; \n  pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(set) |&gt; summarise(n=n_distinct(sbjCode),resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n))\n\n# length(unique(mc_proto$set)) # 304\nsetCounts2 &lt;- mc24_proto |&gt; group_by(set) |&gt; \n  slice_head(n=1) |&gt; \n  select(id,file,set) |&gt; \n  left_join(setCounts,by=\"set\") |&gt; \n  mutate(n = ifelse(is.na(n), 0, n), .groups=\"drop\") |&gt; \n  arrange(n) |&gt; ungroup()\n\npairCounts &lt;- d |&gt; \n  group_by(pair_label,set) |&gt; \n  summarise(n=n(),mean_resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n)) |&gt; ungroup()\n\n\n\n# d |&gt; group_by(sbjCode, file) |&gt; summarise(n=n())\n# d |&gt; group_by(sbjCode, set) |&gt; summarise(n=n())\n\n# d |&gt; group_by(sbjCode) |&gt; summarise(n_distinct(file))\n# d |&gt; group_by(sbjCode) |&gt; summarise(n_distinct(set))\n\n\nsp &lt;- setCounts2 |&gt; \n  mutate(set=reorder(set,n)) |&gt;\n  ggplot(aes(x=set,y=n)) +\n   geom_col() +\n   theme(legend.title=element_blank(),\n      axis.text.x = element_text(size=5,angle = 90, hjust = 0.5, vjust = 0.5)) +\n    labs(x=\"Prototype Set\", y=\"Number of Participants to rate set\") \n\nsh &lt;- setCounts2 |&gt; \n  ggplot(aes(x=n)) + geom_histogram(binwidth = 1) +\n  scale_x_continuous(breaks=seq(0, max(setCounts2$n), by = 1)) +\n  geom_text(stat=\"count\", aes(label=..count..), vjust=-0.5) +\n  labs(x=\"Number of times prototype set has been included in the study\", \n  y=\"Number of prototype sets for each count\") \n\n\nsp/sh\n\n\n\nPrototype set counts\n\n\nCodesetCounts2 |&gt; group_by(n) |&gt; summarise(nc=n()) |&gt; rename(\"Number of times prototype set has been included in the study\"=n, \"Number of prototype sets with this count\"=nc) |&gt; gt() |&gt; \n  tab_spanner(label = \"Prototype Set Counts\") |&gt; \n  tab_header(title = \"Prototype Set Counts\") |&gt; \n  tab_source_note(\n    \"Note: The number of times a prototype set has been included in the study is the number of participants who rated the set.\"\n  )\n\n\n\n\n\n\n\nPrototype Set Counts\n\n\nNumber of times prototype set has been included in the study\nNumber of prototype sets with this count\n\n\n\n\n0\n2\n\n\n1\n26\n\n\n2\n34\n\n\n3\n79\n\n\n4\n78\n\n\n5\n54\n\n\n6\n22\n\n\n7\n6\n\n\n8\n3\n\n\n\nNote: The number of times a prototype set has been included in the study is the number of participants who rated the set.\n\n\n\n\nPrototype set counts\n\n\n \nRating Distributions\n\nCodepgr &lt;- d |&gt; \n  ggplot(aes(x=response))+geom_histogram(binwidth=1) + \n      scale_x_continuous(breaks=seq(1, 9, by = 1)) +\n    coord_cartesian(xlim = c(1, 9)) + labs(title=\"Aggregate Rating Distribution\", x=\"Rating\", y=\"Count\") \n\npir &lt;- d |&gt;  ggplot(aes(x=response))+\n      geom_histogram(binwidth=1) + \n      facet_wrap(~sbjCode) + \n      scale_x_continuous(breaks=seq(1, 9, by = 1)) +\n    coord_cartesian(xlim = c(1, 9)) + labs(title=\"Rating Distribution per Sbj.\", x=\"Rating\", y=\"Count\") \n\npgr/pir\n\n\n\nRating distributions\n\n\n\nReaction Time Distributions\n\nCodeprtg &lt;- d |&gt; ggplot(aes(x=rt))+\n  geom_density() + \n  labs(title=\"Aggregate Reaction Time Distribution\", x=\"Reaction Time (ms)\", y=\"Density\")\n\nprtid &lt;- d |&gt; ggplot(aes(x=rt))+geom_density() + \n  facet_wrap(~sbjCode,scale=\"free_x\") + labs(title=\"Reaction Time Distribution per Sbj.\", x=\"Reaction Time (ms)\", y=\"Density\")\n\nprtg/prtid\n\n\n\nReaction time distributions"
  },
  {
    "objectID": "dotSim_Analysis.html#all-pairs-with-4-ratings",
    "href": "dotSim_Analysis.html#all-pairs-with-4-ratings",
    "title": "Dot Pattern Similarity",
    "section": "All pairs with >=4 ratings",
    "text": "All pairs with &gt;=4 ratings\n\nclick on column headers to change sort order\n\n\n\nCodepat_table_plot &lt;- function(Pair){\n\n  df &lt;- d |&gt; filter(pair_label==Pair) |&gt; slice_head(n=1) \n\n    pat1 &lt;- df %&gt;%\n          mutate(pattern_1 = purrr::map(pattern_1, jsonlite::fromJSON)) %&gt;%\n          unnest(pattern_1) %&gt;%\n          mutate(y=-y, pat=item_label_1) |&gt; select(pair_label,x,y,pat)\n\n    pat2 &lt;- df %&gt;%\n          mutate(pattern_2 = purrr::map(pattern_2, jsonlite::fromJSON)) %&gt;%\n          unnest(pattern_2) %&gt;%\n          mutate(y=-y, pat=item_label_2) |&gt; select(pair_label,x,y,pat)\n\n    pat &lt;- rbind(pat1,pat2)\n\n     pat |&gt; \n    ggplot(aes(x = x, y = y)) +\n          geom_point(alpha=2) +\n          coord_cartesian(xlim = c(-25, 25), ylim = c(-25, 25)) +\n          theme_minimal() +\n          facet_wrap(~pat,ncol=2) + \n          #theme_blank +\n          theme_void() + \n          theme(strip.text = element_text(size = 7,hjust=.5),\n                panel.spacing.x=unit(-11, \"lines\")) \n}\n\n\n\np5 &lt;- pairCounts |&gt; filter(n&gt;=4) \n\n\np5 |&gt; \nrelocate(pair_label,.after=sd) |&gt;\nrename(\"Pair\"=pair_label, \"N Ratings\"=n, \"Mean Rating\"=mean_resp, \"SD\"=sd) |&gt;\n#group_by(Pair) |&gt; \ngt() |&gt; \n  cols_width(\n    set ~ px(120),\n    Pair ~ px(1000),\n    `N Ratings` ~ px(100),\n    `Mean Rating` ~ px(100),\n    SD ~ px(90)\n  ) |&gt;  fmt_integer() |&gt;\n  cols_align('left', columns = set) |&gt; \n  text_transform(\n    locations = cells_body(columns = Pair),\n    fn = function(column) {\n      map(column, pat_table_plot) |&gt;\n        ggplot_image(height = px(250), aspect_ratio = 2)\n    }\n  ) |&gt;  opt_interactive(page_size_default=5, use_page_size_select= TRUE, use_search=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nCode# #| fig-cap: dot plots\n# #| fig-width: 10\n# #| fig-height: 12\n\n# d %&gt;% filter(trial==1) %&gt;%\n#   plot_dots()\n\n# d %&gt;% filter(trial==1) %&gt;%\n#   plot_dots2()\n\n# d %&gt;% filter(trial&lt;2) %&gt;%\n#   plot_dotsAll()\n\n\n\n\nCode#| fig-width: 6\n#| fig-height: 9\n\n\n# d %&gt;% filter(file %in% unique(d$file[1])) %&gt;%\n#   plot_dotsAll()\n\n# plot_dotsAll_orig &lt;- function(df) {\n#   plots &lt;- list()\n\n#   for (i in 1:nrow(df)) {\n#     p1 &lt;- df[i, ] %&gt;%\n#       pivot_longer(cols = starts_with(\"x\"), names_to = \"dot\", values_to = \"x\") %&gt;%\n#       mutate(dot = as.numeric(str_remove(dot, \"x\"))) %&gt;%\n#       pivot_longer(cols = starts_with(\"y\"), names_to = \"dot2\", values_to = \"y\") %&gt;%\n#       mutate(dot2 = as.numeric(str_remove(dot2, \"y\"))) %&gt;%\n#       filter(dot == dot2) %&gt;%\n#       ggplot(aes(x = x, y = y)) +\n#       geom_point() +\n#       coord_cartesian(xlim = c(-25, 25), ylim = c(-25, 25)) +\n#       theme_minimal() +\n#       labs(title = df$id[i]) + theme_blank\n\n#     plots &lt;- append(plots, list(p1))\n#   }\n\n#   patchwork::wrap_plots(plots, ncol = 1)\n# }\n\n# mc24_proto |&gt; filter(file %in% unique(d$file[1])) %&gt;% plot_dotsAll_orig()\n\n\n\n\n\n\n\nPrototype set counts\nRating distributions\nReaction time distributions"
  },
  {
    "objectID": "dotSim_Analysis.html#data-inspection-sanity-checks",
    "href": "dotSim_Analysis.html#data-inspection-sanity-checks",
    "title": "Dot Pattern Similarity",
    "section": "Data Inspection & Sanity Checks",
    "text": "Data Inspection & Sanity Checks\n\nCodeavg_set_rating &lt;- setCounts2 |&gt; summarise(\"Avg Ratings Per Set\" = mean(n)) |&gt; pull(1)\n\nd |&gt; \n  summarize(\"N Subjects\" = n_distinct(sbjCode), \"N Prototype Sets\" = n_distinct(set)) |&gt; \n  mutate(\"Avg Ratings Per Set\" = avg_set_rating) |&gt;\n  kbl()\n\n\nTable 1: Current counts of unique subjects, and prototype sets\n\n\n\n\n\nN Subjects\nN Prototype Sets\nAvg Ratings Per Set\n\n\n23\n304\n7.6\n\n\n\n\n\n\n\n\n\nCode# d |&gt; summarize(n=n(), n_distinct(sbjCode), n_distinct(file), n_distinct(set), n_distinct(trial), n_distinct(item_label_1), n_distinct(item_label_2))\n\n\n\n\n\n\n# d %&gt;%\n#   filter(sbjCode == 11) %&gt;%\n#   select(sbjCode, date, trial, set, rt, time) %&gt;%\n#   mutate(time_parsed = parse_date_time(paste(date, time), orders = c(\"mdY IMS p\", \"mdy IMS p\"))) %&gt;%\n#   group_by(sbjCode, date) %&gt;%\n#   summarise(start_time = min(time_parsed), end_time = max(time_parsed)) %&gt;%\n#   mutate(endTimeMinusStart = end_time - start_time)\n\nplot_hist_sbj &lt;- function(id) {\n  d |&gt; filter(sbjCode==id) |&gt;\n    ggplot(aes(x = response)) +\n    geom_histogram(binwidth=1,fill = 'dodgerblue4') +\n    scale_x_continuous(breaks=seq(1, 9, by = 1)) +\n    coord_cartesian(xlim = c(1, 9)) +\n    theme_minimal() +\n    theme(axis.title.x=element_blank(),\n          axis.title.y=element_blank(),\n          axis.text.x=element_text(size=26))  \n}\n\n\nsbj_sum &lt;- d |&gt; group_by(sbjCode) |&gt; \n#filter(sbjCode&lt;5) |&gt;\n  mutate(time_parsed = parse_date_time(paste(date, time), orders = c(\"mdY IMS p\", \"mdy IMS p\"))) |&gt;\n  summarize (\"Mean Rating\"=mean(response),\n  \"SD Rating\"=sd(response), \n  \"Mean RT\"=mean(rt)/1000, \n  #\"Total Time (min)\" = max(time_elapsed)/60000,\n  \"Total Time (min)\" = round(difftime(max(time_parsed), min(time_parsed), units = \"mins\"),1),\n  n_prototype_sets = n_distinct(set), \n  \"N Trials\" = n_distinct(trial)) |&gt; \n  mutate(\"Response_Distribution\"=sbjCode) \n\n  sbj_sum |&gt; gt() |&gt; \n    text_transform(\n    locations = cells_body(columns = 'Response_Distribution'),\n    fn = function(column) {\n      map(column, plot_hist_sbj) |&gt;\n        ggplot_image(height = px(80), aspect_ratio = 3)\n    }\n    )\nsbj_sum |&gt; mutate(total_time=as.numeric(`Total Time (min)`)) |&gt; \n  rename(\"Subject\"=sbjCode, \"N_Sets\" = n_prototype_sets) |&gt; \n  summarize(\"Average Completion Time (min)\" = mean(total_time), \"Min Completion Time (min)\" = min(total_time), \"Max Completion Time (min)\" = max(total_time)) |&gt; kbl()\n\n\nTable 2: Individual Subject Ratings\n\n\n\n\n\n\n\nsbjCode\nMean Rating\nSD Rating\nMean RT\nTotal Time (min)\nn_prototype_sets\nN Trials\nResponse_Distribution\n\n\n\n2\n6.3\n2.0\n2.2\n14.7\n101\n303\n\n\n\n3\n4.7\n1.6\n1.6\n11.6\n101\n303\n\n\n\n4\n4.5\n1.6\n3.5\n21.1\n101\n303\n\n\n\n5\n4.0\n2.0\n2.0\n13.5\n101\n303\n\n\n\n7\n5.1\n2.8\n2.8\n17.4\n101\n303\n\n\n\n8\n5.0\n2.4\n2.1\n13.9\n101\n303\n\n\n\n9\n4.7\n2.1\n2.8\n17.2\n101\n303\n\n\n\n10\n4.6\n1.7\n2.4\n15.8\n101\n303\n\n\n\n11\n2.8\n1.8\n5.8\n32.4\n101\n303\n\n\n\n12\n4.3\n2.6\n3.8\n22.2\n101\n303\n\n\n\n13\n5.8\n2.4\n1.2\n9.5\n101\n303\n\n\n\n14\n4.5\n1.8\n3.7\n22\n101\n303\n\n\n\n15\n5.1\n2.3\n2.1\n14\n101\n303\n\n\n\n16\n6.1\n2.1\n1.6\n11.5\n101\n303\n\n\n\n17\n5.5\n2.7\n1.0\n8.7\n101\n303\n\n\n\n18\n2.5\n2.5\n2.1\n14.2\n101\n303\n\n\n\n19\n4.4\n2.3\n1.9\n13\n101\n303\n\n\n\n20\n5.7\n1.6\n2.2\n14.4\n101\n303\n\n\n\n21\n4.6\n2.3\n3.9\n23.1\n101\n303\n\n\n\n22\n4.4\n1.6\n3.4\n20.6\n101\n303\n\n\n\n23\n3.3\n2.5\n2.0\n13.5\n101\n303\n\n\n\n24\n4.7\n2.3\n1.5\n11.1\n101\n303\n\n\n\n25\n5.2\n1.6\n3.1\n18.8\n101\n303\n\n\n\n\n\n\n\n\n\n\n\nAverage Completion Time (min)\nMin Completion Time (min)\nMax Completion Time (min)\n\n\n16\n8.7\n32\n\n\n\n\n\n\n\n\nPrototype set counts\n\nCode# d |&gt; filter(sbjCode==11) |&gt; select(sbjCode,date,trial,pair_label,set,rt,time_elapsed,time)\n\n# d |&gt; group_by(sbjCode,set) |&gt; \n#   summarize (n=n()) |&gt;\n#   gt()\n\n#d |&gt; group_by(sbjCode, item_label_1, item_label_2) |&gt; summarise(n=n())\n\n# (1-.33)^8\n# (factorial(8)/(factorial(6)*factorial(8-6))) * (.33^6)*((1-.33)^(8-6))\n# (factorial(8)/(factorial(7)*factorial(8-7))) *(.33^6)*((1-.33)^(8-7))\n# (factorial(8)/(factorial(8)*factorial(8-8))) *(.33^6)*(1-.33)^(8-8)\n\n# d |&gt; pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n#   group_by(sbjCode, item) |&gt; summarise(n=n())\n\n# patternCounts &lt;- d |&gt; pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n#   group_by(item) |&gt; summarise(n=n(),resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n))\n\n\n\n# d |&gt; \n#     pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; select(sbjCode,set,pair_label,item_label,item,response) |&gt;  group_by(set) |&gt;\n#     summarize(n=n_distinct(sbjCode)) |&gt; arrange(desc(n)) \n\n\n\n\n# d |&gt; group_by(sbjCode, file) |&gt; summarise(n=n())\n# d |&gt; group_by(sbjCode, set) |&gt; summarise(n=n())\n\n# d |&gt; group_by(sbjCode) |&gt; summarise(n_distinct(file))\n# d |&gt; group_by(sbjCode) |&gt; summarise(n_distinct(set))\n\n\nsp &lt;- setCounts2 |&gt; \n  mutate(set=reorder(set,n)) |&gt;\n  ggplot(aes(x=set,y=n)) +\n   geom_col() +\n   theme(legend.title=element_blank(),\n      axis.text.x = element_text(size=5,angle = 90, hjust = 0.5, vjust = 0.5)) +\n    labs(x=\"Prototype Set\", y=\"Number of Participants to rate set\") \n\nsh &lt;- setCounts2 |&gt; \n  ggplot(aes(x=n)) + geom_histogram(binwidth = 1) +\n  scale_x_continuous(breaks=seq(0, max(setCounts2$n), by = 1)) +\n  geom_text(stat=\"count\", aes(label=..count..), vjust=-0.5) +\n  labs(x=\"Number of times prototype set has been included in the study\", \n  y=\"Number of prototype sets for each count\") \n\n\nsp/sh\n\n\n\nPrototype set counts\n\n\n\n \n\nCodesetCounts2 |&gt; group_by(n) |&gt; summarise(nc=n()) |&gt; rename(\"Number of times prototype set has been included in the study\"=n, \"Number of prototype sets with this count\"=nc) |&gt; gt() |&gt; \n  tab_spanner(label = \"Prototype Set Counts\") |&gt; \n  tab_header(title = \"Prototype Set Counts\") |&gt; \n  tab_source_note(\n    \"Note: The number of times a prototype set has been included in the study is the number of participants who rated the set.\"\n  )\n\n\n\n\n\n\n\nPrototype Set Counts\n\n\nNumber of times prototype set has been included in the study\nNumber of prototype sets with this count\n\n\n\n\n1\n2\n\n\n3\n8\n\n\n4\n15\n\n\n5\n27\n\n\n6\n47\n\n\n7\n45\n\n\n8\n60\n\n\n9\n36\n\n\n10\n29\n\n\n11\n18\n\n\n12\n11\n\n\n13\n4\n\n\n14\n1\n\n\n15\n1\n\n\n\nNote: The number of times a prototype set has been included in the study is the number of participants who rated the set.\n\n\n\n\n\n\n \nRating Distributions\n\nCodepgr &lt;- d |&gt; \n  ggplot(aes(x=response))+geom_histogram(binwidth=1) + \n      scale_x_continuous(breaks=seq(1, 9, by = 1)) +\n    coord_cartesian(xlim = c(1, 9)) + labs(title=\"Aggregate Rating Distribution\", x=\"Rating\", y=\"Count\") \n\npir &lt;- d |&gt;  ggplot(aes(x=response))+\n      geom_histogram(binwidth=1) + \n      facet_wrap(~sbjCode) + \n      scale_x_continuous(breaks=seq(1, 9, by = 1)) +\n    coord_cartesian(xlim = c(1, 9)) + labs(title=\"Rating Distribution per Sbj.\", x=\"Rating\", y=\"Count\") \n\npgr/pir\n\n\n\nRating distributions\n\n\n\nReaction Time Distributions\n\nCodeprtg &lt;- d |&gt; ggplot(aes(x=rt))+\n  geom_density() + \n  labs(title=\"Aggregate Reaction Time Distribution\", x=\"Reaction Time (ms)\", y=\"Density\")\n\nprtid &lt;- d |&gt; ggplot(aes(x=rt))+geom_density() + \n  facet_wrap(~sbjCode,scale=\"free_x\") + labs(title=\"Reaction Time Distribution per Sbj.\", x=\"Reaction Time (ms)\", y=\"Density\")\n\nprtg/prtid\n\n\n\nReaction time distributions"
  },
  {
    "objectID": "dotSim_Analysis.html#all-pairs-with-5-ratings",
    "href": "dotSim_Analysis.html#all-pairs-with-5-ratings",
    "title": "Dot Pattern Similarity",
    "section": "All pairs with >=5 ratings",
    "text": "All pairs with &gt;=5 ratings\n\nclick on column headers to change sort order\n\ne.g. clicking on “Mean Rating” will toggle showing the pairs rated most similar or most dissimilar\nclicking on “SD” will toggle showing the pairs with the most or least agreement in ratings\n\n\n\n\n\nCodepat_table_plot &lt;- function(Pair){\n\n  df &lt;- d |&gt; filter(pair_label==Pair) |&gt; slice_head(n=1) \n\n    pat1 &lt;- df %&gt;%\n          mutate(pattern_1 = purrr::map(pattern_1, jsonlite::fromJSON)) %&gt;%\n          unnest(pattern_1) %&gt;%\n          mutate(y=-y, pat=item_label_1) |&gt; select(pair_label,x,y,pat)\n\n    pat2 &lt;- df %&gt;%\n          mutate(pattern_2 = purrr::map(pattern_2, jsonlite::fromJSON)) %&gt;%\n          unnest(pattern_2) %&gt;%\n          mutate(y=-y, pat=item_label_2) |&gt; select(pair_label,x,y,pat)\n\n    pat &lt;- rbind(pat1,pat2)\n\n     pat |&gt; \n    ggplot(aes(x = x, y = y)) +\n          geom_point(alpha=2) +\n          coord_cartesian(xlim = c(-25, 25), ylim = c(-25, 25)) +\n          theme_minimal() +\n          facet_wrap(~pat,ncol=2) + \n          #theme_blank +\n          theme_void() + \n          theme(strip.text = element_text(size = 7,hjust=.5),\n                panel.spacing.x=unit(-7.3, \"lines\")) \n}\n\n\n\np5 &lt;- pairCounts |&gt; filter(n&gt;=8) \n\n\np5 |&gt; \nrelocate(pair_label,.after=sd) |&gt;\nrename(\"Pair\"=pair_label, \"N\"=n, \"Mean Rating\"=mean_resp, \"SD\"=sd) |&gt;\n#group_by(Pair) |&gt; \ngt() |&gt; \ntab_options(table.font.size = px(8L)) |&gt;\n  cols_width(\n    set ~ px(116),\n    Pair ~ px(380),\n    `N` ~ px(50),\n    `Mean Rating` ~ px(90),\n    SD ~ px(55)\n  ) |&gt;  \n  fmt_number(decimals = 1) |&gt; #fmt_integer() |&gt;\n  cols_align('left', columns = set) |&gt; \n  text_transform(\n    locations = cells_body(columns = Pair),\n    fn = function(column) {\n      map(column, pat_table_plot) |&gt;\n        ggplot_image(height = px(210), aspect_ratio = 1.8)\n    }\n  ) |&gt;  \n  opt_interactive(page_size_default=5, \n    use_page_size_select= TRUE, use_search=TRUE, use_resizers=TRUE,use_filters=TRUE, page_size_values = c(5, 10, 25, 50, 100)) \n\n\n\n\n\n\n\n\n\nCorrelations with Accuracy in Hu & Nosofsky 2024\n\nnot really enough data for this yet\n\n\nCodepatternAvg &lt;- d |&gt; \n  pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(item,file) |&gt; \n  summarise(n_rating=n(),resp=mean(response),sd=sd(response)) |&gt; \n  arrange(desc(n_rating))\n\n\ncat_sim &lt;- sbj_cat |&gt; \n  mutate(item=item_label) |&gt;\n  left_join(patternAvg,by=c(\"file\",\"item\"))  |&gt; arrange(desc(n_rating)) |&gt;\n  #remove rows where n_rating is NA, or less than 4\n  filter(!is.na(n_rating),n_rating&gt;=12) \n  \n\n\ncat_sim |&gt; ggplot(aes(x=Corr,y=resp)) + \n  geom_point(aes(col=Pattern.Type)) + \n  #geom_smooth(aes(fill=Pattern.Type)) + \n  facet_wrap(~condit)\n\n\n\n\n\n\nCodecat_sim |&gt; ggplot(aes(x=Corr,y=resp)) + \n  geom_point(aes(col=condit)) + \n  #geom_smooth(aes(fill=Pattern.Type)) + \n  facet_wrap(~Pattern.Type)\n\n\n\n\n\n\n\n\n\nCode# #| fig-cap: dot plots\n# #| fig-width: 10\n# #| fig-height: 12\n\n# d %&gt;% filter(trial==1) %&gt;%\n#   plot_dots()\n\n# d %&gt;% filter(trial==1) %&gt;%\n#   plot_dots2()\n\n# d %&gt;% filter(trial&lt;2) %&gt;%\n#   plot_dotsAll()\n\n\n\n\nCode#| fig-width: 6\n#| fig-height: 9\n\n\n# d %&gt;% filter(file %in% unique(d$file[1])) %&gt;%\n#   plot_dotsAll()\n\n# plot_dotsAll_orig &lt;- function(df) {\n#   plots &lt;- list()\n\n#   for (i in 1:nrow(df)) {\n#     p1 &lt;- df[i, ] %&gt;%\n#       pivot_longer(cols = starts_with(\"x\"), names_to = \"dot\", values_to = \"x\") %&gt;%\n#       mutate(dot = as.numeric(str_remove(dot, \"x\"))) %&gt;%\n#       pivot_longer(cols = starts_with(\"y\"), names_to = \"dot2\", values_to = \"y\") %&gt;%\n#       mutate(dot2 = as.numeric(str_remove(dot2, \"y\"))) %&gt;%\n#       filter(dot == dot2) %&gt;%\n#       ggplot(aes(x = x, y = y)) +\n#       geom_point() +\n#       coord_cartesian(xlim = c(-25, 25), ylim = c(-25, 25)) +\n#       theme_minimal() +\n#       labs(title = df$id[i]) + theme_blank\n\n#     plots &lt;- append(plots, list(p1))\n#   }\n\n#   patchwork::wrap_plots(plots, ncol = 1)\n# }\n\n# mc24_proto |&gt; filter(file %in% unique(d$file[1])) %&gt;% plot_dotsAll_orig()\n\n\n\n\n\n\n\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nPrototype set counts\nRating distributions\nReaction time distributions"
  },
  {
    "objectID": "dotSim_Analysis.html#all-pairs-with-10-ratings",
    "href": "dotSim_Analysis.html#all-pairs-with-10-ratings",
    "title": "Dot Pattern Similarity",
    "section": "All pairs with >=10 ratings",
    "text": "All pairs with &gt;=10 ratings\n\nclick on column headers to change sort order\n\ne.g. clicking on “Mean Rating” will toggle showing the pairs rated most similar or most dissimilar\nclicking on “SD” will toggle showing the pairs with the most or least agreement in ratings\n\n\n\n\n\nCodepat_table_plot &lt;- function(Pair){\n\n  df &lt;- d |&gt; filter(pair_label==Pair) |&gt; slice_head(n=1) \n\n    pat1 &lt;- df %&gt;%\n          mutate(pattern_1 = purrr::map(pattern_1, jsonlite::fromJSON)) %&gt;%\n          unnest(pattern_1) %&gt;%\n          mutate(y=-y, pat=item_label_1) |&gt; select(pair_label,x,y,pat)\n\n    pat2 &lt;- df %&gt;%\n          mutate(pattern_2 = purrr::map(pattern_2, jsonlite::fromJSON)) %&gt;%\n          unnest(pattern_2) %&gt;%\n          mutate(y=-y, pat=item_label_2) |&gt; select(pair_label,x,y,pat)\n\n    pat &lt;- rbind(pat1,pat2)\n\n     pat |&gt; \n    ggplot(aes(x = x, y = y)) +\n          geom_point(alpha=2) +\n          coord_cartesian(xlim = c(-25, 25), ylim = c(-25, 25)) +\n          theme_minimal() +\n          facet_wrap(~pat,ncol=2) + \n          #theme_blank +\n          theme_void() + \n          theme(strip.text = element_text(size = 7,hjust=.5),\n                panel.spacing.x=unit(-7.3, \"lines\")) \n}\n\n\n\np5 &lt;- pairCounts |&gt; filter(n&gt;=10) \n\n\np5 |&gt; \nrelocate(pair_label,.after=sd) |&gt;\nrename(\"Pair\"=pair_label, \"N\"=n, \"Mean Rating\"=mean_resp, \"SD\"=sd) |&gt;\n#group_by(Pair) |&gt; \ngt() |&gt; \ntab_options(table.font.size = px(8L)) |&gt;\n  cols_width(\n    set ~ px(116),\n    Pair ~ px(415),\n    `N` ~ px(50),\n    `Mean Rating` ~ px(90),\n    SD ~ px(55)\n  ) |&gt;  \n  fmt_number(decimals = 1) |&gt; #fmt_integer() |&gt;\n  cols_align('left', columns = set) |&gt; \n  text_transform(\n    locations = cells_body(columns = Pair),\n    fn = function(column) {\n      map(column, pat_table_plot) |&gt;\n        ggplot_image(height = px(230), aspect_ratio = 1.8)\n    }\n  ) |&gt;  \n  opt_interactive(page_size_default=5, \n    use_page_size_select= TRUE, use_search=TRUE, use_resizers=TRUE,use_filters=TRUE, page_size_values = c(5, 10, 25, 50, 100)) \n\n\n\n\n\n\n\n\n\nCorrelations with Accuracy in Hu & Nosofsky 2024\n\nnot really enough data for this yet\n\nAssess # of patterns in various binnings - e.g. quartile, decile\n\nCodepatternAvg &lt;- d |&gt; \n  pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(item,file) |&gt; \n  summarise(n_rating=n(),resp=mean(response),sd=sd(response)) |&gt; \n  arrange(desc(n_rating))\n\n\ncat_sim &lt;- sbj_cat |&gt; \n  mutate(item=item_label) |&gt;\n  left_join(patternAvg,by=c(\"file\",\"item\"))  |&gt; arrange(desc(n_rating)) |&gt;\n  #remove rows where n_rating is NA, or less than 4\n  filter(!is.na(n_rating),n_rating&gt;=12) |&gt; \n  mutate(sim_group = ifelse(resp&gt;6.0,\"Very Similar\",ifelse(resp&lt;3.5,\"Very Dissimilar\",\"Medium\"))) |&gt; \n  mutate(sim_group=factor(sim_group,levels=c(\"Very Dissimilar\",\"Medium\",\"Very Similar\"))) \n\n\n# bin data by rating (resp) into quartiles\nt1 &lt;- cat_sim |&gt; \n  mutate(Quartile = ntile(resp, 5))|&gt;\n  group_by(Quartile) |&gt;\n  summarize(\"Avg. Similarity Rating\"=mean(resp),sd=sd(resp),n_ratings=n_distinct(file), .groups=\"drop\") \n\nt2 &lt;- cat_sim |&gt; \n  mutate(Decile = ntile(resp, 10))|&gt;\n  group_by(Decile) |&gt;\n  summarize(\"Avg. Similarity Rating\"=mean(resp),sd=sd(resp),n_ratings=n_distinct(file), .groups=\"drop\") \n\n\nt3 &lt;- cat_sim |&gt; \n  group_by(sim_group) |&gt;\n  summarize(\"Avg. Similarity Rating\"=mean(resp),sd=sd(resp),n_ratings=n_distinct(file), .groups=\"drop\") \n\nt1 |&gt; kbl(caption=\"Quartiles\")\n\n\n\nQuartiles\n\nQuartile\nAvg. Similarity Rating\nsd\nn_ratings\n\n\n\n1\n3.2\n0.52\n96\n\n\n2\n4.1\n0.15\n112\n\n\n3\n4.7\n0.16\n115\n\n\n4\n5.2\n0.15\n114\n\n\n5\n6.0\n0.43\n90\n\n\n\n\n\nCodet2 |&gt; kbl(caption=\"Deciles\")\n\n\n\nDeciles\n\nDecile\nAvg. Similarity Rating\nsd\nn_ratings\n\n\n\n1\n2.8\n0.42\n49\n\n\n2\n3.6\n0.16\n68\n\n\n3\n4.0\n0.08\n63\n\n\n4\n4.3\n0.08\n68\n\n\n5\n4.6\n0.08\n70\n\n\n6\n4.8\n0.08\n69\n\n\n7\n5.1\n0.08\n69\n\n\n8\n5.4\n0.08\n65\n\n\n9\n5.7\n0.14\n66\n\n\n10\n6.4\n0.37\n48\n\n\n\n\n\nCodet3 |&gt; kbl(caption=\"Extreme Groups\")\n\n\n\nExtreme Groups\n\nsim_group\nAvg. Similarity Rating\nsd\nn_ratings\n\n\n\nVery Dissimilar\n2.9\n0.45\n62\n\n\nMedium\n4.8\n0.66\n232\n\n\nVery Similar\n6.4\n0.36\n41\n\n\n\n\n\n\nCombined Category Testing Performance with Similarity Ratings (resp)\n\nEach subject in the 2024 study has a similarity score for each of their 3 categories. (averaged over 2 comparisons with that categories prototype)\nThe same category similarity scores are then compared to their accuracy for each of the Pattern Tyeps (old, prototype, new low, new med, new high)\n\n\nCodecat_sim %&gt;% # round all numerics except sbjCode to 2 decimal places\n mutate(across(where(is.numeric), ~round(., 1))) |&gt; select(-id,-sim_group,-item_label) |&gt; \n  relocate(item,file, .after=sd) |&gt;\n  rename(\"Category Similarity\" = resp, \"CatLearn Accuracy\" = Corr) |&gt;\n   DT::datatable(options = list(pageLength = 6))\n\n\n\n\n\n\nCodep3 &lt;- cat_sim |&gt; \n  mutate(Quartile = ntile(resp, 4)) |&gt; \n  ggplot(aes(x=Quartile,y=Corr,fill=Quartile)) + \n  stat_bar + \n  facet_wrap(~Pattern.Type) + labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Quintile\", title=\"Effect by Pattern Type\")\n\n\np4 &lt;- cat_sim |&gt; \n  mutate(Decile = ntile(resp, 10)) |&gt; \n  ggplot(aes(x=Decile,y=Corr,fill=Decile)) + \n  stat_bar + \n  facet_wrap(~Pattern.Type) + labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Decile\", title=\"Effect by Pattern Type\")\n\n\n\n\n\np5 &lt;- cat_sim |&gt; \n  mutate(Quartile = ntile(resp, 4)) |&gt; \n  ggplot(aes(x=Quartile,y=Corr,fill=Quartile)) + \n  stat_bar + \n  facet_wrap(~condit) + labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Quartile\", title=\"Effect by Training Condition\")\n\n\np6 &lt;- cat_sim |&gt; \n  mutate(Decile = ntile(resp, 10)) |&gt; \n  ggplot(aes(x=Decile,y=Corr,fill=Decile)) + \n  stat_bar + \n  facet_wrap(~condit) + labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Decile\", title=\"Effect by Training Condition\")\n\n\np7 &lt;- cat_sim |&gt; \n  mutate(Quartile = ntile(resp, 4)) |&gt; \n  ggplot(aes(x=Quartile,y=Corr,fill=Quartile)) + \n  stat_bar + \n  facet_nested_wrap(~condit+Pattern.Type) + labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Quintile\", title=\"Effect by Training Condition and Pattern Type\")\n\n\np3 + p4\n\n\n\n\n\n\nCodep5 + p6\n\n\n\n\n\n\nCodep7\n\n\n\n\n\n\nCodep9 &lt;- cat_sim |&gt; \n  ggplot(aes(y=Corr,x=Pattern.Type, fill=sim_group)) + \n  stat_bar + labs(title=\"Group by Pattern Type\",y=\"CatLearn Accuracy\")\n\np10 &lt;- cat_sim |&gt; \n  ggplot(aes(y=Corr,x=condit, fill=sim_group)) + \n  stat_bar + labs(title=\"Group by Condit\",y=\"CatLearn Accuracy\")\n\n p9 / p10\n\n\n\n\n\n\n\n\nCodecat_sim |&gt; ggplot(aes(x=Corr,y=resp)) + \n  geom_point(aes(col=Pattern.Type)) + \n  geom_smooth(aes(fill=Pattern.Type),method = \"lm\") + \n labs(y=\"Similarity Rating\", x=\"Aggregated Accuracy in CatLearn study\")\n\n\n\n\n\n\nCodecat_sim |&gt; ggplot(aes(x=Corr,y=resp)) + \n  geom_point(aes(col=Pattern.Type)) + \n  geom_smooth(aes(fill=Pattern.Type),method = \"lm\") + \n  facet_wrap(~condit) + labs(y=\"Similarity Rating\", x=\"Aggregated Accuracy in CatLearn study\")\n\n\n\n\n\n\nCodecat_sim |&gt; ggplot(aes(x=Corr,y=resp)) + \n  geom_point(aes(col=condit)) + \n  #geom_smooth(aes(fill=Pattern.Type)) + \n  facet_wrap(~Pattern.Type)\n\n\n\n\n\n\n\n\n\nCode# #| fig-cap: dot plots\n# #| fig-width: 10\n# #| fig-height: 12\n\n# d %&gt;% filter(trial==1) %&gt;%\n#   plot_dots()\n\n# d %&gt;% filter(trial==1) %&gt;%\n#   plot_dots2()\n\n# d %&gt;% filter(trial&lt;2) %&gt;%\n#   plot_dotsAll()\n\n\n\n\nCode#| fig-width: 6\n#| fig-height: 9\n\n\n# d %&gt;% filter(file %in% unique(d$file[1])) %&gt;%\n#   plot_dotsAll()\n\n# plot_dotsAll_orig &lt;- function(df) {\n#   plots &lt;- list()\n\n#   for (i in 1:nrow(df)) {\n#     p1 &lt;- df[i, ] %&gt;%\n#       pivot_longer(cols = starts_with(\"x\"), names_to = \"dot\", values_to = \"x\") %&gt;%\n#       mutate(dot = as.numeric(str_remove(dot, \"x\"))) %&gt;%\n#       pivot_longer(cols = starts_with(\"y\"), names_to = \"dot2\", values_to = \"y\") %&gt;%\n#       mutate(dot2 = as.numeric(str_remove(dot2, \"y\"))) %&gt;%\n#       filter(dot == dot2) %&gt;%\n#       ggplot(aes(x = x, y = y)) +\n#       geom_point() +\n#       coord_cartesian(xlim = c(-25, 25), ylim = c(-25, 25)) +\n#       theme_minimal() +\n#       labs(title = df$id[i]) + theme_blank\n\n#     plots &lt;- append(plots, list(p1))\n#   }\n\n#   patchwork::wrap_plots(plots, ncol = 1)\n# }\n\n# mc24_proto |&gt; filter(file %in% unique(d$file[1])) %&gt;% plot_dotsAll_orig()\n\n\n\n\n\n\n\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nTable 2: Individual Subject Ratings\nPrototype set counts\nRating distributions\nReaction time distributions"
  }
]