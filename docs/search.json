[
  {
    "objectID": "read_22.html",
    "href": "read_22.html",
    "title": "Process 2022 data",
    "section": "",
    "text": "# packages &lt;- c('plyr','dplyr','tidyr','ggplot2','magrittr',\n#              'psych','data.table','grid','gridExtra','R.matlab','units','readr')\n# have = packages %in% rownames(installed.packages())\n# if ( any(!have) ) { install.packages(packages[!have]) }\n# (lapply(packages, require, character.only = TRUE))\n\npacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table,readr,here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n# Data variable order, from left to right:\n#   \n#   1. Phase type (1 = Training, 2 = Transfer)\n# 2. Block number (1-15 training, 1 transfer)\n# 3. Trial number (1-15 training, 1-63 transfer)\n# 4. Pattern type (1 = old medium, 2 = prototype, 3 = new low, 4 = new medium, 5 = new high)\n# 5. Category number (1-3)\n# 6. Pattern token* \n#   7. Category response (1-3)\n# 8. Correct/Incorrect (0 = Incorrect, 1 = Correct)\n# 9. Reaction time (in milliseconds)\n# 10-27.Coordinates of nine dots* (-25 through 24)\n# \n# *Pattern token: index of unique tokens for each category of each type of pattern. The numbering of old medium patterns differs for the two conditions.\n# *Coordinates of nine dots: every two columns represent the x and y coordinates of a dot on a 50 x 50 grid\n# \n# file names starting with \"polyrep\" contain data from repeating condtion.\n# file names starting with \"polynrep\" contain data from non-repeating condtion.\n\n\n\n\n\n\n\n#rm(list=ls())\n\ncol.names = c(\"Phase\",\"Block\",\"BlockTrial\",\"Pattern\",\"Category\",\"Pattern.Token\",\"Response\",\"Corr\",\"rt\",\n              \"x1\",\"y1\",\"x2\",\"y2\",\"x3\",\"y3\",\"x4\",\"y4\",\"x5\",\"y5\",\"x6\",\"y6\",\"x7\",\"y7\",\"x8\",\"y8\",\"x9\",\"y9\")\n\npathLoad=\"Exp2_Classification\"\nloadPattern=\"*.txt\"\npathString=paste(pathLoad,\"/Data/\",sep=\"\")\nmFiles &lt;- list.files(path=\"Exp2_Classification/Data/\",pattern = loadPattern, recursive = FALSE) # should be 89 in exp 2\nnFiles=length(mFiles)\n\ndCat &lt;- data.frame(matrix(ncol=27,nrow=0)) %&gt;% purrr::set_names(col.names)\n\nfor (i in 1:nFiles){\n  ps=paste(pathString,mFiles[i],sep=\"\")\n  sbj = readr::parse_number(mFiles[i])\n  ind1=regexpr(\"y\",mFiles[i])\n  ind2=regexpr(sbj,mFiles[i])\n  d.load=read.table(ps) %&gt;% set_names(col.names) %&gt;% mutate(file=mFiles[i],condit=substr(file,ind1+1,ind2-1),sbjCode=as.factor(sbj))\n  dCat=rbind(dCat,d.load)\n}\n\n\ndCat &lt;- dCat %&gt;% group_by(sbjCode,condit,file) %&gt;% mutate(ind=1,trial=cumsum(ind),id=paste0(sbjCode,\".\",condit))  %&gt;%\n  group_by(sbjCode,condit,Phase) %&gt;%\n  mutate(nPhase=n(),phaseAvg=sum(Corr)/nPhase,\n         Pattern.Type=recode_factor(Pattern,`1` = 'Trained.Med', `2` = 'Prototype',  `3` = 'New.Low', `4` = 'New.Med',`5` = 'New.High'),\n         Stage=car::recode(trial, \"1:75='Start'; 76:150='Med'; 151:225='End';226:288='Test';else='Junk'\"),\n         Phase2=car::recode(trial, \"1:225='Training'; 226:288='Transfer';else='Junk'\"),\n         id=as.factor(id),condit=as.factor(condit)) %&gt;% relocate(id,condit,.before=Phase)%&gt;%\n  relocate(id,trial,Phase,Phase2,Stage,Block,BlockTrial,Pattern.Type,Category,Corr,rt,phaseAvg,Pattern,Pattern.Token,Response,.after=\"condit\") %&gt;% arrange(condit,sbj) %&gt;% as.data.frame()\n\nWarning: There were 356 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `Stage = car::recode(trial, \"1:75='Start'; 76:150='Med';\n  151:225='End';226:288='Test';else='Junk'\")`.\nℹ In group 1: `sbjCode = 1`, `condit = \"nrep\"`, `Phase = 1`.\nCaused by warning in `car::recode()`:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 355 remaining warnings.\n\ndCat &lt;- dCat %&gt;% group_by(sbjCode,Pattern.Type) %&gt;% mutate(patN=cumsum(ind)) %&gt;%\n  group_by(sbjCode,Pattern.Type,Category) %&gt;% mutate(patCatN=cumsum(ind),typeCount=paste0(Pattern.Type,\".\",patCatN)) %&gt;% \n  relocate(typeCount,.after=\"Pattern.Type\") \n\ndCat$Block = ifelse(dCat$Phase==2,16,dCat$Block)\ndCat$Stage = factor(dCat$Stage,levels=c(\"Start\",\"Med\",\"End\",\"Test\")) \n\n\ndCat$Pattern.Type = factor(dCat$Pattern.Type,levels=c(\"Trained.Med\",\"Prototype\",\"New.Low\",\"New.Med\",\"New.High\")) \ndCat$Pattern.Type2 &lt;- ifelse(dCat$Phase==1,\"Training\",dCat$Pattern.Type)\ndCat$Pattern.Type2=recode_factor(dCat$Pattern.Type2,\"Training\"=\"End.Training\",`1` = 'Trained.Med', `2` = 'Prototype',  `3` = 'New.Low', `4` = 'New.Med',`5` = 'New.High')\ndCat$Pattern.Type2 = factor(dCat$Pattern.Type2,levels=c(\"End.Training\",\"Trained.Med\",\"Prototype\",\"New.Low\",\"New.Med\",\"New.High\")) \ndCat$Condition = factor(dCat$condit,levels=c(\"rep\",\"nrep\"))\ndCat$Phase2 = factor(dCat$Phase2,levels=c(\"Training\",\"Transfer\"))\n\n\ndCatTrain &lt;- dCat %&gt;% filter(Phase==1)%&gt;% relocate(sbjCode,condit,file) %&gt;% group_by(id) %&gt;%\n   relocate(trial,phaseAvg,.after=\"condit\") %&gt;% arrange(condit,sbj) %&gt;% mutate(Category=as.factor(Category))\n\n\ndCatTrainAvg=dCatTrain  %&gt;% group_by(id,condit,Condition,Block) %&gt;% \n  summarise(nCorr=sum(Corr),propCor=nCorr/15,rtMean=mean(rt),phaseAvg=mean(phaseAvg),nTrain=max(nPhase)) %&gt;% ungroup() %&gt;% group_by(condit) %&gt;%\n  mutate(grpRank=factor(rank(-phaseAvg)),id=factor(id)) %&gt;% arrange(-phaseAvg) %&gt;% as.data.frame()\n\n`summarise()` has grouped output by 'id', 'condit', 'Condition'. You can\noverride using the `.groups` argument.\n\ndCatTrainAvg$id &lt;-factor(dCatTrainAvg$id,levels=unique(dCatTrainAvg$id))\n\ndCatTrainAvg2=dCatTrain  %&gt;% group_by(id,condit,Condition,Category,Block) %&gt;% \n  summarise(nCorr=sum(Corr),propCor=nCorr/5,rtMean=mean(rt),phaseAvg=mean(phaseAvg),nTrain=max(nPhase)) %&gt;% ungroup() %&gt;% group_by(condit) %&gt;%\n  mutate(grpRank=factor(rank(-phaseAvg)),id=factor(id)) %&gt;% arrange(-phaseAvg) %&gt;% as.data.frame()\n\n`summarise()` has grouped output by 'id', 'condit', 'Condition', 'Category'.\nYou can override using the `.groups` argument.\n\ndCatTrainAvg2$id &lt;-factor(dCatTrainAvg2$id,levels=unique(dCatTrainAvg2$id))\n\n\ndCatAvg &lt;- dCat %&gt;% group_by(id,condit,Condition,Stage,Pattern.Type) %&gt;% \n  dplyr::summarise(nPatStage=n(),nCorr=sum(Corr),propCor=nCorr/nPatStage,rt=mean(rt)) %&gt;% ungroup() \n\n`summarise()` has grouped output by 'id', 'condit', 'Condition', 'Stage'. You\ncan override using the `.groups` argument.\n\ndCatAvg$id &lt;-factor(dCatAvg$id,levels=unique(dCatTrainAvg2$id))\n\n\n\ndCatAvg2 &lt;- dCat %&gt;% filter(trial&gt;=151) %&gt;% group_by(id,condit,Condition,Pattern.Type2,Category) %&gt;% \n  dplyr::summarise(nPatStage=n(),nCorr=sum(Corr),propCor=nCorr/nPatStage,rt=mean(rt)) %&gt;% ungroup() \n\n`summarise()` has grouped output by 'id', 'condit', 'Condition',\n'Pattern.Type2'. You can override using the `.groups` argument.\n\ndCatAvg2$id &lt;-factor(dCatAvg2$id,levels=unique(dCatTrainAvg2$id))\n\n\ndCatAvg3 &lt;- dCatAvg2 %&gt;% group_by(id,condit,Pattern.Type2) %&gt;% \n  dplyr::summarise(propCor=mean(propCor)) %&gt;% ungroup() \n\n`summarise()` has grouped output by 'id', 'condit'. You can override using the\n`.groups` argument.\n\nsbjTrainAvg &lt;- dCatTrainAvg %&gt;% filter(Block&gt;12) %&gt;% \n  group_by(id,condit,Condition) %&gt;% summarise(endTrain=mean(propCor)) %&gt;% ungroup() %&gt;% as.data.frame() %&gt;% group_by(condit,Condition) %&gt;% \n  mutate(conditRank=rank(-endTrain),cq=factor(ntile(endTrain,2))) \n\n`summarise()` has grouped output by 'id', 'condit'. You can override using the\n`.groups` argument.\n\nsbjTrainAvg$cq=recode_factor(sbjTrainAvg$cq,`1` = 'low-Performers', `2` = 'High-Performers')\n\n\n\n\n\n\n# dCatBlockAvg &lt;- dCat %&gt;% group_by(id,condit,Block,Pattern.Type) %&gt;% \n#   summarise(nCorr=sum(Corr),propCor=nCorr/15,rtMean=mean(rt),phaseAvg=mean(phaseAvg)) %&gt;% ungroup() %&gt;% group_by(condit) %&gt;%\n#   mutate(grpRank=factor(rank(-phaseAvg)),id=factor(id)) %&gt;% arrange(-phaseAvg) %&gt;% as.data.frame()\n# dCatAvg$id &lt;-factor(dCatAvg$id,levels=unique(dCatAvg$id))\n\n\n\n# dCatAvg=dCatTrain  %&gt;% group_by(condit,Block) %&gt;%\n#   mutate(group.nCorr=sum(Corr),group.propCor=group.nCorr/15,grp.sd=sd(group.nCorr)) %&gt;% group_by(sbjCode,id,condit,Block) %&gt;% \n#   summarise(nCorr=sum(Corr),propCor=nCorr/15,rtMean=mean(rt),zProp=propCor-(group.propCor*grp.sd),group.nCorr=mean(group.nCorr),\n#             group.propCor=mean(group.propCor),grp.sd=mean(grp.sd))\n\n\n# \n# dCatAvg=dCatTrain %&gt;% group_by(sbjCode,id,condit,Block) %&gt;% \n#   summarise(nCorr=sum(Corr),propCor=nCorr/15,rtMean=mean(rt),trainAvg=mean(trainAvg)) %&gt;% ungroup() %&gt;% group_by(sbjCode,id,condit) %&gt;%\n#   mutate(sbjAvg=mean(propCor)) %&gt;% group_by(condit) %&gt;% mutate(grpRank=rank(sbjAvg)) %&gt;% arrange(grpRank)\n\n# dCatAvg %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+stat_summary(geom=\"point\",fun=\"mean\")+stat_summary(geom=\"line\",fun=\"mean\")\n\n\n\n\n\n\n\n\n\n\n\n# We started by conducting preliminary analyses to remove severe outlier subjects. \n# For the learning phase, the performance measure used for identifying outliers was the \n# same as in Experi- ment 1. For the classification-transfer phase, we measured average\n# accuracy computed across all 63 transfer trials. We again removed the data of any \n# subject who performed more than 2.5 standard deviations below the mean in each condition \n# on either measure. We removed four subjects from the REP condition (leaving 39 valid subjects)\n# and two subjects from the NREP condition (leaving 44 valid subjects).\n\n\n\n\n\n\n\n# \n# Data variable order, from left to right:\n#   \n# 1. Phase type (1 = Training, 2 = Transfer)\n# 2. Block number (1-15 training, 1 transfer)\n# 3. Trial number (1-15 training, 1-39 transfer)\n# 4. Pattern type (1 = old medium, 2 = prototype, 4 = new medium, 6 = Foil)\n# 5. Category number (1-3)\n# 6. Pattern token* \n# 7. Category/Recognition response (1-3 category training; 1 = old 2 = new recognition transfer)\n# 8. Correct/Incorrect (0 = Incorrect, 1 = Correct)\n# 9. Reaction time (in milliseconds)\n# 10-27.Coordinates of nine dots* (-25 through 24)\n# *Pattern token: index of unique tokens for each category of each type of pattern. The numbering of old medium patterns differs across the two conditions.\n# *Coordinates of nine dots: every two columns represent the x and y coordinates of a dot on a 50 x 50 grid\n\n# file names starting with \"polyrep\" contain data from repeating condtion.\n# file names starting with \"polynrep\" contain data from non-repeating condtion.\n\n\n\n\n# pathLoad=\"Exp1_Recognition\"\n# loadPattern=\"*.txt\"\n# pathString=paste(pathLoad,\"/Data/\",sep=\"\")\n# mFiles &lt;- list.files(path=\"Exp1_Recognition/Data/\",pattern = loadPattern, recursive = FALSE) # should be 198 in exp1\n# nFiles=length(mFiles)\n# \n# dRec &lt;- data.frame(matrix(ncol=27,nrow=0)) %&gt;% purrr::set_colnames(col.names)\n# \n# for (i in 1:nFiles){\n#   ps=paste(pathString,mFiles[i],sep=\"\")\n#   sbj = readr::parse_number(mFiles[i])\n#   ind1=regexpr(\"y\",mFiles[i])\n#   ind2=regexpr(sbj,mFiles[i])\n#   d.load=read.table(ps) %&gt;% set_names(col.names) %&gt;% mutate(file=mFiles[i],condit=substr(file,ind1+1,ind2-1),sbjCode=as.factor(sbj))\n#   dRec=rbind(dRec,d.load)\n# }\n# \n# dRec &lt;- dRec %&gt;% relocate(sbjCode,condit,file) %&gt;% group_by(sbjCode) %&gt;%\n#   mutate(nTrain=n(),ind=1,trial=cumsum(ind),id=paste0(sbjCode,\".\",condit),trainAvg=sum(Corr)/nTrain) %&gt;% relocate(trial,.after=\"condit\") %&gt;% arrange(condit,sbj)\n\n\n\n\n# we conducted preliminary analyses to identify severe outlier sub- jects within each condition. \n# In the learning phase, we computed mean proportion correct for each subject during \n# the final eight blocks. In the transfer phase, we computed the difference between mean \n# proportion of old judgments on the old learning patterns and the foils. We removed from \n# all subsequently reported analyses the data of any subject who performed more than 2.5 \n# standard deviations below the mean on either measure. We removed seven subjects from \n# the REP condition (leaving 91 valid subjects) and five subjects from the NREP \n# condition (leaving 95 valid subjects).\n\n#library(forcats)\n\n# dRecAvg=dRec %&gt;% filter(Phase==1) %&gt;% group_by(sbjCode,id,condit,Block) %&gt;% \n#   summarise(nCorr=sum(Corr),propCor=nCorr/15,rtMean=mean(rt),trainAvg=mean(trainAvg)) %&gt;% ungroup() %&gt;% group_by(condit) %&gt;%\n#   mutate(sbjAvg=mean(propCor)) %&gt;% \n#   mutate(grpRank=factor(rank(-trainAvg)),id=factor(id)) %&gt;% arrange(-trainAvg) %&gt;% as.data.frame()\n# \n# dRecAvg$id &lt;-factor(dRecAvg$id,levels=unique(dRecAvg$id))\n# \n# dRecAvg %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+stat_summary(geom=\"point\",fun=\"mean\")+stat_summary(geom=\"line\",fun=\"mean\")\n# dRecAvg %&gt;% ggplot(aes(x=Block,y=rtMean,col=condit))+stat_summary(geom=\"point\",fun=\"mean\")+stat_summary(geom=\"line\",fun=\"mean\")\n# dRecAvg %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+\n#   stat_summary(geom=\"point\",fun=\"mean\")+stat_summary(geom=\"line\",fun=\"mean\")+facet_wrap(~sbjCode)"
  },
  {
    "objectID": "plotDots.html",
    "href": "plotDots.html",
    "title": "Dot Pattern Plots",
    "section": "",
    "text": "Codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\nsource(\"read_22.R\")\n\n\n\nCodedot &lt;- dCat %&gt;% ungroup() %&gt;% filter(id==\"1.nrep\",(Pattern.Type==\"Prototype\" | Pattern.Type==\"New-Low\"))%&gt;%  select(typeCount,Category,x1,y1,x2,y2,x3,y3,x4,y4,x5,y5,x6,y6,x7,y7,x8,y8,x9,y9) \nnTrial=nrow(dot);\ndotx=c(dot$x1,dot$x2,dot$x3,dot$x4,dot$x5,dot$x6,dot$x7,dot$x8,dot$x9); doty=c(dot$y1,dot$y2,dot$y3,dot$y4,dot$y5,dot$y6,dot$y7,dot$y8,dot$y9)\ndotFrame &lt;- data.frame(typeCount=rep(dot$typeCount,each=9),Trial=rep(seq(1:nTrial),each=9),Category=factor(rep(dot$Category,each=9)),x=dotx,y=doty)\npg &lt;- ggplot(dotFrame,aes(dotx,doty,col=Category))+geom_point()+facet_grid(typeCount~Category)\n\npg"
  },
  {
    "objectID": "dp_22.html",
    "href": "dp_22.html",
    "title": "Hu & Nosofsky 2022",
    "section": "",
    "text": "Codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted, viridis, gghalves)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\nsource(\"read_22.R\")\n\ntheme_set(theme_bw())\n\ndcp &lt;- merge(dCatAvg2,sbjTrainAvg,by=c(\"id\",\"condit\",\"Condition\"))\n\n\ndc &lt;- dCatAvg2 %&gt;% select(id,condit,Condition,Pattern.Type2,Category,propCor) %&gt;% \n  pivot_wider(names_from = \"Pattern.Type2\",values_from = \"propCor\") %&gt;%\n  mutate(EndTrain.Minus.HighDistort= End.Training-New.High,\n         MedDistort.Minus.HighDistort=New.Med-New.High,\n         LowDistort.Minus.HighDistort=New.Low-New.High,\n         TrainedItem.Minus.HighDistort=Trained.Med-New.High,\n         Prototype.Minus.HighDistort=Prototype-New.High) \n\ndc &lt;- merge(dc,sbjTrainAvg,by=c(\"id\",\"condit\",\"Condition\"))\ndc2 &lt;- dc %&gt;% group_by(id,condit,Condition,cq) %&gt;% summarise(End.Training=mean(End.Training),New.High=mean(New.High)) %&gt;% as.data.frame()"
  },
  {
    "objectID": "dp_22.html#testing---splitting-peformance-by-end-of-training",
    "href": "dp_22.html#testing---splitting-peformance-by-end-of-training",
    "title": "Hu & Nosofsky 2022",
    "section": "Testing - Splitting Peformance by End of Training",
    "text": "Testing - Splitting Peformance by End of Training\n\nCodelibrary(gghalves)\n\nps &lt;- dcp  %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~cq)+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n  xlab(\"Pattern-Type\")+ylab(\"Proportion Correct\")+ggtitle(\"Low vs High Performers (median split within condition - final training block) - Performance x Pattern Type\")\n\nhd&lt;- dcp  %&gt;% filter(Pattern.Type2==\"New-High\")%&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  geom_boxplot(outlier.shape=NA)+geom_jitter(alpha=.5)+facet_wrap(~cq)+xlab(\"Pattern-Type\")+\n  ggtitle(\"Low vs High Performers (median split within condition) - High Distortion Performance\")+ylab(\"Proportion Correct\")\n\n\n# dcp  %&gt;% filter(Pattern.Type2==\"New-High\") %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n#   geom_half_violin()+\n#   geom_jitter(alpha=.5)+\n#   facet_wrap(~cq)+ggtitle(\"Low vs High Performers (median split within condition) - High Distortion Performance\")\n\n#ps\n#gridExtra::grid.arrange(ps,hd)\n\n\np7&lt;- dcp  %&gt;% filter(endTrain&gt;.75) %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n  xlab(\"Pattern-Type\")+ylab(\"Proportion Correct\")+ggtitle(\"Performance x Pattern Type - Only retaining sbjs with &gt;75% accuracy in final training block\")\n\np5 &lt;-  dcp  %&gt;% filter(endTrain&gt;.50) %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n  xlab(\"Pattern-Type\")+ylab(\"Proportion Correct\")+ggtitle(\"Performance x Pattern Type - Only retaining sbjs with &gt;50% accuracy in final training block\")\n\n\ngridExtra::grid.arrange(ps,p7,p5)\n\n\n\n\n\n\nCode# dCatAvg2  %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~cq)+\n#   stat_summary(geom=\"point\")\n#    geom_hline(yintercept = .33,linetype=\"dashed\")+\n#  ggtitle(\"\")+ylab(\"Proportion Correct\")\n\n# dCatAvg2 %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Pattern.Type2))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~condit)+\n#    geom_hline(yintercept = .33,linetype=\"dashed\")+\n#  ggtitle(\"\")+ylab(\"Proportion Correct\")\n# \n# \n# dCatAvg3 %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Pattern.Type2))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~condit)+\n#    geom_hline(yintercept = .33,linetype=\"dashed\")+\n#  ggtitle(\"\")+ylab(\"Proportion Correct\")"
  },
  {
    "objectID": "dp_22.html#controlling-for-end-of-training-performace",
    "href": "dp_22.html#controlling-for-end-of-training-performace",
    "title": "Hu & Nosofsky 2022",
    "section": "Controlling for End of Training Performace",
    "text": "Controlling for End of Training Performace\n\nCodelibrary(rstatix)\nlibrary(ggpubr)\nlibrary(emmeans)\nlibrary(cowplot)\n\n\n# dc2 %&gt;% filter() %&gt;% ggplot(aes(x=End.Training,y=New.High,color=condit))+geom_point()+geom_smooth(method=\"lm\")\n# dc2 %&gt;% filter(End.Training&gt;.33, New.High&gt;.33) %&gt;% ggplot(aes(x=End.Training,y=New.High,color=condit))+geom_point()+geom_smooth(method=\"lm\")\n\n(at1 &lt;- dc2 %&gt;% anova_test(dv=New.High,between=Condition,covariate = End.Training,wid=id,type=3))\n\nANOVA Table (type III tests)\n\n        Effect DFn DFd       F        p p&lt;.05   ges\n1 End.Training   1  86 128.607 9.21e-19     * 0.599\n2    Condition   1  86  12.249 7.40e-04     * 0.125\n\nCode(at2 &lt;- dc2 %&gt;% filter(End.Training&gt;.33) %&gt;% anova_test(dv=New.High,between=Condition,covariate = End.Training,wid=id,type=3))\n\nANOVA Table (type III tests)\n\n        Effect DFn DFd       F        p p&lt;.05   ges\n1 End.Training   1  84 103.961 2.36e-16     * 0.553\n2    Condition   1  84  12.573 6.43e-04     * 0.130\n\nCode(at3 &lt;- dc2 %&gt;% filter(End.Training&gt;.88) %&gt;% anova_test(dv=New.High,between=Condition,covariate = End.Training,wid=id,type=3))\n\nANOVA Table (type III tests)\n\n        Effect DFn DFd      F        p p&lt;.05   ges\n1 End.Training   1  49 13.847 0.000511     * 0.220\n2    Condition   1  49 13.131 0.000689     * 0.211\n\nCode#dc2 %&gt;% anova_test(New.High ~condit*End.Training) # no sig. interaction\npwc1 &lt;- dc2 %&gt;% emmeans_test(New.High ~ Condition,covariate=End.Training,p.adjust.method=\"bonferroni\")%&gt;% add_xy_position(x = \"condit\", fun = \"mean_se\")\nget_emmeans(pwc1)\n\n# A tibble: 2 × 8\n  End.Training Condition emmean     se    df conf.low conf.high method      \n         &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       \n1        0.830 rep        0.673 0.0198    86    0.634     0.713 Emmeans test\n2        0.830 nrep       0.772 0.0191    86    0.734     0.810 Emmeans test\n\nCodepwc2 &lt;- dc2 %&gt;% filter(End.Training&gt;.33) %&gt;% emmeans_test(New.High ~ Condition,covariate=End.Training,p.adjust.method=\"bonferroni\")%&gt;% add_xy_position(x = \"condit\", fun = \"mean_se\")\npwc3 &lt;- dc2 %&gt;% filter(End.Training&gt;.88) %&gt;% emmeans_test(New.High ~ Condition,covariate=End.Training,p.adjust.method=\"bonferroni\")%&gt;% add_xy_position(x = \"condit\", fun = \"mean_se\")\n\n\n\nep1&lt;-ggline(get_emmeans(pwc1), x = \"Condition\", y = \"emmean\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + \n  stat_pvalue_manual(pwc1, hide.ns = TRUE, tip.length = FALSE) +\n  labs(subtitle = get_test_label(at1, detailed = TRUE),caption = get_pwc_label(pwc1),title=\"Estimated Marginal Means from ANCOVA - All Sbj. (n=89)\" )\n\nep2&lt;-ggline(get_emmeans(pwc2), x = \"Condition\", y = \"emmean\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + \n  stat_pvalue_manual(pwc2, hide.ns = TRUE, tip.length = FALSE) +\n  labs(subtitle = get_test_label(at2, detailed = TRUE),caption = get_pwc_label(pwc2), title= \"Estimated Marginal Means from ANCOVA - Only above chance sbj (&gt;.33,n=87)\")\n\nep3&lt;-ggline(get_emmeans(pwc3), x = \"Condition\", y = \"emmean\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + \n  stat_pvalue_manual(pwc3, hide.ns = TRUE, tip.length = FALSE) +\n  labs(subtitle = get_test_label(at3, detailed = TRUE),caption = get_pwc_label(pwc3), title= \"Estimated Marginal Means from ANCOVA - Only strong learners (&gt;.88; n=52)\")\n\n\n\ngg.ac1 &lt;- ggscatter(dc2,x=\"End.Training\",y=\"New.High\",color=\"Condition\",add=\"reg.line\",add.params = list(size=.3))+\n  stat_regline_equation(aes(label=paste(..eq.label.., ..rr.label..,sep=\"~~~~\"),color=Condition))+\n  ggtitle(\"Including All Subjects (n=89)\")+ylab(\"High Distortions - Proportion Correct\")+xlab(\"End of Training - Proportion Correct\")\n\ngg.ac2 &lt;- dc2 %&gt;% filter(End.Training&gt;.33) %&gt;% ggscatter(.,x=\"End.Training\",y=\"New.High\",color=\"Condition\",add=\"reg.line\",add.params = list(size=.3))+\n  stat_regline_equation(aes(label=paste(..eq.label.., ..rr.label..,sep=\"~~~~\"),color=Condition))+\n  ggtitle(\"Retain Sbj's above chance (&gt;.33) at train end (n=87). \")+ylab(\"High Distortions - Proportion Correct\")+xlab(\"End of Training - Proportion Correct\")\n\ngg.ac3 &lt;- dc2 %&gt;% filter(End.Training&gt;.88) %&gt;% ggscatter(.,x=\"End.Training\",y=\"New.High\",color=\"Condition\",add=\"reg.line\",add.params = list(size=.3))+\n  stat_regline_equation(aes(label=paste(..eq.label.., ..rr.label..,sep=\"~~~~\"),color=Condition))+\n  ggtitle(\"Retain only stronger learners (&gt;.88) at train end (n=52). \")+ylab(\"High Distortions - Proportion Correct\")+xlab(\"End of Training - Proportion Correct\")\n\n\n\ngtitle=\" Hu & Nosofsky 2020 - Experiment 2. Effect of Condition on High Distortions - Controlling for End of Training Performance\"\ntitle = ggdraw()+draw_label(gtitle,fontface = 'bold',x=0,hjust=0)+theme(plot.margin = margin(0, 0, 0, 7))\n\nplot_grid(title,NULL,gg.ac1,ep1,gg.ac2,ep2,gg.ac3,ep3,ncol=2,rel_heights=c(.1,1,1,1))"
  },
  {
    "objectID": "dp_22.html#individual-learning-curves",
    "href": "dp_22.html#individual-learning-curves",
    "title": "Hu & Nosofsky 2022",
    "section": "Individual Learning Curves",
    "text": "Individual Learning Curves\n\nCodedCatTrainAvg %&gt;% filter(condit==\"rep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+\n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Hu & Nosofsky Experiment 2 - Learning. Rep Subjects - Average Accuracy Per Block.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))\n\n\n\n\n\n\nCodedCatTrainAvg %&gt;% filter(condit==\"nrep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+\n  stat_summary(shape=2, geom=\"point\",fun=\"mean\",col=\"lightblue\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"lightblue\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  facet_wrap(~id)+ggtitle(\"Hu & Nosofsky Experiment 2 - Learning. NRep Subjects - Average Accuracy Per Block.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))"
  },
  {
    "objectID": "dp_22.html#experiment-2---separate-category---learning-curves",
    "href": "dp_22.html#experiment-2---separate-category---learning-curves",
    "title": "Hu & Nosofsky 2022",
    "section": "Experiment 2 - separate category - learning curves",
    "text": "Experiment 2 - separate category - learning curves\n\nCodedCatTrainAvg2 %&gt;% filter(condit==\"rep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=Category,shape=Category))+\n  stat_summary(geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Hu & Nosofsky Experiment 2 - Learning Curves. Rep Subjects - Separated Categories.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))\n\n\n\n\n\n\nCodedCatTrainAvg2 %&gt;% filter(condit==\"nrep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=Category,shape=Category))+\n  stat_summary(geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  facet_wrap(~id)+ggtitle(\"Hu & Nosofsky Experiment 2 - Learning Curves. NRep Subjects - Separated Categories.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))"
  },
  {
    "objectID": "dp_22.html#experiment-2---3-training-stages-transfer-patterns",
    "href": "dp_22.html#experiment-2---3-training-stages-transfer-patterns",
    "title": "Hu & Nosofsky 2022",
    "section": "Experiment 2 - 3 Training Stages + Transfer Patterns",
    "text": "Experiment 2 - 3 Training Stages + Transfer Patterns\n\nCodedCatAvg %&gt;% filter(condit==\"rep\") %&gt;% ggplot(aes(x=Stage,y=propCor,fill=Pattern.Type))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~id)+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n ggtitle(\"REP - 3 training bins (75 trials each) + Transfer Patterns\")+ylab(\"Proportion Correct\")\n\n\n\n\n\n\nCodedCatAvg %&gt;% filter(condit==\"nrep\") %&gt;% ggplot(aes(x=Stage,y=propCor,fill=Pattern.Type))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~id)+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n ggtitle(\"NREP - 3 training bins (75 trials each) + Transfer Patterns\")+ylab(\"Proportion Correct\")\n\n\n\n\n\n\nCode# \n# dCatAvg %&gt;% filter() %&gt;% ggplot(aes(x=Stage,y=propCor,fill=Pattern.Type))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~condit)+ggtitle(\"nrep\")\n# \n# dCatAvg %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type,y=propCor,fill=condit))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~Stage)+ggtitle(\"\")\n# \n# dCatAvg %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type,y=propCor,col=condit))+\n#   geom_boxplot(position=position_dodge())+facet_wrap(~Stage)"
  },
  {
    "objectID": "dp_24.html",
    "href": "dp_24.html",
    "title": "Hu & Nosofsky 2024",
    "section": "",
    "text": "Codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted, knitr,grateful)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\nsource(\"read_24.R\")\n\n#https://fonts.google.com/specimen/Manrope\n# ~/Library/Fonts\ntheme_nice &lt;- function() {\n  theme_minimal(base_family = \"Manrope\") +\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.title = element_text(family = \"Manrope Extrabold\", face = \"plain\", size = rel(1.35)),\n      plot.subtitle = element_text(family = \"Manrope Medium\", face = \"plain\", size = rel(1.2)),\n      axis.title = element_text(family = \"Manrope SemiBold\", face = \"plain\", size = rel(1)),\n      axis.title.x = element_text(hjust = .5),\n      axis.title.y = element_text(hjust = .5),\n      axis.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(0.8)),\n      strip.text = element_text(\n        family = \"Manrope\", face = \"bold\",\n        size = rel(.75), hjust = 0\n      ),\n      strip.background = element_rect(fill = \"grey90\", color = NA)\n    )\n}\n\ntheme_nice_dist &lt;- function() {\n  theme_nice() +\n    theme(\n      panel.grid = element_blank(),\n      panel.spacing.x = unit(10, units = \"pt\"),\n      axis.ticks.x = element_line(linewidth = 0.25),\n      axis.text.y = element_blank()\n    )\n}\n\ntheme_set(theme_nice())"
  },
  {
    "objectID": "dp_24.html#filter-to-only-include-sbjs.-who-learned-during-training",
    "href": "dp_24.html#filter-to-only-include-sbjs.-who-learned-during-training",
    "title": "Hu & Nosofsky 2024",
    "section": "Filter to only include sbjs. who learned during training",
    "text": "Filter to only include sbjs. who learned during training\n\nCode# dCat |&gt; filter(Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\n# dCat |&gt; filter(finalTrain&gt;.33, Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\n# dCat |&gt; filter(finalTrain&gt;.66, Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\n# dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\ndCat |&gt; \n  filter(Phase == 2) |&gt; \n  group_by(condit) |&gt; \n  summarise(\n    `All Sbjs.` = n_distinct(sbjCode),\n    `&gt;.33` = n_distinct(sbjCode[finalTrain &gt; .35]),\n    `&gt;.50` = n_distinct(sbjCode[finalTrain &gt; .50]),\n    `&gt;.70` = n_distinct(sbjCode[finalTrain &gt; .70])\n  ) |&gt; kable()\n\n\nSubject Counts for each filtering level. Note that the training conditions are disproporionately impacted.\n\ncondit\nAll Sbjs.\n&gt;.33\n&gt;.50\n&gt;.70\n\n\n\nlow\n77\n77\n75\n73\n\n\nmedium\n78\n75\n63\n42\n\n\nmixed\n74\n67\n57\n42\n\n\nhigh\n75\n56\n35\n17\n\n\n\n\n\nIn the full data-set, the high distortion group has the worst performance for all testing patterns, and the low distortion group has performance either better or equal to all other training groups. However if we only include participants who exceeded 50%, or 70% accuracy during training - the patterns become a bit more complex. Considering the new_high distortion testing items, the groups that experienced more training variability now either match or outperform the low distortion group. The effect of filtering out the weaker learners does not influence the ordering of performance for the old items (i.e. The low distortion group remains the best, and the high distortion group remains the worst).\n\n\nMatch # of learners\nGroup by Condition\nGroup by Pattern\n\n\n\n\nCodetrainRanks &lt;- dCat |&gt; group_by(sbjCode,condit) |&gt; \n  select(finalTrain) |&gt; slice(1) |&gt; arrange(-finalTrain)\n\ntop17 &lt;- trainRanks |&gt; group_by(condit) |&gt; slice(1:17)\ntop35 &lt;- trainRanks |&gt; group_by(condit) |&gt; slice(1:35)\ntop56 &lt;- trainRanks |&gt; group_by(condit) |&gt; slice(1:56)\nlow &lt;- trainRanks |&gt; filter(!(sbjCode %in% top56$sbjCode)) \n\n\n#top17 |&gt; gt::gt()\n\nt17 &lt;- dCat |&gt; filter(sbjCode %in% top17$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing - top 17 Sbjs.\", y=\"Accuracy\") \n\n\nt35 &lt;- dCat |&gt; filter(sbjCode %in% top35$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing - top 35 Sbjs.\", y=\"Accuracy\") \n\nt56 &lt;- dCat |&gt; filter(sbjCode %in% top56$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing - top 56 Sbjs.\", y=\"Accuracy\") \n\ntLow56 &lt;- dCat |&gt; filter(sbjCode %in% low$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) + \n  labs(title=\"Testing - lowest Sbjs (all sbj. NOT in top 56)\", y=\"Accuracy\")\n\n\ntLow35 &lt;- dCat |&gt; filter(!(sbjCode %in% (trainRanks |&gt; group_by(condit) |&gt; slice(1:35))$sbjCode)) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) + \n  labs(title=\"Testing - subjects NOT in top 35\", y=\"Accuracy\")\n\ntLow17 &lt;- dCat |&gt; filter(!(sbjCode %in% (trainRanks |&gt; group_by(condit) |&gt; slice(1:17))$sbjCode)) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) + \n  labs(title=\"Testing - subjects NOT in top 17\", y=\"Accuracy\")\n\n\n\n(t17+tLow17) /(t35+tLow35)/(t56+tLow56) + \n  plot_annotation(title=\"Test Accuracy - matching # of subjects\", \n                  caption=\" Only the top 17; top 35; top 56; or lowest performing subjects included. Rankings based on final training accuracy\")\n\n\n\ntest_strong_learners- top\n\n\nCode# (t17+t35) /(t56+tLow) + \n#   plot_annotation(title=\"Test Accuracy - matching # of subjects\", \n#                   caption=\" Only the top 17; top 35; top 56; or lowest performing subjects included. Rankings based on final training accuracy\")\n\n\n\n\n\nCodetAll &lt;- dCat |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \n\nt33 &lt;- dCat |&gt; filter(finalTrain&gt;.35, Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 35%\", y=\"Accuracy\") \n\nt66 &lt;- dCat |&gt; filter(finalTrain&gt;.50, Phase==2) |&gt;\n  group_by(sbjCode, condit,Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 50%\", y=\"Accuracy\") \n\nt80 &lt;- dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt;\n  group_by(sbjCode, condit,  Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 70%\", y=\"Accuracy\") \n\n((tAll + t33)/(t66 + t80)) + \n  plot_annotation(title=\"Test Accuracy - Influence of filtering out weak/non learers\", \n                  caption=\" % values indicate level of final training performance needed to be included. Note that the training conditions are disproporionately impacted by exclusions.\")\n\n\n\ntest_strong_learners\n\n\n\n\n\n\nCodetAll &lt;- dCat |&gt; filter(Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \n\nt33 &lt;- dCat |&gt; filter(finalTrain&gt;.35, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 35%\", y=\"Accuracy\") \n\nt66 &lt;- dCat |&gt; filter(finalTrain&gt;.50, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 50%\", y=\"Accuracy\") \n\nt80 &lt;- dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 70%\", y=\"Accuracy\") \n\n((tAll + t33)/(t66 + t80))\n\n\n\ntest_strong_learners2"
  },
  {
    "objectID": "dp_24.html#split-by-quartiles-end-of-training-performance",
    "href": "dp_24.html#split-by-quartiles-end-of-training-performance",
    "title": "Hu & Nosofsky 2024",
    "section": "Split by Quartiles (end of training performance)",
    "text": "Split by Quartiles (end of training performance)\nWe can also inspect testing performance by splitting the data into quartiles based on the final training performance. This avoids the issue of excluding subjects, but increases the disparity in training performance between groups (i.e. the worst quartile of high distortion sbjs. had much worse training performance than the worst quartile of low distortion sbjs.)\n\n\nGroup by Condit\nQuartile - Group by Pattern\nQuartile_Boxplots\n\n\n\n\nCodetx1 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank())\ntx2 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank(),legend.position = \"none\" )\nyt &lt;- round(seq(0,1,length.out=7), 2)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),scale_y_continuous(breaks=yt))\n\n\ndq1 &lt;- dCat |&gt; filter(Phase==2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit)) +\n  stat_summary(geom=\"bar\",fun=\"mean\", position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge(), width=.9) +\n  eg + labs(x=\"Pattern Token\", y=\"Proportion Correct\", title=\"Testing Accuracy Overall Averages\", \n            fill=\"Training Condition\") \n  \ndq2 &lt;-dCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = Pattern_Token, y = Corr, fill = condit)) +\n  stat_summary(geom = \"bar\", fun = \"mean\", position = position_dodge()) +\n  stat_summary(geom = \"errorbar\", fun.data = mean_se, position = position_dodge(width = 0.9), width = 0.25) +\n  facet_wrap(~quartile) +\n  labs(x = \"Pattern Token\", y = \"Proportion Correct\", title = \"Testing Accuracy by End-Training Quartile\", \n       subtitle=\"Quartiles are based on the final training performance of each subject\", \n       fill=\"Training Condition\") \n  \ndq1/dq2\n\n\n\ntest_quartiles_condit\n\n\n\n\n\n\nCodetx1 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank())\ntx2 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank(),legend.position = \"none\" )\nyt &lt;- round(seq(0,1,length.out=7), 2)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),scale_y_continuous(breaks=yt))\n\n\ndq1 &lt;- dCat |&gt; filter(Phase==2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token)) +\n  stat_summary(geom=\"bar\",fun=\"mean\", position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge(), width=.9) +\n  eg + labs(x=\"Training Condition\", y=\"Proportion Correct\", title=\"Testing Accuracy Overall Averages\") \n  \ndq2 &lt;-dCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = condit, y = Corr, fill = Pattern_Token)) +\n  stat_summary(geom = \"bar\", fun = \"mean\", position = position_dodge()) +\n  stat_summary(geom = \"errorbar\", fun.data = mean_se, position = position_dodge(width = 0.9), width = 0.25) +\n  facet_wrap(~quartile) +\n  labs(x = \"Training Condition\", y = \"Proportion Correct\", title = \"Testing Accuracy by End-Training Quartile\", \n       subtitle=\"Quartiles are based on the final training performance of each subject\") \n  \ndq1/dq2\n\n\n\ntest_quartiles\n\n\n\n\n\n\nCodedCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = condit, y = Corr, fill = Pattern_Token)) +\n  geom_boxplot(position=position_dodge()) +\n  geom_jitter(position = position_jitterdodge(jitter.width = 0.25, dodge.width = 0.9), alpha = .2) +\n  labs(x = \"Training Condition\", y = \"Proportion Correct\", title = \"Testing Accuracy - All\")\n\n\n\ntest_quartiles_boxplots\n\n\nCodedCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = condit, y = Corr, fill = Pattern_Token)) +\n  geom_boxplot(position=position_dodge()) +\n  geom_jitter(position = position_jitterdodge(jitter.width = 0.25, dodge.width = 0.9), alpha = .2) +\n  facet_wrap(~quartile)\n\n\n\ntest_quartiles_boxplots\n\n\nCode  labs(x = \"Training Condition\", y = \"Proportion Correct\", title = \"Testing Accuracy - All\")\n\n$x\n[1] \"Training Condition\"\n\n$y\n[1] \"Proportion Correct\"\n\n$title\n[1] \"Testing Accuracy - All\"\n\nattr(,\"class\")\n[1] \"labels\""
  },
  {
    "objectID": "dp_24.html#testing-reaction-time",
    "href": "dp_24.html#testing-reaction-time",
    "title": "Hu & Nosofsky 2024",
    "section": "Testing Reaction Time",
    "text": "Testing Reaction Time\nWorth comparing the RT’s to the accuracy. In many cases the RT’s show the inverse pattern of accuracy, i.e. slower RT’s for less accurate patterns.But, the weakest quartile for the High and Medium distortion training conditions don’t follow this pattern.\n\n\nFacet by Training Condition\nGroup by Pattern\n\n\n\n\nCodetx1 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank())\ntx2 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank(),legend.position = \"none\" )\nrtfun &lt;- \"median\"\nyt &lt;- round(seq(0,1500,length.out=7), 2)\neg &lt;- list(scale_y_continuous(breaks=yt))\n\n\nhtq &lt;- dCat |&gt; filter(condit==\"high\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"High Training -  Test RT\", y=\"Reaction Time\") +tx2\n\nltq &lt;- dCat |&gt; filter(condit==\"low\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"Low Training -  Test RT\", y=\"Reaction Time\") +tx1\n\nmtq &lt;- dCat |&gt; filter(condit==\"medium\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"Medium Training -  Test RT\", y=\"Reaction Time\") +tx2\n\n\nmxtq &lt;- dCat |&gt; filter(condit==\"mixed\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"Mixed Training -  Test RT\", y=\"Reaction Time\")  + tx1\n  \n\n\n(htq+ltq)/(mtq+mxtq) + plot_annotation(\n  title = 'Testing Reaction Times by Quartile',\n  subtitle = 'Quartiles set by Final TRAINING block',\n  caption = 'bars reflect median reaction times. Quartiles are set by ACCURACY in the final training block. Bar colors are pattern type.'\n)\n\n\n\nReaction Times\n\n\n\n\n\n\nCodetAll &lt;- dCat |&gt; filter(Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing - All Sbjs.\", y=\"Reaction Time\", x=\"Training Condition\") + theme(legend.position = \"top\")\n\nt33 &lt;- dCat |&gt; filter(finalTrain&gt;.35, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing - Only greater than 35%\", y=\"Reaction Time\", x=\"Training Condition\")  + theme(legend.position = \"none\")\n\nt66 &lt;- dCat |&gt; filter(finalTrain&gt;.50, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing - Only greater than 50%\", y=\"Reaction Times\", x=\"Training Condition\") + theme(legend.position = \"none\")\n\nt80 &lt;- dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing- Only greater than 70%\", y=\"Reaction Times\", x=\"Training Condition\") + theme(legend.position = \"none\")\n((tAll + t33)/(t66 + t80)) + plot_annotation(\n  title = 'Testing Reaction Times by Training Accuracy',\n  subtitle = 'Filtering to retain subjects who achieved different performace levels during training',\n  caption = 'bars reflect median reaction times. Quartiles are set by ACCURACY in the final training block. Bar colors are pattern type.'\n)\n\n\n\n\n\n\n\n\n\n\n’"
  },
  {
    "objectID": "dp_24.html#individual-learning-curves",
    "href": "dp_24.html#individual-learning-curves",
    "title": "Hu & Nosofsky 2024",
    "section": "Individual Learning Curves",
    "text": "Individual Learning Curves\n\nfacets sorted by final training accuracy\nclick on plots to enlarge.\n\n\n\nHigh Distortion\nLow Distortion\nMedium Distortion\nMixed Distortion\n\n\n\n\nCodedCat |&gt; filter(condit==\"high\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"High Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves\n\n\n\n\n\n\nCodedCat |&gt; filter(condit==\"low\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Low Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves - Low\n\n\n\n\n\n\nCodedCat |&gt; filter(condit==\"medium\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Medium Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves - Low\n\n\n\n\n\n\nCodedCat |&gt; filter(condit==\"mixed\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Mixed Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves - Low"
  },
  {
    "objectID": "dp_24.html#individual-testing",
    "href": "dp_24.html#individual-testing",
    "title": "Hu & Nosofsky 2024",
    "section": "Individual Testing",
    "text": "Individual Testing\n\nfacets sorted by final training accuracy\nclick on plots to enlarge.\n\n\nCodetx &lt;- theme(axis.text.x=element_blank() )\n\ndht &lt;- dCat |&gt; filter(condit==\"high\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"High Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\") +\n  theme(legend.position = \"top\") + tx\n\ndlt &lt;- dCat |&gt; filter(condit==\"low\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"Low Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\")+\n  tx +theme(legend.position = \"none\")\n\ndmt &lt;- dCat |&gt; filter(condit==\"medium\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"Medium Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\") +\n  theme(legend.position = \"none\")+\n  tx +theme(legend.position = \"none\")\n\ndmxt &lt;- dCat |&gt; filter(condit==\"mixed\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"Mixed Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\")+\n  tx +theme(legend.position = \"none\")\n\n(dht + dlt)/(dmt+dmxt)\n\n\n\nIndividual Testing Performance\n\n\n\nLink to preprocessing code"
  },
  {
    "objectID": "read_24.html",
    "href": "read_24.html",
    "title": "Process 24 data",
    "section": "",
    "text": "pacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n\n\n# 1. Phase type (1 Training, 2 Test)\n# 2. Block number (1-10 Training, 1 Test)\n# 3. Trial number (1-270 Training, 271-354 Test)*\n# 4. Pattern type (1 = old*, 2 = prototype, 3 = new low, 4 = new medium, 5 = new high)\n# 5. Category number (1-3)\n# 6. Pattern token* (1-90 old, 1 prototype, 1-3 new low, 1-6 new med, 1-9 new high)\n# 7. distortion level (1 = low, 2 = med, 3 = high)\n# 8. Category response (1-3)\n# 9. Correct/Incorrect (0 = Incorrect, 1 = Correct)\n# 10. Reaction time (in milliseconds)\n# 11-28. Coordinates of nine dots* (-25 through 24)\n# *Pattern type: All training patterns (including old patterns in the test phase) are coded as 1 regardless of the distortion levels\n# *Pattern token: index of unique tokens for each category of each type of pattern. \n# *Coordinates of nine dots: every two columns represent the x and y coordinates of a dot on a 50 x 50 grid\n# \n# The conditions are indicated in the file names: \n#   file names with \"cond1\", \"cond2\", \"cond3\" and \"cond4\" contain data from the low, medium, high and mixed-distortion training conditions respectively. \n\n\n#rm(list=ls())\n\ncol.names = c(\"Phase\",\"Block\",\"BlockTrial\",\"Pattern\",\"Category\",\"Pattern.Token\",\"distortion\",\"Response\",\"Corr\",\"rt\",\n              \"x1\",\"y1\",\"x2\",\"y2\",\"x3\",\"y3\",\"x4\",\"y4\",\"x5\",\"y5\",\"x6\",\"y6\",\"x7\",\"y7\",\"x8\",\"y8\",\"x9\",\"y9\", \"name\", \"condit\", \"sbjCode\")\n\nloadPattern=\"dot_*\"\npathString=paste(\"data/\",sep=\"\")\nmFiles &lt;- list.files(path=\"data/\",pattern = loadPattern, recursive = FALSE) # should be 89 in exp 2\nmFiles\n\n  [1] \"dot_cond1_sub1.txt\"   \"dot_cond1_sub102.txt\" \"dot_cond1_sub106.txt\"\n  [4] \"dot_cond1_sub110.txt\" \"dot_cond1_sub114.txt\" \"dot_cond1_sub122.txt\"\n  [7] \"dot_cond1_sub13.txt\"  \"dot_cond1_sub201.txt\" \"dot_cond1_sub205.txt\"\n [10] \"dot_cond1_sub209.txt\" \"dot_cond1_sub21.txt\"  \"dot_cond1_sub213.txt\"\n [13] \"dot_cond1_sub217.txt\" \"dot_cond1_sub221.txt\" \"dot_cond1_sub225.txt\"\n [16] \"dot_cond1_sub229.txt\" \"dot_cond1_sub233.txt\" \"dot_cond1_sub237.txt\"\n [19] \"dot_cond1_sub245.txt\" \"dot_cond1_sub249.txt\" \"dot_cond1_sub25.txt\" \n [22] \"dot_cond1_sub253.txt\" \"dot_cond1_sub257.txt\" \"dot_cond1_sub261.txt\"\n [25] \"dot_cond1_sub265.txt\" \"dot_cond1_sub269.txt\" \"dot_cond1_sub273.txt\"\n [28] \"dot_cond1_sub277.txt\" \"dot_cond1_sub278.txt\" \"dot_cond1_sub282.txt\"\n [31] \"dot_cond1_sub286.txt\" \"dot_cond1_sub29.txt\"  \"dot_cond1_sub290.txt\"\n [34] \"dot_cond1_sub294.txt\" \"dot_cond1_sub298.txt\" \"dot_cond1_sub302.txt\"\n [37] \"dot_cond1_sub306.txt\" \"dot_cond1_sub310.txt\" \"dot_cond1_sub314.txt\"\n [40] \"dot_cond1_sub318.txt\" \"dot_cond1_sub322.txt\" \"dot_cond1_sub326.txt\"\n [43] \"dot_cond1_sub33.txt\"  \"dot_cond1_sub330.txt\" \"dot_cond1_sub334.txt\"\n [46] \"dot_cond1_sub338.txt\" \"dot_cond1_sub342.txt\" \"dot_cond1_sub346.txt\"\n [49] \"dot_cond1_sub350.txt\" \"dot_cond1_sub354.txt\" \"dot_cond1_sub358.txt\"\n [52] \"dot_cond1_sub362.txt\" \"dot_cond1_sub366.txt\" \"dot_cond1_sub37.txt\" \n [55] \"dot_cond1_sub370.txt\" \"dot_cond1_sub374.txt\" \"dot_cond1_sub378.txt\"\n [58] \"dot_cond1_sub382.txt\" \"dot_cond1_sub386.txt\" \"dot_cond1_sub390.txt\"\n [61] \"dot_cond1_sub394.txt\" \"dot_cond1_sub41.txt\"  \"dot_cond1_sub45.txt\" \n [64] \"dot_cond1_sub49.txt\"  \"dot_cond1_sub5.txt\"   \"dot_cond1_sub53.txt\" \n [67] \"dot_cond1_sub57.txt\"  \"dot_cond1_sub61.txt\"  \"dot_cond1_sub65.txt\" \n [70] \"dot_cond1_sub73.txt\"  \"dot_cond1_sub77.txt\"  \"dot_cond1_sub82.txt\" \n [73] \"dot_cond1_sub86.txt\"  \"dot_cond1_sub9.txt\"   \"dot_cond1_sub90.txt\" \n [76] \"dot_cond1_sub94.txt\"  \"dot_cond1_sub98.txt\"  \"dot_cond2_sub10.txt\" \n [79] \"dot_cond2_sub103.txt\" \"dot_cond2_sub107.txt\" \"dot_cond2_sub111.txt\"\n [82] \"dot_cond2_sub115.txt\" \"dot_cond2_sub118.txt\" \"dot_cond2_sub119.txt\"\n [85] \"dot_cond2_sub123.txt\" \"dot_cond2_sub14.txt\"  \"dot_cond2_sub18.txt\" \n [88] \"dot_cond2_sub2.txt\"   \"dot_cond2_sub202.txt\" \"dot_cond2_sub206.txt\"\n [91] \"dot_cond2_sub214.txt\" \"dot_cond2_sub218.txt\" \"dot_cond2_sub22.txt\" \n [94] \"dot_cond2_sub222.txt\" \"dot_cond2_sub226.txt\" \"dot_cond2_sub230.txt\"\n [97] \"dot_cond2_sub234.txt\" \"dot_cond2_sub238.txt\" \"dot_cond2_sub241.txt\"\n[100] \"dot_cond2_sub242.txt\" \"dot_cond2_sub246.txt\" \"dot_cond2_sub250.txt\"\n[103] \"dot_cond2_sub254.txt\" \"dot_cond2_sub258.txt\" \"dot_cond2_sub262.txt\"\n[106] \"dot_cond2_sub266.txt\" \"dot_cond2_sub270.txt\" \"dot_cond2_sub274.txt\"\n[109] \"dot_cond2_sub279.txt\" \"dot_cond2_sub283.txt\" \"dot_cond2_sub287.txt\"\n[112] \"dot_cond2_sub291.txt\" \"dot_cond2_sub295.txt\" \"dot_cond2_sub299.txt\"\n[115] \"dot_cond2_sub30.txt\"  \"dot_cond2_sub303.txt\" \"dot_cond2_sub307.txt\"\n[118] \"dot_cond2_sub311.txt\" \"dot_cond2_sub315.txt\" \"dot_cond2_sub319.txt\"\n[121] \"dot_cond2_sub323.txt\" \"dot_cond2_sub327.txt\" \"dot_cond2_sub331.txt\"\n[124] \"dot_cond2_sub335.txt\" \"dot_cond2_sub339.txt\" \"dot_cond2_sub34.txt\" \n[127] \"dot_cond2_sub347.txt\" \"dot_cond2_sub351.txt\" \"dot_cond2_sub355.txt\"\n[130] \"dot_cond2_sub359.txt\" \"dot_cond2_sub363.txt\" \"dot_cond2_sub367.txt\"\n[133] \"dot_cond2_sub371.txt\" \"dot_cond2_sub375.txt\" \"dot_cond2_sub38.txt\" \n[136] \"dot_cond2_sub383.txt\" \"dot_cond2_sub387.txt\" \"dot_cond2_sub391.txt\"\n[139] \"dot_cond2_sub395.txt\" \"dot_cond2_sub399.txt\" \"dot_cond2_sub42.txt\" \n[142] \"dot_cond2_sub46.txt\"  \"dot_cond2_sub54.txt\"  \"dot_cond2_sub58.txt\" \n[145] \"dot_cond2_sub6.txt\"   \"dot_cond2_sub62.txt\"  \"dot_cond2_sub66.txt\" \n[148] \"dot_cond2_sub70.txt\"  \"dot_cond2_sub74.txt\"  \"dot_cond2_sub79.txt\" \n[151] \"dot_cond2_sub83.txt\"  \"dot_cond2_sub87.txt\"  \"dot_cond2_sub91.txt\" \n[154] \"dot_cond2_sub95.txt\"  \"dot_cond2_sub99.txt\"  \"dot_cond3_sub100.txt\"\n[157] \"dot_cond3_sub104.txt\" \"dot_cond3_sub108.txt\" \"dot_cond3_sub112.txt\"\n[160] \"dot_cond3_sub116.txt\" \"dot_cond3_sub12.txt\"  \"dot_cond3_sub120.txt\"\n[163] \"dot_cond3_sub124.txt\" \"dot_cond3_sub15.txt\"  \"dot_cond3_sub19.txt\" \n[166] \"dot_cond3_sub203.txt\" \"dot_cond3_sub207.txt\" \"dot_cond3_sub211.txt\"\n[169] \"dot_cond3_sub215.txt\" \"dot_cond3_sub219.txt\" \"dot_cond3_sub223.txt\"\n[172] \"dot_cond3_sub227.txt\" \"dot_cond3_sub231.txt\" \"dot_cond3_sub235.txt\"\n[175] \"dot_cond3_sub239.txt\" \"dot_cond3_sub243.txt\" \"dot_cond3_sub247.txt\"\n[178] \"dot_cond3_sub251.txt\" \"dot_cond3_sub255.txt\" \"dot_cond3_sub259.txt\"\n[181] \"dot_cond3_sub263.txt\" \"dot_cond3_sub271.txt\" \"dot_cond3_sub275.txt\"\n[184] \"dot_cond3_sub280.txt\" \"dot_cond3_sub284.txt\" \"dot_cond3_sub288.txt\"\n[187] \"dot_cond3_sub292.txt\" \"dot_cond3_sub296.txt\" \"dot_cond3_sub3.txt\"  \n[190] \"dot_cond3_sub300.txt\" \"dot_cond3_sub304.txt\" \"dot_cond3_sub308.txt\"\n[193] \"dot_cond3_sub31.txt\"  \"dot_cond3_sub312.txt\" \"dot_cond3_sub316.txt\"\n[196] \"dot_cond3_sub320.txt\" \"dot_cond3_sub324.txt\" \"dot_cond3_sub328.txt\"\n[199] \"dot_cond3_sub332.txt\" \"dot_cond3_sub336.txt\" \"dot_cond3_sub340.txt\"\n[202] \"dot_cond3_sub344.txt\" \"dot_cond3_sub348.txt\" \"dot_cond3_sub35.txt\" \n[205] \"dot_cond3_sub352.txt\" \"dot_cond3_sub356.txt\" \"dot_cond3_sub360.txt\"\n[208] \"dot_cond3_sub364.txt\" \"dot_cond3_sub368.txt\" \"dot_cond3_sub372.txt\"\n[211] \"dot_cond3_sub376.txt\" \"dot_cond3_sub380.txt\" \"dot_cond3_sub384.txt\"\n[214] \"dot_cond3_sub39.txt\"  \"dot_cond3_sub392.txt\" \"dot_cond3_sub396.txt\"\n[217] \"dot_cond3_sub400.txt\" \"dot_cond3_sub43.txt\"  \"dot_cond3_sub51.txt\" \n[220] \"dot_cond3_sub55.txt\"  \"dot_cond3_sub59.txt\"  \"dot_cond3_sub63.txt\" \n[223] \"dot_cond3_sub67.txt\"  \"dot_cond3_sub7.txt\"   \"dot_cond3_sub75.txt\" \n[226] \"dot_cond3_sub80.txt\"  \"dot_cond3_sub84.txt\"  \"dot_cond3_sub88.txt\" \n[229] \"dot_cond3_sub92.txt\"  \"dot_cond3_sub96.txt\"  \"dot_cond4_sub101.txt\"\n[232] \"dot_cond4_sub105.txt\" \"dot_cond4_sub109.txt\" \"dot_cond4_sub113.txt\"\n[235] \"dot_cond4_sub117.txt\" \"dot_cond4_sub12.txt\"  \"dot_cond4_sub121.txt\"\n[238] \"dot_cond4_sub16.txt\"  \"dot_cond4_sub20.txt\"  \"dot_cond4_sub204.txt\"\n[241] \"dot_cond4_sub208.txt\" \"dot_cond4_sub212.txt\" \"dot_cond4_sub216.txt\"\n[244] \"dot_cond4_sub220.txt\" \"dot_cond4_sub224.txt\" \"dot_cond4_sub228.txt\"\n[247] \"dot_cond4_sub232.txt\" \"dot_cond4_sub236.txt\" \"dot_cond4_sub24.txt\" \n[250] \"dot_cond4_sub240.txt\" \"dot_cond4_sub244.txt\" \"dot_cond4_sub252.txt\"\n[253] \"dot_cond4_sub256.txt\" \"dot_cond4_sub260.txt\" \"dot_cond4_sub264.txt\"\n[256] \"dot_cond4_sub268.txt\" \"dot_cond4_sub272.txt\" \"dot_cond4_sub276.txt\"\n[259] \"dot_cond4_sub28.txt\"  \"dot_cond4_sub281.txt\" \"dot_cond4_sub285.txt\"\n[262] \"dot_cond4_sub289.txt\" \"dot_cond4_sub293.txt\" \"dot_cond4_sub297.txt\"\n[265] \"dot_cond4_sub301.txt\" \"dot_cond4_sub305.txt\" \"dot_cond4_sub309.txt\"\n[268] \"dot_cond4_sub313.txt\" \"dot_cond4_sub32.txt\"  \"dot_cond4_sub321.txt\"\n[271] \"dot_cond4_sub329.txt\" \"dot_cond4_sub333.txt\" \"dot_cond4_sub337.txt\"\n[274] \"dot_cond4_sub341.txt\" \"dot_cond4_sub345.txt\" \"dot_cond4_sub349.txt\"\n[277] \"dot_cond4_sub353.txt\" \"dot_cond4_sub357.txt\" \"dot_cond4_sub36.txt\" \n[280] \"dot_cond4_sub361.txt\" \"dot_cond4_sub365.txt\" \"dot_cond4_sub369.txt\"\n[283] \"dot_cond4_sub373.txt\" \"dot_cond4_sub377.txt\" \"dot_cond4_sub381.txt\"\n[286] \"dot_cond4_sub385.txt\" \"dot_cond4_sub389.txt\" \"dot_cond4_sub393.txt\"\n[289] \"dot_cond4_sub397.txt\" \"dot_cond4_sub4.txt\"   \"dot_cond4_sub40.txt\" \n[292] \"dot_cond4_sub44.txt\"  \"dot_cond4_sub52.txt\"  \"dot_cond4_sub56.txt\" \n[295] \"dot_cond4_sub60.txt\"  \"dot_cond4_sub64.txt\"  \"dot_cond4_sub68.txt\" \n[298] \"dot_cond4_sub72.txt\"  \"dot_cond4_sub76.txt\"  \"dot_cond4_sub8.txt\"  \n[301] \"dot_cond4_sub85.txt\"  \"dot_cond4_sub89.txt\"  \"dot_cond4_sub93.txt\" \n[304] \"dot_cond4_sub97.txt\" \n\nnFiles=length(mFiles)\n# read in each of the txt files in mFiles - into a single tibble\n\nd &lt;- purrr::map2_dfr(mFiles, mFiles, ~ read.table(paste0(pathString, .x, sep = \"\")) %&gt;%\n    mutate(\n      name = .y,\n      condit = stringr::str_extract(.y, \"cond\\\\d+\"),\n      subject_id = stringr::str_extract(.y, \"sub\\\\d+\")\n    )) %&gt;%\n    purrr::set_names(col.names) |&gt; \n  group_by(sbjCode, condit) |&gt;\n  mutate(trial = row_number()) |&gt; \n  relocate(\"sbjCode\", \"condit\", \"trial\") \n\n\n\ndCat &lt;- d |&gt; \n  mutate(\n    phase = case_when(\n      Phase == \"1\" ~ \"Training\",\n      Phase == \"2\" ~ \"Test\"\n    ), \n    Stage = case_when(\n      trial %in% 1:90 ~ \"Start\",\n      trial %in% 91:180 ~ \"Middle\",\n      trial %in% 181:270 ~ \"End\",\n      trial %in% 271:354 ~ \"Test\"\n    ),\n    pattern = case_when(\n      Pattern == \"1\" ~ \"old\",\n      Pattern == \"2\" ~ \"prototype\",\n      Pattern == \"3\" ~ \"new_low\",\n      Pattern == \"4\" ~ \"new_med\",\n      Pattern == \"5\" ~ \"new_high\"\n    ),\n    distortion = recode(distortion,\n                        `0` = \"prototype\",\n                        `1` = \"low\",\n                        `2` = \"med\",\n                        `3` = \"high\"),\n    Pattern_Token = case_when(\n      pattern == \"old\" & Pattern.Token %in% 1:90 ~ \"old\",\n      pattern == \"prototype\" & Pattern.Token == 0 ~ \"prototype\",\n      pattern == \"new_low\" & Pattern.Token %in% 1:3 ~ \"new_low\",\n      pattern == \"new_med\" & Pattern.Token %in% 1:6 ~ \"new_med\",\n      pattern == \"new_high\" & Pattern.Token %in% 1:9 ~ \"new_high\"\n    ),\n    condit = recode(condit,\n                    \"cond1\" = \"low\",\n                    \"cond2\" = \"medium\",\n                    \"cond3\" = \"high\",\n                    \"cond4\" = \"mixed\")\n  ) |&gt; \n  relocate(Stage, .after=trial) |&gt; relocate(Pattern_Token, pattern, .after=Pattern.Token)\n\ndCat$Pattern_Token = factor(dCat$Pattern_Token,levels=c(\"old\",\"prototype\",\"new_low\",\"new_med\",\"new_high\")) \ndCat$condit = factor(dCat$condit,levels=c(\"low\",\"medium\",\"mixed\",\"high\") )\n\n\ndCatTrainAvg=dCat |&gt; filter(Phase==1)  |&gt; group_by(sbjCode,condit,Block) |&gt; \n  summarise(nCorr=sum(Corr),propCor=nCorr/27,rtMean=mean(rt), n=n(),.groups = 'keep') |&gt; \n  ungroup() |&gt; group_by(condit) |&gt;\n  mutate(grpRank=factor(rank(-propCor)),id=factor(sbjCode)) |&gt; \n   as.data.frame() |&gt; arrange(sbjCode,condit,Block)\n\ndtf &lt;- dCatTrainAvg |&gt; filter(Block==10) |&gt; arrange(-propCor) |&gt;\n  group_by(condit) |&gt; # bin into quartile by propCor\n  mutate(quartile = ntile(propCor, 4), finalTrain=propCor) \n\ndCatTrainAvg$id &lt;-factor(dCatTrainAvg$id,levels=unique(dCatTrainAvg$sbjCode))\n\n\n\ndCatTestAvg=dCat |&gt; filter(Phase==2)  |&gt; group_by(sbjCode,condit,Pattern_Token) |&gt; \n  summarise(Corr=mean(Corr),rtMean=mean(rt), n=n(),.groups = 'keep') |&gt; \n  ungroup() |&gt; group_by(condit) |&gt;\n  mutate(grpRank=factor(rank(-Corr)),id=factor(sbjCode)) |&gt; \n  as.data.frame() |&gt; arrange(sbjCode,condit,Corr)\n\ndte_h &lt;- dCatTestAvg |&gt; filter(Pattern_Token==\"new_high\") |&gt; arrange(-Corr) |&gt;\n  group_by(condit) |&gt; \n  mutate(q_test_high = ntile(Corr, 4), test_high=Corr)\n\ndte_o &lt;- dCatTestAvg |&gt; filter(Pattern_Token==\"old\") |&gt; arrange(-Corr) |&gt;\n  group_by(condit) |&gt; \n  mutate(q_test_old = ntile(Corr, 4), test_old=Corr)\n\ndCat &lt;- dCat |&gt; left_join(dtf |&gt; select(sbjCode,condit,quartile, finalTrain), by=c(\"sbjCode\",\"condit\"))\ndCat &lt;- dCat |&gt; left_join(dte_h |&gt; select(sbjCode,condit,q_test_high, test_high), by=c(\"sbjCode\",\"condit\"))\ndCat &lt;- dCat |&gt; left_join(dte_o |&gt; select(sbjCode,condit,q_test_old, test_old), by=c(\"sbjCode\",\"condit\"))\n\n\n\n\n# order sbjCode by end of training performance\ndCat$sbjCode &lt;-factor(dCat$sbjCode,levels=unique(dtf$id))\n\n\n\n\n# d1 &lt;- dCat |&gt; filter(sbjCode==\"sub1\")\n# da &lt;- d |&gt; group_by(sbjCode, condit) |&gt; summarise(n = n()) %&gt;% dplyr::arrange(n)\n# sub12 has 708 trials - rest have 354. \n# the two sub12 instances are in different condits"
  },
  {
    "objectID": "dp_24_model.html",
    "href": "dp_24_model.html",
    "title": "exemplar_baseline",
    "section": "",
    "text": "Codepacman::p_load(dplyr, purrr, tidyr, ggplot2, here, patchwork, conflicted, knitr, grateful)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n\n\nCode# Distance function using Euclidean distance\ndist.euclidean &lt;- function(e, p) {\n  sqrt(sum((e - p)^2))\n}\n\n# Similarity function using exponential decay\nsimilarity &lt;- function(e, p, c) {\n  exp(-c * dist.euclidean(e, p))\n}\n\n# Generating Prototypes\ngenerate_prototypes &lt;- function(num_categories, num_dimensions, between) {\n  matrix(runif(num_categories * num_dimensions, min = 0, max = between), \n         nrow = num_categories, ncol = num_dimensions)\n}\n\ngenerate_distorted_patterns &lt;- function(prototype, num_samples, distortion_level, within) {\n  num_dimensions &lt;- length(prototype)\n  t(sapply(1:num_samples, function(x) {\n    noise &lt;- rnorm(num_dimensions) * within * distortion_level\n    prototype + noise\n  }))\n}\n\n# Categorization Probability Function\ncategorization_probability &lt;- function(test_pattern, training_patterns, gamma, c) {\n  # Calculate the summed similarities for each category\n  summed_similarities &lt;- apply(training_patterns, 3,function(category_patterns) {\n    sum(sapply(1:nrow(category_patterns), function(i) {\n      similarity(test_pattern, category_patterns[i, ], c)\n    }))\n  })\n  # Raise the summed similarities to the power of gamma\n  numerator &lt;- summed_similarities^gamma\n  denominator &lt;- sum(summed_similarities^gamma)\n  \n  # Return the probability of the test_pattern being in category A\n  probs &lt;- numerator / denominator\n  return (probs)\n}\n\n\n# Simulation Function\nsimulate &lt;- function(num_categories, num_samples, training_distortion_level, within, between, c, gamma, nd=6) {\n  prototypes &lt;- generate_prototypes(num_categories, num_dimensions=nd, between=between)\n  training_patterns &lt;- array(dim = c(num_samples, ncol(prototypes), num_categories))\n  \n  for (cat in 1:num_categories) {\n    training_patterns[,,cat] &lt;- generate_distorted_patterns(prototypes[cat,], num_samples, training_distortion_level, within)\n  }\n  \n  # Assess Testing Performance Here\n  test_performance &lt;- list()\n  categories &lt;- seq_len(num_categories)\n  types_of_patterns &lt;- c(\"old\", \"prototype\", \"new_low\", \"new_medium\", \"new_high\")\n  distortion_levels_test &lt;- c(1.20, 2.80, 4.60) # low, medium, high distortion levels\n  #distortion_levels_test &lt;- c(4, 6, 7.7)\n  \n  for (type in types_of_patterns) {\n    for (cat in categories) {\n      if (type == \"old\") {\n        test_patterns &lt;- matrix(training_patterns[sample(1:num_samples, 27),,cat])\n        #colMeans(test_patterns)\n      } else if (type == \"prototype\") {\n        test_patterns &lt;- matrix(prototypes[cat,], nrow = 1, ncol = ncol(prototypes), byrow = TRUE)\n      } else {\n        distortion_level &lt;- switch(type,\n                                   \"new_low\" = distortion_levels_test[1],\n                                   \"new_medium\" = distortion_levels_test[2],\n                                   \"new_high\" = distortion_levels_test[3])\n        test_patterns &lt;- generate_distorted_patterns(prototypes[cat,], 27, distortion_level, within)\n      }\n      # Calculate categorization probabilities for the test patterns\n      probs &lt;- apply(test_patterns, 1, categorization_probability, training_patterns = training_patterns, gamma = gamma, c = c)\n      # Count correct classifications\n      #correct_classifications &lt;- sum(apply(probs, 2, which.max) == cat)\n      prob_cat &lt;- probs[cat,]\n      \n      test_performance[[paste(type, \"cat\", cat, sep = \"_\")]] &lt;- mean(prob_cat) #correct_classifications / nrow(test_patterns)\n    }\n  }\n  \n  # Combine results into a single data frame\n  test_performance_df &lt;- data.frame(\n    type = rep(types_of_patterns, each = num_categories),\n    category = rep(categories, times = length(types_of_patterns)),\n    correct_classifications = unlist(test_performance)\n  )\n  \n  return(test_performance_df)\n}\n\n\n\nCode# Simulation Parameters\nnum_categories &lt;- 3\nnum_dimensions &lt;- 8\nnum_samples &lt;- 300 # number of samples per category\nbetween &lt;- 2\nwithin &lt;- 0.210\ngamma &lt;- 5.0\nc &lt;- 0.475\ndistortion_levels &lt;- c(4, 6, 7.7) # low, medium, high distortion levels\n#distortion_levels &lt;- c(1, 5, 7.7)\nnsim &lt;- 100\n\n\n\n# List to store performance results from each distortion level\nperformance_results &lt;- list()\n\n# Simulate for each distortion level\nfor (distortion_level in distortion_levels) {\n  results &lt;- replicate(nsim, simulate(num_categories, num_samples, distortion_level, within, between, c, gamma, nd=num_dimensions), simplify = FALSE)\n  performance_results[[as.character(distortion_level)]] &lt;- do.call(rbind, results)\n}\n\n# Combining results\ncombined_results &lt;- bind_rows(\n  lapply(names(performance_results), function(name) {\n    transform(performance_results[[name]], distortion_level = as.numeric(name))\n  }),\n  .id = \"distortion_level\"\n) |&gt; mutate(Pattern_Token = factor(type,levels=c(\"old\",\"prototype\",\"new_low\",\"new_medium\",\"new_high\")))\n\n\n\nyt &lt;- round(seq(0,1,length.out=7), 2)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),scale_y_continuous(breaks=yt))\n# Visualizing the results\nggplot(combined_results, aes(x = Pattern_Token, y = correct_classifications, fill = factor(distortion_level))) +\n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(x = \"Pattern Type\", y = \"Correct Classifications (%)\", fill = \"Training Distortion Level\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set1\") +ggtitle(paste0(\"nsim: \",nsim,\"; gamma: \",gamma,\"; c: \",c,\"; within: \",within,\"; between: \",between,\"; num_samples: \",num_samples, \" nd: \", num_dimensions)) +eg\n\n\n\nCodesaveRDS(sim_nosof1000, file = \"sim_nosof1000.rds\")\n\n\ngenerate_distorted_patterns &lt;- function(prototype, num_samples, distortion_level, within) { num_dimensions &lt;- length(prototype) noise &lt;- matrix(rnorm(num_samples * num_dimensions), nrow = num_samples) * within * distortion_level matrix(rep(prototype, each = num_samples), nrow = num_samples, ncol = num_dimensions) + noise }\ncategorization_probability &lt;- function(test_pattern, training_patterns, gamma, c) { # Compute all similarities at once using matrix operations differences = array(dim = dim(training_patterns)) for (i in 1:dim(training_patterns)[3]) { differences[,,i] = training_patterns[,,i] - test_pattern } distances = sqrt(rowSums(differences^2, dims = 2)) summed_similarities = exp(-c * distances) summed_similarities = apply(summed_similarities, 2, sum)\n# Calculate probabilities numerator &lt;- summed_similarities^gamma denominator &lt;- sum(numerator)\nprobs &lt;- numerator / denominator return(probs) }"
  }
]