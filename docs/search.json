[
  {
    "objectID": "Analysis/dp_24.html",
    "href": "Analysis/dp_24.html",
    "title": "Hu & Nosofsky 2024",
    "section": "",
    "text": "Display codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted, knitr,grateful)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\nsource(here::here(\"R/read_24.R\"))\n\n#https://fonts.google.com/specimen/Manrope\n# ~/Library/Fonts\ntheme_nice &lt;- function() {\n  theme_minimal(base_family = \"Manrope\") +\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.title = element_text(family = \"Manrope Extrabold\", face = \"plain\", size = rel(1.35)),\n      plot.subtitle = element_text(family = \"Manrope Medium\", face = \"plain\", size = rel(1.2)),\n      axis.title = element_text(family = \"Manrope SemiBold\", face = \"plain\", size = rel(1)),\n      axis.title.x = element_text(hjust = .5),\n      axis.title.y = element_text(hjust = .5),\n      axis.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(0.8)),\n      strip.text = element_text(\n        family = \"Manrope\", face = \"bold\",\n        size = rel(.75), hjust = 0\n      ),\n      strip.background = element_rect(fill = \"grey90\", color = NA)\n    )\n}\n\ntheme_nice_dist &lt;- function() {\n  theme_nice() +\n    theme(\n      panel.grid = element_blank(),\n      panel.spacing.x = unit(10, units = \"pt\"),\n      axis.ticks.x = element_line(linewidth = 0.25),\n      axis.text.y = element_blank()\n    )\n}\n\ntheme_set(theme_nice())",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2024"
    ]
  },
  {
    "objectID": "Analysis/dp_24.html#filter-to-only-include-sbjs.-who-learned-during-training",
    "href": "Analysis/dp_24.html#filter-to-only-include-sbjs.-who-learned-during-training",
    "title": "Hu & Nosofsky 2024",
    "section": "Filter to only include sbjs. who learned during training",
    "text": "Filter to only include sbjs. who learned during training\n\nDisplay code# dCat |&gt; filter(Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\n# dCat |&gt; filter(finalTrain&gt;.33, Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\n# dCat |&gt; filter(finalTrain&gt;.66, Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\n# dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt; group_by(condit) |&gt; summarise(n=n_distinct(sbjCode))\ndCat |&gt; \n  filter(Phase == 2) |&gt; \n  group_by(condit) |&gt; \n  summarise(\n    `All Sbjs.` = n_distinct(sbjCode),\n    `&gt;.33` = n_distinct(sbjCode[finalTrain &gt; .35]),\n    `&gt;.50` = n_distinct(sbjCode[finalTrain &gt; .50]),\n    `&gt;.70` = n_distinct(sbjCode[finalTrain &gt; .70])\n  ) |&gt; kable()\n\n\nSubject Counts for each filtering level. Note that the training conditions are disproporionately impacted.\n\ncondit\nAll Sbjs.\n&gt;.33\n&gt;.50\n&gt;.70\n\n\n\nlow\n77\n77\n75\n73\n\n\nmedium\n78\n75\n63\n42\n\n\nmixed\n74\n67\n57\n42\n\n\nhigh\n75\n56\n35\n17\n\n\n\n\n\nIn the full data-set, the high distortion group has the worst performance for all testing patterns, and the low distortion group has performance either better or equal to all other training groups. However if we only include participants who exceeded 50%, or 70% accuracy during training - the patterns become a bit more complex. Considering the new_high distortion testing items, the groups that experienced more training variability now either match or outperform the low distortion group. The effect of filtering out the weaker learners does not influence the ordering of performance for the old items (i.e.Â The low distortion group remains the best, and the high distortion group remains the worst).\n\n\nMatch # of learners\nGroup by Condition\nGroup by Pattern\n\n\n\n\nDisplay codetrainRanks &lt;- dCat |&gt; group_by(sbjCode,condit) |&gt; \n  select(finalTrain) |&gt; slice(1) |&gt; arrange(-finalTrain)\n\ntop17 &lt;- trainRanks |&gt; group_by(condit) |&gt; slice(1:17)\ntop35 &lt;- trainRanks |&gt; group_by(condit) |&gt; slice(1:35)\ntop56 &lt;- trainRanks |&gt; group_by(condit) |&gt; slice(1:56)\nlow &lt;- trainRanks |&gt; filter(!(sbjCode %in% top56$sbjCode)) \n\n\n#top17 |&gt; gt::gt()\n\nt17 &lt;- dCat |&gt; filter(sbjCode %in% top17$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing - top 17 Sbjs.\", y=\"Accuracy\") \n\n\nt35 &lt;- dCat |&gt; filter(sbjCode %in% top35$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing - top 35 Sbjs.\", y=\"Accuracy\") \n\nt56 &lt;- dCat |&gt; filter(sbjCode %in% top56$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing - top 56 Sbjs.\", y=\"Accuracy\") \n\ntLow56 &lt;- dCat |&gt; filter(sbjCode %in% low$sbjCode) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) + \n  labs(title=\"Testing - lowest Sbjs (all sbj. NOT in top 56)\", y=\"Accuracy\")\n\n\ntLow35 &lt;- dCat |&gt; filter(!(sbjCode %in% (trainRanks |&gt; group_by(condit) |&gt; slice(1:35))$sbjCode)) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) + \n  labs(title=\"Testing - subjects NOT in top 35\", y=\"Accuracy\")\n\ntLow17 &lt;- dCat |&gt; filter(!(sbjCode %in% (trainRanks |&gt; group_by(condit) |&gt; slice(1:17))$sbjCode)) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) + \n  labs(title=\"Testing - subjects NOT in top 17\", y=\"Accuracy\")\n\n\n\n(t17+tLow17) /(t35+tLow35)/(t56+tLow56) + \n  plot_annotation(title=\"Test Accuracy - matching # of subjects\", \n                  caption=\" Only the top 17; top 35; top 56; or lowest performing subjects included. Rankings based on final training accuracy\")\n\n\n\ntest_strong_learners- top\n\n\nDisplay code# (t17+t35) /(t56+tLow) + \n#   plot_annotation(title=\"Test Accuracy - matching # of subjects\", \n#                   caption=\" Only the top 17; top 35; top 56; or lowest performing subjects included. Rankings based on final training accuracy\")\n\n\n\n\n\nDisplay codetAll &lt;- dCat |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \n\nt33 &lt;- dCat |&gt; filter(finalTrain&gt;.35, Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 35%\", y=\"Accuracy\") \n\nt66 &lt;- dCat |&gt; filter(finalTrain&gt;.50, Phase==2) |&gt;\n  group_by(sbjCode, condit,Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 50%\", y=\"Accuracy\") \n\nt80 &lt;- dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt;\n  group_by(sbjCode, condit,  Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 70%\", y=\"Accuracy\") \n\n((tAll + t33)/(t66 + t80)) + \n  plot_annotation(title=\"Test Accuracy - Influence of filtering out weak/non learers\", \n                  caption=\" % values indicate level of final training performance needed to be included. Note that the training conditions are disproporionately impacted by exclusions.\")\n\n\n\ntest_strong_learners\n\n\n\n\n\n\nDisplay codetAll &lt;- dCat |&gt; filter(Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \n\nt33 &lt;- dCat |&gt; filter(finalTrain&gt;.35, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 35%\", y=\"Accuracy\") \n\nt66 &lt;- dCat |&gt; filter(finalTrain&gt;.50, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 50%\", y=\"Accuracy\") \n\nt80 &lt;- dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Only greater than 70%\", y=\"Accuracy\") \n\n((tAll + t33)/(t66 + t80))\n\n\n\ntest_strong_learners2",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2024"
    ]
  },
  {
    "objectID": "Analysis/dp_24.html#split-by-quartiles-end-of-training-performance",
    "href": "Analysis/dp_24.html#split-by-quartiles-end-of-training-performance",
    "title": "Hu & Nosofsky 2024",
    "section": "Split by Quartiles (end of training performance)",
    "text": "Split by Quartiles (end of training performance)\nWe can also inspect testing performance by splitting the data into quartiles based on the final training performance. This avoids the issue of excluding subjects, but increases the disparity in training performance between groups (i.e.Â the worst quartile of high distortion sbjs. had much worse training performance than the worst quartile of low distortion sbjs.)\n\n\nGroup by Condit\nQuartile - Group by Pattern\nQuartile_Boxplots\n\n\n\n\nDisplay codetx1 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank())\ntx2 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank(),legend.position = \"none\" )\nyt &lt;- round(seq(0,1,length.out=7), 2)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),scale_y_continuous(breaks=yt))\n\n\ndq1 &lt;- dCat |&gt; filter(Phase==2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit)) +\n  stat_summary(geom=\"bar\",fun=\"mean\", position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge(), width=.9) +\n  eg + labs(x=\"Pattern Token\", y=\"Proportion Correct\", title=\"Testing Accuracy Overall Averages\", \n            fill=\"Training Condition\") \n  \ndq2 &lt;-dCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = Pattern_Token, y = Corr, fill = condit)) +\n  stat_summary(geom = \"bar\", fun = \"mean\", position = position_dodge()) +\n  stat_summary(geom = \"errorbar\", fun.data = mean_se, position = position_dodge(width = 0.9), width = 0.25) +\n  facet_wrap(~quartile) +\n  labs(x = \"Pattern Token\", y = \"Proportion Correct\", title = \"Testing Accuracy by End-Training Quartile\", \n       subtitle=\"Quartiles are based on the final training performance of each subject\", \n       fill=\"Training Condition\") \n  \ndq1/dq2\n\n\n\ntest_quartiles_condit\n\n\n\n\n\n\nDisplay codetx1 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank())\ntx2 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank(),legend.position = \"none\" )\nyt &lt;- round(seq(0,1,length.out=7), 2)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),scale_y_continuous(breaks=yt))\n\n\ndq1 &lt;- dCat |&gt; filter(Phase==2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token)) +\n  stat_summary(geom=\"bar\",fun=\"mean\", position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge(), width=.9) +\n  eg + labs(x=\"Training Condition\", y=\"Proportion Correct\", title=\"Testing Accuracy Overall Averages\") \n  \ndq2 &lt;-dCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = condit, y = Corr, fill = Pattern_Token)) +\n  stat_summary(geom = \"bar\", fun = \"mean\", position = position_dodge()) +\n  stat_summary(geom = \"errorbar\", fun.data = mean_se, position = position_dodge(width = 0.9), width = 0.25) +\n  facet_wrap(~quartile) +\n  labs(x = \"Training Condition\", y = \"Proportion Correct\", title = \"Testing Accuracy by End-Training Quartile\", \n       subtitle=\"Quartiles are based on the final training performance of each subject\") \n  \ndq1/dq2\n\n\n\ntest_quartiles\n\n\n\n\n\n\nDisplay codedCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = condit, y = Corr, fill = Pattern_Token)) +\n  geom_boxplot(position=position_dodge()) +\n  geom_jitter(position = position_jitterdodge(jitter.width = 0.25, dodge.width = 0.9), alpha = .2) +\n  labs(x = \"Training Condition\", y = \"Proportion Correct\", title = \"Testing Accuracy - All\")\n\n\n\ntest_quartiles_boxplots\n\n\nDisplay codedCat |&gt; filter(Phase == 2) |&gt; \n  group_by(sbjCode, condit, quartile, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x = condit, y = Corr, fill = Pattern_Token)) +\n  geom_boxplot(position=position_dodge()) +\n  geom_jitter(position = position_jitterdodge(jitter.width = 0.25, dodge.width = 0.9), alpha = .2) +\n  facet_wrap(~quartile)\n\n\n\ntest_quartiles_boxplots\n\n\nDisplay code  labs(x = \"Training Condition\", y = \"Proportion Correct\", title = \"Testing Accuracy - All\")\n\n$x\n[1] \"Training Condition\"\n\n$y\n[1] \"Proportion Correct\"\n\n$title\n[1] \"Testing Accuracy - All\"\n\nattr(,\"class\")\n[1] \"labels\"",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2024"
    ]
  },
  {
    "objectID": "Analysis/dp_24.html#testing-reaction-time",
    "href": "Analysis/dp_24.html#testing-reaction-time",
    "title": "Hu & Nosofsky 2024",
    "section": "Testing Reaction Time",
    "text": "Testing Reaction Time\nWorth comparing the RTâs to the accuracy. In many cases the RTâs show the inverse pattern of accuracy, i.e.Â slower RTâs for less accurate patterns.But, the weakest quartile for the High and Medium distortion training conditions donât follow this pattern.\n\n\nFacet by Training Condition\nGroup by Pattern\n\n\n\n\nDisplay codetx1 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank())\ntx2 &lt;- theme(axis.title.x=element_blank(), axis.text.x=element_blank(),legend.position = \"none\" )\nrtfun &lt;- \"median\"\nyt &lt;- round(seq(0,1500,length.out=7), 2)\neg &lt;- list(scale_y_continuous(breaks=yt))\n\n\nhtq &lt;- dCat |&gt; filter(condit==\"high\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"High Training -  Test RT\", y=\"Reaction Time\") +tx2\n\nltq &lt;- dCat |&gt; filter(condit==\"low\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"Low Training -  Test RT\", y=\"Reaction Time\") +tx1\n\nmtq &lt;- dCat |&gt; filter(condit==\"medium\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"Medium Training -  Test RT\", y=\"Reaction Time\") +tx2\n\n\nmxtq &lt;- dCat |&gt; filter(condit==\"mixed\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=rt, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun)+\n  facet_wrap(~quartile) + eg+\n  labs(title=\"Mixed Training -  Test RT\", y=\"Reaction Time\")  + tx1\n  \n\n\n(htq+ltq)/(mtq+mxtq) + plot_annotation(\n  title = 'Testing Reaction Times by Quartile',\n  subtitle = 'Quartiles set by Final TRAINING block',\n  caption = 'bars reflect median reaction times. Quartiles are set by ACCURACY in the final training block. Bar colors are pattern type.'\n)\n\n\n\nReaction Times\n\n\n\n\n\n\nDisplay codetAll &lt;- dCat |&gt; filter(Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing - All Sbjs.\", y=\"Reaction Time\", x=\"Training Condition\") + theme(legend.position = \"top\")\n\nt33 &lt;- dCat |&gt; filter(finalTrain&gt;.35, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing - Only greater than 35%\", y=\"Reaction Time\", x=\"Training Condition\")  + theme(legend.position = \"none\")\n\nt66 &lt;- dCat |&gt; filter(finalTrain&gt;.50, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing - Only greater than 50%\", y=\"Reaction Times\", x=\"Training Condition\") + theme(legend.position = \"none\")\n\nt80 &lt;- dCat |&gt; filter(finalTrain&gt;.70, Phase==2) |&gt;\n  ggplot(aes(x=condit, y=rt, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=rtfun, position=position_dodge())+\n  labs(title=\"High Distortion Testing- Only greater than 70%\", y=\"Reaction Times\", x=\"Training Condition\") + theme(legend.position = \"none\")\n((tAll + t33)/(t66 + t80)) + plot_annotation(\n  title = 'Testing Reaction Times by Training Accuracy',\n  subtitle = 'Filtering to retain subjects who achieved different performace levels during training',\n  caption = 'bars reflect median reaction times. Quartiles are set by ACCURACY in the final training block. Bar colors are pattern type.'\n)\n\n\n\n\n\n\n\n\n\n\nâ",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2024"
    ]
  },
  {
    "objectID": "Analysis/dp_24.html#individual-learning-curves",
    "href": "Analysis/dp_24.html#individual-learning-curves",
    "title": "Hu & Nosofsky 2024",
    "section": "Individual Learning Curves",
    "text": "Individual Learning Curves\n\nfacets sorted by final training accuracy\nclick on plots to enlarge.\n\n\n\nHigh Distortion\nLow Distortion\nMedium Distortion\nMixed Distortion\n\n\n\n\nDisplay codedCat |&gt; filter(condit==\"high\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"High Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves\n\n\n\n\n\n\nDisplay codedCat |&gt; filter(condit==\"low\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Low Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves - Low\n\n\n\n\n\n\nDisplay codedCat |&gt; filter(condit==\"medium\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Medium Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves - Low\n\n\n\n\n\n\nDisplay codedCat |&gt; filter(condit==\"mixed\", Phase==1) |&gt;\n  ggplot(aes(x=Block, y=Corr)) +  \n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+\n  facet_wrap(~sbjCode)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Mixed Training - Learning Curves\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,10))\n\n\n\nIndividual Learning Curves - Low",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2024"
    ]
  },
  {
    "objectID": "Analysis/dp_24.html#individual-testing",
    "href": "Analysis/dp_24.html#individual-testing",
    "title": "Hu & Nosofsky 2024",
    "section": "Individual Testing",
    "text": "Individual Testing\n\nfacets sorted by final training accuracy\nclick on plots to enlarge.\n\n\nDisplay codetx &lt;- theme(axis.text.x=element_blank() )\n\ndht &lt;- dCat |&gt; filter(condit==\"high\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"High Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\") +\n  theme(legend.position = \"top\") + tx\n\ndlt &lt;- dCat |&gt; filter(condit==\"low\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"Low Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\")+\n  tx +theme(legend.position = \"none\")\n\ndmt &lt;- dCat |&gt; filter(condit==\"medium\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"Medium Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\") +\n  theme(legend.position = \"none\")+\n  tx +theme(legend.position = \"none\")\n\ndmxt &lt;- dCat |&gt; filter(condit==\"mixed\", Phase==2) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=\"mean\")+\n  facet_wrap(~sbjCode, ncol=8)+\n  ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\", alpha=.5)+\n  ggtitle(\"Mixed Distortion Training - Testing\")+\n  xlab(\"Pattern Type\")+ylab(\"Proportion Correct\")+\n  tx +theme(legend.position = \"none\")\n\n(dht + dlt)/(dmt+dmxt)\n\n\n\nIndividual Testing Performance\n\n\n\nLink to preprocessing code",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2024"
    ]
  },
  {
    "objectID": "Analysis/dotSim_Analysis.html",
    "href": "Analysis/dotSim_Analysis.html",
    "title": "Dot Pattern Ratings - data checks",
    "section": "",
    "text": "catLearn accuracy refers to accuracy on the categorization task in the Hu & Nosofsky 2024 study.\nprototype sets refer to sets of 3 prototypes that correspond to a single participant in the Hu & Nosofsky 2024 study.\nprototype pairs refer to the specific pairs of prototypes that are displayed together on a rating trial (3 pairs per set).\nDisplay codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, \n  conflicted, jsonlite,stringr, gt, knitr, kableExtra, \n  lubridate,ggh4x, lmerTest)\nwalk(c(\"dplyr\", \"lmerTest\"), conflict_prefer_all, quiet = TRUE)\noptions(digits=2, scipen=999, dplyr.summarise.inform=FALSE)\nwalk(c(\"fun_plot\"), ~ source(here::here(paste0(\"R/\", .x, \".R\"))))\nmc24_proto &lt;- read.csv(here(\"Stimulii\",\"mc24_prototypes.csv\")) |&gt; mutate(set=paste0(sbjCode,\"_\",condit)) \nsbj_cat &lt;- read.csv(here(\"data\",\"mc24_sbj_cat.csv\"))\n\ndfiles &lt;- list(path=list.files(here::here(\"data/dotSim_data\"),full.names=TRUE))\n\nd &lt;- map_dfr(dfiles$path, ~read.csv(.x))\n\nd &lt;- map_dfr(dfiles$path, ~{read.csv(.x) |&gt; \n    mutate(sfile=tools::file_path_sans_ext(basename(.x)))}) |&gt; \n  select(-trial_index, -internal_node_id,-trial_type) |&gt;\n   mutate(set = paste(str_extract(item_label_1, \"^\\\\d+\"),\n                     str_extract(item_label_1, \"[a-z]+\"), sep = \"_\")) |&gt;\n  mutate(pair_label = paste0(item_label_1,\"_\",item_label_2)) |&gt;\n  relocate(sbjCode,date,set,pair_label,trial,item_label_1,item_label_2,response,rt)\n\nsetCounts &lt;- d |&gt; \n  pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(set) |&gt; summarise(n=n_distinct(sbjCode),resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n))\n\n# length(unique(mc_proto$set)) # 304\nsetCounts2 &lt;- mc24_proto |&gt; group_by(set) |&gt; \n  slice_head(n=1) |&gt; \n  select(id,file,set) |&gt; \n  left_join(setCounts,by=\"set\") |&gt; \n  mutate(n = ifelse(is.na(n), 0, n), .groups=\"drop\") |&gt; \n  arrange(n) |&gt; ungroup()\n\npairCounts &lt;- d |&gt; \n  group_by(pair_label,set) |&gt; \n  summarise(n=n(),mean_resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n)) |&gt; ungroup()\n\n\n\npatternAvg &lt;- d |&gt; \n  pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(item,file) |&gt; \n  summarise(n_rating=n(),resp=mean(response),sd=sd(response)) |&gt; \n  arrange(desc(n_rating))\n\ncat_sim &lt;- sbj_cat |&gt; \n  mutate(item=item_label) |&gt; \n  left_join(patternAvg,by=c(\"file\",\"item\"))  |&gt; arrange(desc(n_rating)) |&gt;\n  #remove rows where n_rating is NA, or less than 4\n  filter(!is.na(n_rating),n_rating&gt;=12) |&gt; \n  mutate(sim_group = ifelse(resp&gt;6.0,\"Very Similar\",ifelse(resp&lt;3.5,\"Very Dissimilar\",\"Medium\"))) |&gt; \n  mutate(sim_group=factor(sim_group,levels=c(\"Very Dissimilar\",\"Medium\",\"Very Similar\"))) \n\ncat_sim_test &lt;- cat_sim |&gt; \n  filter(Phase==2) |&gt; group_by(condit) |&gt;\n  mutate(quartile=ntile(Corr,4))\n\n\n\n\n\n\n#cor(cat_sim$resp,cat_sim$Corr)\n\n#  m1 &lt;- lmer(Corr ~ resp + (1|sbjCode), data=cat_sim)\n#  summary(m1)\n\n#  m1 &lt;- lmer(Corr ~ resp + (1|Pattern.Type) +  (1|sbjCode), data=cat_sim)\n#  summary(m1)\n\n#  m1 &lt;- lmer(Corr ~ resp*Pattern.Type*condit +  (1|sbjCode), data=cat_sim)\n#  summary(m1)\n\n\n# m1 &lt;- lmer(Corr ~ sim_group +  (1|sbjCode), data=cat_sim)\n# summary(m1)\n\n# m1 &lt;- lmer(Corr ~ sim_group*condit +  (1|sbjCode), data=cat_sim)\n# summary(m1)\n\n# m1 &lt;- lmer(Corr ~ sim_group*condit*Pattern.Type +  (1|sbjCode), data=cat_sim)\n# summary(m1)",
    "crumbs": [
      "Dot Patterns",
      "Rating Data Check"
    ]
  },
  {
    "objectID": "Analysis/dotSim_Analysis.html#data-inspection-sanity-checks",
    "href": "Analysis/dotSim_Analysis.html#data-inspection-sanity-checks",
    "title": "Dot Pattern Ratings - data checks",
    "section": "Data Inspection & Sanity Checks",
    "text": "Data Inspection & Sanity Checks\n\nDisplay codeavg_set_rating &lt;- setCounts2 |&gt; summarise(\"Avg Ratings Per Set\" = mean(n)) |&gt; pull(1)\n\nd |&gt; \n  summarize(\"N Subjects\" = n_distinct(sbjCode), \"N Prototype Sets\" = n_distinct(set)) |&gt; \n  mutate(\"Avg Ratings Per Set\" = avg_set_rating) |&gt;\n  kbl()\n\n\nTableÂ 1: Current counts of unique subjects, and prototype sets\n\n\n\n\nN Subjects\nN Prototype Sets\nAvg Ratings Per Set\n\n\n87\n304\n29\n\n\n\n\n\n\n\nPrototype set counts\nÂ \n\nDisplay codesetCounts2 |&gt; group_by(n) |&gt; summarise(nc=n()) |&gt; rename(\"Number of times prototype set has been included in the study\"=n, \"Number of prototype sets with this count\"=nc) |&gt; gt() |&gt; \n  tab_spanner(label = \"Prototype Set Counts\") |&gt; \n  tab_header(title = \"Prototype Set Counts\") |&gt; \n  tab_source_note(\n    \"Note: The number of times a prototype set has been included in the study is equal to the number of participants who rated the set.\"\n  )\n\n\n\n\n\n\nPrototype Set Counts\n\n\nNumber of times prototype set has been included in the study\nNumber of prototype sets with this count\n\n\n\n\n17\n1\n\n\n19\n4\n\n\n20\n3\n\n\n21\n3\n\n\n22\n8\n\n\n23\n10\n\n\n24\n19\n\n\n25\n19\n\n\n26\n20\n\n\n27\n25\n\n\n28\n23\n\n\n29\n24\n\n\n30\n28\n\n\n31\n25\n\n\n32\n17\n\n\n33\n24\n\n\n34\n15\n\n\n35\n13\n\n\n36\n14\n\n\n37\n2\n\n\n38\n3\n\n\n39\n1\n\n\n40\n2\n\n\n41\n1\n\n\n\nNote: The number of times a prototype set has been included in the study is equal to the number of participants who rated the set.\n\n\n\n\n\n\nDisplay code# d |&gt; filter(sbjCode==11) |&gt; select(sbjCode,date,trial,pair_label,set,rt,time_elapsed,time)\n\n# d |&gt; group_by(sbjCode,set) |&gt; \n#   summarize (n=n()) |&gt;\n#   gt()\n\n#d |&gt; group_by(sbjCode, item_label_1, item_label_2) |&gt; summarise(n=n())\n\n# (1-.33)^8\n# (factorial(8)/(factorial(6)*factorial(8-6))) * (.33^6)*((1-.33)^(8-6))\n# (factorial(8)/(factorial(7)*factorial(8-7))) *(.33^6)*((1-.33)^(8-7))\n# (factorial(8)/(factorial(8)*factorial(8-8))) *(.33^6)*(1-.33)^(8-8)\n\n# d |&gt; pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n#   group_by(sbjCode, item) |&gt; summarise(n=n())\n\n# patternCounts &lt;- d |&gt; pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n#   group_by(item) |&gt; summarise(n=n(),resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n))\n\n\n\n# d |&gt; \n#     pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; select(sbjCode,set,pair_label,item_label,item,response) |&gt;  group_by(set) |&gt;\n#     summarize(n=n_distinct(sbjCode)) |&gt; arrange(desc(n)) \n\n\n\n\n# d |&gt; group_by(sbjCode, file) |&gt; summarise(n=n())\n# d |&gt; group_by(sbjCode, set) |&gt; summarise(n=n())\n\n# d |&gt; group_by(sbjCode) |&gt; summarise(n_distinct(file))\n# d |&gt; group_by(sbjCode) |&gt; summarise(n_distinct(set))\n\n\n# sp &lt;- setCounts2 |&gt; \n#   mutate(set=reorder(set,n)) |&gt;\n#   ggplot(aes(x=set,y=n)) +\n#    geom_col() +\n#    theme(legend.title=element_blank(),\n#       axis.text.x = element_text(size=5,angle = 90, hjust = 0.5, vjust = 0.5)) +\n#     labs(x=\"Prototype Set\", y=\"Number of Participants to rate set\") \n\nsh &lt;- setCounts2 |&gt; \n  ggplot(aes(x=n)) + geom_histogram(binwidth = 1) +\n  scale_x_continuous(breaks=seq(0, max(setCounts2$n), by = 1)) +\n  geom_text(stat=\"count\", aes(label=..count..), vjust=-0.5) +\n  labs(x=\"Number of times prototype set has been included in the study\", \n  y=\"Number of prototype sets for each count\") \n\n\n#sp/sh\n\nsh\n\n\n\nPrototype set counts\n\n\n\nÂ \nRating Distributions\n\nDisplay codepgr &lt;- d |&gt; \n  ggplot(aes(x=response))+geom_histogram(binwidth=1) + \n      scale_x_continuous(breaks=seq(1, 9, by = 1)) +\n    coord_cartesian(xlim = c(1, 9)) + labs(title=\"Aggregate Rating Distribution\", x=\"Rating\", y=\"Count\") \n\npir &lt;- d |&gt;  ggplot(aes(x=response))+\n      geom_histogram(binwidth=1) + \n      facet_wrap(~sbjCode) + \n      scale_x_continuous(breaks=seq(1, 9, by = 1)) +\n    coord_cartesian(xlim = c(1, 9)) + labs(title=\"Rating Distribution per Sbj.\", x=\"Rating\", y=\"Count\") \n\npgr/pir\n\n\n\nRating distributions\n\n\n\nReaction Time Distributions\n\nDisplay codeprtg &lt;- d |&gt; ggplot(aes(x=rt))+\n  geom_density() + \n  labs(title=\"Aggregate Reaction Time Distribution\", x=\"Reaction Time (ms)\", y=\"Density\")\n\nprtid &lt;- d |&gt; ggplot(aes(x=rt))+geom_density() + \n  facet_wrap(~sbjCode,scale=\"free_x\") + labs(title=\"Reaction Time Distribution per Sbj.\", x=\"Reaction Time (ms)\", y=\"Density\")\n\nprtg/prtid\n\n\n\nReaction time distributions\n\n\n\nIndividual Subject Ratings\n\nDisplay code# d |&gt; summarize(n=n(), n_distinct(sbjCode), n_distinct(file), n_distinct(set), n_distinct(trial), n_distinct(item_label_1), n_distinct(item_label_2))\n\n\n# d %&gt;%\n#   filter(sbjCode == 11) %&gt;%\n#   select(sbjCode, date, trial, set, rt, time) %&gt;%\n#   mutate(time_parsed = parse_date_time(paste(date, time), orders = c(\"mdY IMS p\", \"mdy IMS p\"))) %&gt;%\n#   group_by(sbjCode, date) %&gt;%\n#   summarise(start_time = min(time_parsed), end_time = max(time_parsed)) %&gt;%\n#   mutate(endTimeMinusStart = end_time - start_time)\n\nplot_hist_sbj &lt;- function(id) {\n  d |&gt; filter(sbjCode==id) |&gt;\n    ggplot(aes(x = response)) +\n    geom_histogram(binwidth=1,fill = 'dodgerblue4') +\n    scale_x_continuous(breaks=seq(1, 9, by = 1)) +\n    coord_cartesian(xlim = c(1, 9)) +\n    theme_minimal() +\n    theme(axis.title.x=element_blank(),\n          axis.title.y=element_blank(),\n          axis.text.x=element_text(size=26))  \n}\n\n\nsbj_sum &lt;- d |&gt; group_by(sbjCode) |&gt; \n#filter(sbjCode&lt;5) |&gt;\n  mutate(time_parsed = parse_date_time(paste(date, time), orders = c(\"mdY IMS p\", \"mdy IMS p\"))) |&gt;\n  summarize (\"Mean Rating\"=mean(response),\n  \"SD Rating\"=sd(response), \n  \"Mean RT\"=mean(rt)/1000, \n  #\"Total Time (min)\" = max(time_elapsed)/60000,\n  \"Total Time (min)\" = round(difftime(max(time_parsed), min(time_parsed), units = \"mins\"),1),\n  n_prototype_sets = n_distinct(set), \n  \"N Trials\" = n_distinct(trial)) |&gt; \n  mutate(\"Response_Distribution\"=sbjCode) \n\n  sbj_sum |&gt; gt() |&gt; \n    text_transform(\n    locations = cells_body(columns = 'Response_Distribution'),\n    fn = function(column) {\n      map(column, plot_hist_sbj) |&gt;\n        ggplot_image(height = px(80), aspect_ratio = 3)\n    }\n    )\nsbj_sum |&gt; mutate(total_time=as.numeric(`Total Time (min)`)) |&gt; \n  rename(\"Subject\"=sbjCode, \"N_Sets\" = n_prototype_sets) |&gt; \n  summarize(\"Median Completition time (min)\"=median(total_time), \n  \"Average Completion Time\" = mean(total_time), \n  \"Min Completion Time (min)\" = min(total_time), \n  \"Max Completion Time (min)\" = max(total_time)) |&gt; kbl()\n\n\nTableÂ 2: Individual Subject Ratings\n\n\n\n\n\n\nsbjCode\nMean Rating\nSD Rating\nMean RT\nTotal Time (min)\nn_prototype_sets\nN Trials\nResponse_Distribution\n\n\n\n2\n6.3\n2.0\n2.22\n14.7\n101\n303\n\n\n\n3\n4.7\n1.6\n1.62\n11.6\n101\n303\n\n\n\n4\n4.5\n1.6\n3.52\n21.1\n101\n303\n\n\n\n5\n4.0\n2.0\n2.02\n13.5\n101\n303\n\n\n\n7\n5.1\n2.8\n2.79\n17.4\n101\n303\n\n\n\n8\n5.0\n2.4\n2.10\n13.9\n101\n303\n\n\n\n9\n4.7\n2.1\n2.81\n17.2\n101\n303\n\n\n\n10\n4.6\n1.7\n2.45\n15.8\n101\n303\n\n\n\n11\n2.8\n1.8\n5.80\n32.4\n101\n303\n\n\n\n12\n4.3\n2.6\n3.76\n22.2\n101\n303\n\n\n\n13\n5.8\n2.4\n1.21\n9.5\n101\n303\n\n\n\n14\n4.5\n1.8\n3.74\n22\n101\n303\n\n\n\n15\n5.1\n2.3\n2.11\n14\n101\n303\n\n\n\n16\n6.1\n2.1\n1.62\n11.5\n101\n303\n\n\n\n17\n5.5\n2.7\n1.05\n8.7\n101\n303\n\n\n\n18\n2.5\n2.5\n2.13\n14.2\n101\n303\n\n\n\n19\n4.4\n2.3\n1.91\n13\n101\n303\n\n\n\n20\n5.7\n1.6\n2.18\n14.4\n101\n303\n\n\n\n21\n4.6\n2.3\n3.93\n23.1\n101\n303\n\n\n\n22\n4.4\n1.6\n3.44\n20.6\n101\n303\n\n\n\n23\n3.3\n2.5\n2.00\n13.5\n101\n303\n\n\n\n24\n4.7\n2.3\n1.51\n11.1\n101\n303\n\n\n\n25\n5.2\n1.6\n3.06\n18.8\n101\n303\n\n\n\n26\n4.7\n2.0\n1.83\n12.6\n101\n303\n\n\n\n27\n4.5\n2.6\n2.69\n17\n101\n303\n\n\n\n28\n4.7\n2.1\n6.25\n34.9\n101\n303\n\n\n\n29\n4.9\n2.2\n2.75\n17.2\n101\n303\n\n\n\n30\n5.3\n1.9\n0.65\n6.6\n101\n303\n\n\n\n31\n6.6\n2.4\n1.14\n9\n101\n303\n\n\n\n32\n4.0\n1.8\n6.43\n35.7\n101\n303\n\n\n\n33\n5.1\n3.3\n1.40\n10.3\n101\n303\n\n\n\n34\n5.2\n2.5\n2.77\n17.4\n101\n303\n\n\n\n35\n4.7\n2.2\n3.07\n18.9\n101\n303\n\n\n\n36\n6.3\n2.0\n1.46\n10.7\n101\n303\n\n\n\n37\n5.8\n1.9\n1.42\n10.6\n101\n303\n\n\n\n38\n5.8\n2.4\n1.51\n10.8\n101\n303\n\n\n\n39\n5.7\n1.7\n2.61\n16.2\n101\n303\n\n\n\n40\n4.1\n2.0\n1.97\n13.3\n101\n303\n\n\n\n41\n5.1\n2.4\n3.53\n21.1\n101\n303\n\n\n\n42\n4.8\n1.4\n3.57\n21.4\n101\n303\n\n\n\n43\n5.3\n2.0\n1.82\n12.4\n101\n303\n\n\n\n44\n3.3\n2.6\n2.05\n13.7\n101\n303\n\n\n\n45\n4.6\n1.9\n3.31\n20.1\n101\n303\n\n\n\n46\n5.7\n1.6\n4.92\n28\n101\n303\n\n\n\n48\n4.7\n2.4\n3.26\n1328\n170\n303\n\n\n\n49\n3.7\n2.0\n3.07\n18.6\n101\n303\n\n\n\n50\n4.5\n1.8\n3.05\n18.8\n101\n303\n\n\n\n51\n4.8\n2.7\n4.13\n24.1\n101\n303\n\n\n\n52\n5.2\n2.0\n3.45\n20.7\n101\n303\n\n\n\n53\n6.6\n1.9\n1.74\n12.2\n101\n303\n\n\n\n54\n4.7\n1.7\n1.93\n13.1\n101\n303\n\n\n\n55\n4.7\n2.2\n3.59\n21.4\n101\n303\n\n\n\n56\n5.6\n1.5\n1.89\n12.9\n101\n303\n\n\n\n57\n4.7\n1.7\n5.53\n31.3\n101\n303\n\n\n\n58\n5.4\n2.1\n1.90\n12.9\n101\n303\n\n\n\n59\n4.3\n1.7\n2.40\n15.5\n101\n303\n\n\n\n60\n6.0\n2.5\n0.66\n6.8\n101\n303\n\n\n\n61\n4.9\n1.6\n2.25\n14.3\n101\n303\n\n\n\n62\n5.0\n2.4\n1.73\n12\n101\n303\n\n\n\n63\n4.7\n2.1\n3.77\n22.3\n101\n303\n\n\n\n64\n4.0\n2.0\n2.31\n15.1\n101\n303\n\n\n\n65\n4.0\n2.0\n2.98\n18.1\n101\n303\n\n\n\n66\n5.0\n3.4\n3.10\n19\n101\n303\n\n\n\n67\n4.5\n2.5\n2.18\n14.3\n101\n303\n\n\n\n68\n4.1\n2.3\n2.52\n16.1\n101\n303\n\n\n\n69\n4.2\n2.2\n1.90\n13\n101\n303\n\n\n\n70\n4.3\n2.0\n2.46\n15.8\n101\n303\n\n\n\n71\n5.1\n1.9\n3.49\n21\n101\n303\n\n\n\n72\n4.7\n2.0\n2.12\n13.8\n101\n303\n\n\n\n73\n5.6\n2.4\n1.39\n10.3\n101\n303\n\n\n\n74\n5.5\n1.9\n2.90\n17.8\n101\n303\n\n\n\n75\n5.1\n1.6\n1.67\n11.8\n101\n303\n\n\n\n76\n4.8\n1.8\n2.44\n15.6\n101\n303\n\n\n\n77\n3.9\n2.3\n2.35\n15.2\n101\n303\n\n\n\n78\n5.0\n2.0\n2.61\n16.5\n101\n303\n\n\n\n79\n2.7\n2.0\n6.03\n33.7\n101\n303\n\n\n\n80\n5.3\n1.6\n1.45\n10.7\n101\n303\n\n\n\n81\n4.8\n1.8\n1.52\n10.9\n101\n303\n\n\n\n82\n5.0\n3.1\n0.54\n6.1\n101\n303\n\n\n\n83\n4.3\n2.3\n2.23\n14.6\n101\n303\n\n\n\n84\n4.8\n2.2\n1.60\n11.5\n101\n303\n\n\n\n85\n4.7\n3.3\n1.68\n11.8\n101\n303\n\n\n\n86\n5.1\n2.3\n2.46\n15.8\n101\n303\n\n\n\n87\n3.1\n2.5\n2.83\n17.7\n101\n303\n\n\n\n88\n4.1\n2.7\n1.24\n9.6\n101\n303\n\n\n\n89\n4.4\n1.3\n2.40\n15.4\n101\n303\n\n\n\n90\n4.9\n2.7\n2.79\n17.4\n101\n303\n\n\n\n\n\n\n\n\n\nMedian Completition time (min)\nAverage Completion Time\nMin Completion Time (min)\nMax Completion Time (min)\n\n\n15\n31\n6.1\n1328",
    "crumbs": [
      "Dot Patterns",
      "Rating Data Check"
    ]
  },
  {
    "objectID": "Analysis/dotSim_Analysis.html#lowest-and-highest-rated-pairs",
    "href": "Analysis/dotSim_Analysis.html#lowest-and-highest-rated-pairs",
    "title": "Dot Pattern Ratings - data checks",
    "section": "Lowest and Highest Rated Pairs",
    "text": "Lowest and Highest Rated Pairs\n\nDisplay code# patternCounts |&gt; filter(n&gt;=8) |&gt;  slice_min(resp)\n# patternCounts |&gt; filter(n&gt;=8) |&gt;  slice_max(resp)\n\n# setCounts |&gt; filter(n&gt;=24) |&gt;  slice_min(resp)\n# setCounts |&gt; filter(n&gt;=24) |&gt;  slice_max(resp)\n\n\n# pairCounts |&gt; filter(n&gt;=5) |&gt;  slice_min(resp,n=2)\n# pairCounts |&gt; filter(n&gt;=5) |&gt;  slice_max(resp)\n\nmin_resp=7\nn_show=3\n\nd %&gt;% filter(pair_label %in% {pairCounts |&gt; filter(n&gt;=min_resp) |&gt;  \n  slice_min(mean_resp,n=n_show, with_ties=FALSE) |&gt; pull(pair_label)} ) |&gt;\n  group_by(pair_label) |&gt;\n  slice_head(n=1) %&gt;%\n  plot_dotsAll() + \n  plot_annotation(title=glue::glue(\"Lowest rated pairs ( out of sets with n&gt;={min_resp} ratings)\"), theme = theme(plot.title = element_text(hjust = 0.4)))\n\n\n\n\n\n\nDisplay coded %&gt;% filter(pair_label %in% {pairCounts |&gt; filter(n&gt;=min_resp) |&gt;  \n  slice_max(mean_resp,n=n_show, with_ties=FALSE) |&gt; pull(pair_label)} ) |&gt;\n  group_by(pair_label) |&gt;\n  slice_head(n=1) %&gt;%\n  plot_dotsAll() +  \n  plot_annotation(title=glue::glue(\"Highest rated pairs ( out of sets with n&gt;={min_resp} ratings)\"), theme = theme(plot.title = element_text(hjust = 0.4)))",
    "crumbs": [
      "Dot Patterns",
      "Rating Data Check"
    ]
  },
  {
    "objectID": "Analysis/dotSim_Analysis.html#pattern-pair-table",
    "href": "Analysis/dotSim_Analysis.html#pattern-pair-table",
    "title": "Dot Pattern Ratings - data checks",
    "section": "Pattern Pair Table",
    "text": "Pattern Pair Table\nAll pairs with &gt;=25 ratings\n\nclick on column headers to change sort order\n\ne.g.Â clicking on âMean Ratingâ will toggle showing the pairs rated most similar or most dissimilar\nclicking on âSDâ will toggle showing the pairs with the most or least agreement in ratings\n\n\nnote your screen may need to be at full width to see all columns\n\n\n\nDisplay code# could try formatting table environment with #| column: page\n\nplot_hist_pair &lt;- function(Pair) {\n  d |&gt; filter(pair_label==Pair) |&gt;\n    ggplot(aes(x = response)) +\n    geom_histogram(binwidth=1,fill = 'dodgerblue4') +\n    scale_x_continuous(breaks=seq(1, 9, by = 1)) +\n    coord_cartesian(xlim = c(1, 9)) +\n    theme_minimal() +\n    theme(axis.title.x=element_blank(),\n          axis.title.y=element_blank(),\n          axis.text.x=element_text(size=26))  \n}\n\n\n\npat_table_plot &lt;- function(Pair){\n\n  df &lt;- d |&gt; filter(pair_label==Pair) |&gt; slice_head(n=1) \n\n    pat1 &lt;- df %&gt;%\n          mutate(pattern_1 = purrr::map(pattern_1, jsonlite::fromJSON)) %&gt;%\n          unnest(pattern_1) %&gt;%\n          mutate(y=-y, pat=item_label_1) |&gt; select(pair_label,x,y,pat)\n\n    pat2 &lt;- df %&gt;%\n          mutate(pattern_2 = purrr::map(pattern_2, jsonlite::fromJSON)) %&gt;%\n          unnest(pattern_2) %&gt;%\n          mutate(y=-y, pat=item_label_2) |&gt; select(pair_label,x,y,pat)\n\n    pat &lt;- rbind(pat1,pat2)\n\n     pat |&gt; \n    ggplot(aes(x = x, y = y,fill=pat,col=pat)) +\n          geom_point(alpha=2) +\n          coord_cartesian(xlim = c(-25, 35.5), ylim = c(-25, 25)) +\n          theme_minimal() +\n          facet_wrap2(~pat,ncol=2,axes=\"all\") + \n          #theme_blank +\n          theme_void() + \n          theme(strip.text = element_text(size = 7,hjust=.5),\n                panel.spacing.x=unit(-7.3, \"lines\"), \n                #strip.background = element_rect(colour = \"black\", linewidth = 2),\n                legend.position = \"none\",\n        axis.line.y = element_line(colour = \"black\", linewidth = .1)) \n}\n\n\n\np5 &lt;- pairCounts |&gt; filter(n&gt;=34) \n\np5 |&gt; \n  arrange(mean_resp) |&gt;\n  relocate(pair_label,.after=sd) |&gt;\n  rename(\"Pair\"=pair_label, \"N\"=n, \"Mean Rating\"=mean_resp, \"SD\"=sd) |&gt;\n  mutate(Rating_Dist=Pair) |&gt; \n  #group_by(Pair) |&gt; \n  gt() |&gt; \n  tab_options(table.font.size = px(8L)) |&gt;\n    cols_width(\n      set ~ px(116),\n      Pair ~ px(415),\n      `N` ~ px(50),\n      `Mean Rating` ~ px(90),\n      SD ~ px(55)\n    ) |&gt;  \n    fmt_number(decimals = 1) |&gt; #fmt_integer() |&gt;\n    cols_align('left', columns = set) |&gt; \n    text_transform(\n      locations = cells_body(columns = Pair),\n      fn = function(column) {\n        map(column, pat_table_plot) |&gt;\n          ggplot_image(height = px(230), aspect_ratio = 1.8)\n      }\n    ) |&gt;\n    text_transform(\n      locations = cells_body(columns = Rating_Dist),\n      fn = function(column) {\n        map(column, plot_hist_pair) |&gt;\n          ggplot_image(height = px(150), aspect_ratio = 1)\n      }\n    ) |&gt;  \n     opt_interactive(page_size_default=5, \n       use_page_size_select= TRUE, use_search=TRUE, use_resizers=TRUE,use_filters=TRUE, page_size_values = c(5, 10, 25, 50, 100)) \n\n\n\n\n\n\n\n\n\n\n\nDisplay code# #| fig-cap: dot plots\n# #| fig-width: 10\n# #| fig-height: 12\n\n# d %&gt;% filter(trial==1) %&gt;%\n#   plot_dots()\n\n# d %&gt;% filter(trial==1) %&gt;%\n#   plot_dots2()\n\n# d %&gt;% filter(trial&lt;2) %&gt;%\n#   plot_dotsAll()\n\n\n\n\nDisplay code#| fig-width: 6\n#| fig-height: 9\n\n\n# d %&gt;% filter(file %in% unique(d$file[1])) %&gt;%\n#   plot_dotsAll()\n\n# plot_dotsAll_orig &lt;- function(df) {\n#   plots &lt;- list()\n\n#   for (i in 1:nrow(df)) {\n#     p1 &lt;- df[i, ] %&gt;%\n#       pivot_longer(cols = starts_with(\"x\"), names_to = \"dot\", values_to = \"x\") %&gt;%\n#       mutate(dot = as.numeric(str_remove(dot, \"x\"))) %&gt;%\n#       pivot_longer(cols = starts_with(\"y\"), names_to = \"dot2\", values_to = \"y\") %&gt;%\n#       mutate(dot2 = as.numeric(str_remove(dot2, \"y\"))) %&gt;%\n#       filter(dot == dot2) %&gt;%\n#       ggplot(aes(x = x, y = y)) +\n#       geom_point() +\n#       coord_cartesian(xlim = c(-25, 25), ylim = c(-25, 25)) +\n#       theme_minimal() +\n#       labs(title = df$id[i]) + theme_blank\n\n#     plots &lt;- append(plots, list(p1))\n#   }\n\n#   patchwork::wrap_plots(plots, ncol = 1)\n# }\n\n# mc24_proto |&gt; filter(file %in% unique(d$file[1])) %&gt;% plot_dotsAll_orig()",
    "crumbs": [
      "Dot Patterns",
      "Rating Data Check"
    ]
  },
  {
    "objectID": "Analysis/dotSim_Analysis.html#stucture-of-dataframe-after-merging-similarity-ratings-with-catlearn-accuracy",
    "href": "Analysis/dotSim_Analysis.html#stucture-of-dataframe-after-merging-similarity-ratings-with-catlearn-accuracy",
    "title": "Dot Pattern Ratings - data checks",
    "section": "Stucture of dataframe after merging similarity ratings with CatLearn accuracy",
    "text": "Stucture of dataframe after merging similarity ratings with CatLearn accuracy\n\nEach subject in the 2024 study has a similarity score for each of their 3 categories. (averaged over 2 comparisons with that categories prototype)\nThe same category similarity scores are then compared to their accuracy for each of the 5 Pattern Tyeps (old, prototype, new low, new med, new high)\n5 Pattern types * 3 Categories = 15 comparisons per subject\n\n\n\nTableÂ 3: Example of how data is structure after combining similarity ratings with CatLearn accuracy. 5 Pattern types * 3 Categories = 15 rows per subject in the 2024 study\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsbjCode\ncondit\nCategory\nPattern.Type\nn\nCatLearn Accuracy\nn_rating\nCategory Similarity\nsd\nitem\n\n\n\n316\nhigh\n1\nprototype\n1\n1\n60\n5.1\n2.6\n316_high_1_285\n\n\n316\nhigh\n1\nold\n9\n0.4\n60\n5.1\n2.6\n316_high_1_285\n\n\n316\nhigh\n1\nnew_low\n3\n0.3\n60\n5.1\n2.6\n316_high_1_285\n\n\n316\nhigh\n1\nnew_med\n6\n0.3\n60\n5.1\n2.6\n316_high_1_285\n\n\n316\nhigh\n1\nnew_high\n9\n0.4\n60\n5.1\n2.6\n316_high_1_285\n\n\n316\nhigh\n2\nprototype\n1\n0\n60\n3.8\n2\n316_high_2_327\n\n\n316\nhigh\n2\nold\n9\n0.7\n60\n3.8\n2\n316_high_2_327\n\n\n316\nhigh\n2\nnew_low\n3\n0.7\n60\n3.8\n2\n316_high_2_327\n\n\n316\nhigh\n2\nnew_med\n6\n0.2\n60\n3.8\n2\n316_high_2_327\n\n\n316\nhigh\n2\nnew_high\n9\n0.2\n60\n3.8\n2\n316_high_2_327\n\n\n316\nhigh\n3\nprototype\n1\n0\n60\n5.2\n2.4\n316_high_3_287\n\n\n316\nhigh\n3\nold\n9\n0.1\n60\n5.2\n2.4\n316_high_3_287\n\n\n316\nhigh\n3\nnew_low\n3\n0.7\n60\n5.2\n2.4\n316_high_3_287\n\n\n316\nhigh\n3\nnew_med\n6\n0\n60\n5.2\n2.4\n316_high_3_287\n\n\n316\nhigh\n3\nnew_high\n9\n0.3\n60\n5.2\n2.4\n316_high_3_287\n\n\n\n\n\n\n\nDisplay codecat_sim_test %&gt;% # round all numerics except sbjCode to 2 decimal places\n mutate(across(where(is.numeric), ~round(., 1))) |&gt; select(-id,-sim_group,-item_label) |&gt; \n  relocate(item,file, .after=sd) |&gt;\n  select(-Phase,-Block) |&gt; \n  rename(\"Category Similarity\" = resp, \"CatLearn Accuracy\" = Corr) |&gt;\n   DT::datatable(options = list(pageLength = 6))\n# cat_sim_test %&gt;% # round all numerics except sbjCode to 2 decimal places\n#      mutate(across(where(is.numeric), ~round(., 1))) |&gt; select(-id,-sim_group,-item_label) |&gt; \n#      filter(sbjCode==316) |&gt; \n#       relocate(item,file, .after=sd) |&gt;\n#       select(-Phase,-Block, -file) |&gt; \n#       rename(\"Category Similarity\" = resp, \"CatLearn Accuracy\" = Corr) |&gt; pander::pandoc.table(style=\"rmarkdown\",split.table=Inf)\n\n\nTableÂ 4: Example of how data is structure after combining similarity ratings with CatLearn accuracy. 5 Pattern types * 3 Categories = 15 rows per subject in the 2024 study",
    "crumbs": [
      "Dot Patterns",
      "Rating Data Check"
    ]
  },
  {
    "objectID": "Analysis/dotSim_compare.html",
    "href": "Analysis/dotSim_compare.html",
    "title": "Dot Pattern Similarity Analysis",
    "section": "",
    "text": "Codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, \n  conflicted, jsonlite,stringr, gt, knitr, kableExtra, \n  lubridate,ggh4x, lmerTest)\nwalk(c(\"dplyr\", \"lmerTest\"), conflict_prefer_all, quiet = TRUE)\noptions(digits=2, scipen=999, dplyr.summarise.inform=FALSE)\nwalk(c(\"fun_plot\"), ~ source(here::here(paste0(\"R/\", .x, \".R\"))))\nmc24_proto &lt;- read.csv(here(\"Stimulii\",\"mc24_prototypes.csv\")) |&gt; mutate(set=paste0(sbjCode,\"_\",condit)) \nsbj_cat &lt;- read.csv(here(\"data\",\"mc24_sbj_cat.csv\")) |&gt; mutate(condit=factor(condit,levels=c(\"low\",\"medium\",\"mixed\",\"high\") ))\n\ndfiles &lt;- list(path=list.files(here::here(\"data/dotSim_data\"),full.names=TRUE))\n\nd &lt;- map_dfr(dfiles$path, ~read.csv(.x))\n\nd &lt;- map_dfr(dfiles$path, ~{read.csv(.x) |&gt; \n    mutate(sfile=tools::file_path_sans_ext(basename(.x)))}) |&gt; \n  select(-trial_index, -internal_node_id,-trial_type) |&gt;\n   mutate(set = paste(str_extract(item_label_1, \"^\\\\d+\"),\n                     str_extract(item_label_1, \"[a-z]+\"), sep = \"_\")) |&gt;\n  mutate(pair_label = paste0(item_label_1,\"_\",item_label_2)) |&gt;\n  relocate(sbjCode,date,set,pair_label,trial,item_label_1,item_label_2,response,rt)\n\nsetCounts &lt;- d |&gt; \n  pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(set) |&gt; summarise(n=n_distinct(sbjCode),resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n))\n\n# length(unique(mc_proto$set)) # 304\nsetCounts2 &lt;- mc24_proto |&gt; group_by(set) |&gt; \n  slice_head(n=1) |&gt; \n  select(id,file,set) |&gt; \n  left_join(setCounts,by=\"set\") |&gt; \n  mutate(n = ifelse(is.na(n), 0, n), .groups=\"drop\") |&gt; \n  arrange(n) |&gt; ungroup()\n\npairCounts &lt;- d |&gt; \n  group_by(pair_label,set) |&gt; \n  summarise(n=n(),mean_resp=mean(response),sd=sd(response)) |&gt; arrange(desc(n)) |&gt; ungroup()\n\npatternAvg &lt;- d |&gt; \n  pivot_longer(cols=c(item_label_1, item_label_2), names_to=\"item_label\", values_to=\"item\") |&gt; \n  group_by(item,file) |&gt; \n  summarise(n_rating=n(),resp=mean(response),sd=sd(response)) |&gt; \n  arrange(desc(n_rating))\n\ncat_sim &lt;- sbj_cat |&gt; \n  mutate(item=item_label) |&gt; \n  left_join(patternAvg,by=c(\"file\",\"item\"))  |&gt; arrange(desc(n_rating)) |&gt;\n  #remove rows where n_rating is NA, or less than 4\n  filter(!is.na(n_rating),n_rating&gt;=12) |&gt; \n  mutate(sim_group = ifelse(resp&gt;5.5,\"Very Similar\",ifelse(resp&lt;3.9,\"Very Dissimilar\",\"Medium\"))) |&gt; \n  mutate(sim_group=factor(sim_group,levels=c(\"Very Dissimilar\",\"Medium\",\"Very Similar\"))) \n\ncat_sim_test &lt;- cat_sim |&gt; \n  filter(Phase==2) |&gt; \n  mutate(rate_quartile = as.factor(ntile(resp, 4))) |&gt;\n  group_by(id,condit) |&gt;\n  mutate(agg_corr=mean(Corr)) |&gt;\n  group_by(condit) |&gt; \n  mutate(quartile=ntile(agg_corr,4),ms=ntile(agg_corr,2))\nCode# cat_sim_test |&gt; \n#   group_by(condit,quartile) |&gt; \n#   summarize(mean_resp=mean(resp),mean_corr=mean(Corr),n=n_distinct(file), .groups=\"drop\") \n\n# cat_sim_test |&gt; \n#   group_by(sbjCode,condit,quartile,rate_quartile) |&gt;\n#   summarize(resp=mean(resp),corr=mean(Corr)) |&gt; \n#   mutate(quartile=factor(quartile,levels=c(1,2,3,4))) |&gt; \n#   ggplot(aes(x=quartile,y=corr,fill=condit)) + \n#   stat_bar+\n#  # geom_boxplot() +\n#   facet_wrap(~rate_quartile) +\n#   labs(y=\"Similarity Rating\",x=\"Performance Quartile\")\n\n\ncat_sim_test |&gt; \n  group_by(sbjCode,condit,quartile,rate_quartile) |&gt;\n  summarize(resp=mean(resp),corr=mean(Corr)) |&gt; \n  mutate(quartile=factor(quartile,levels=c(1,2,3,4))) |&gt; \n  ggplot(aes(x=condit,y=corr,fill=rate_quartile)) + \n  stat_bar +\n # geom_boxplot() +\n#   facet_wrap(~condit) +\n  labs(y=\"CatLearn Accuracy\",x=\"Training Condition\")\n\n\n\n\n\n\nCodecat_sim_test |&gt; \n  group_by(sbjCode,condit,ms,sim_group) |&gt;\n  summarize(resp=mean(resp),corr=mean(Corr)) |&gt; \n  mutate(ms=factor(ms,levels=c(1,2))) |&gt; \n  ggplot(aes(x=condit,y=corr,fill=sim_group)) + \n  stat_bar +\n  facet_wrap(~ms) +\n  labs(y=\"CatLearn Accuracy\",x=\"Training Condition\")",
    "crumbs": [
      "Dot Patterns",
      "Group Comparison"
    ]
  },
  {
    "objectID": "Analysis/dotSim_compare.html#correlations-with-accuracy-in-hu-nosofsky-2024",
    "href": "Analysis/dotSim_compare.html#correlations-with-accuracy-in-hu-nosofsky-2024",
    "title": "Dot Pattern Similarity Analysis",
    "section": "Correlations with Accuracy in Hu & Nosofsky 2024",
    "text": "Correlations with Accuracy in Hu & Nosofsky 2024\nAssess # of patterns in various binnings - e.g.Â quartile, decile\n\nCode# bin data by rating (resp) into quartiles\nt1 &lt;- cat_sim |&gt; \n  mutate(Quartile = ntile(resp, 4))|&gt;\n  group_by(Quartile) |&gt;\n  summarize(\"Avg. Similarity Rating\"=mean(resp),sd=sd(resp),n_ratings=n_distinct(file), .groups=\"drop\") \n\nt2 &lt;- cat_sim |&gt; \n  mutate(Decile = ntile(resp, 10))|&gt;\n  group_by(Decile) |&gt;\n  summarize(\"Avg. Similarity Rating\"=mean(resp),sd=sd(resp),n_ratings=n_distinct(file), .groups=\"drop\") \n\n\nt3 &lt;- cat_sim |&gt; \n  group_by(sim_group) |&gt;\n  summarize(\"Avg. Similarity Rating\"=mean(resp),sd=sd(resp),n_ratings=n_distinct(file), .groups=\"drop\") \n\nt1 |&gt; kbl(caption=\"Quartiles\")\n\n\nQuartiles\n\nQuartile\nAvg. Similarity Rating\nsd\nn_ratings\n\n\n\n1\n3.6\n0.55\n134\n\n\n2\n4.5\n0.17\n157\n\n\n3\n5.1\n0.17\n167\n\n\n4\n5.8\n0.37\n124\n\n\n\n\nCodet2 |&gt; kbl(caption=\"Deciles\")\n\n\nDeciles\n\nDecile\nAvg. Similarity Rating\nsd\nn_ratings\n\n\n\n1\n3.1\n0.45\n64\n\n\n2\n3.9\n0.13\n74\n\n\n3\n4.2\n0.08\n78\n\n\n4\n4.5\n0.08\n80\n\n\n5\n4.7\n0.07\n79\n\n\n6\n5.0\n0.06\n81\n\n\n7\n5.2\n0.07\n84\n\n\n8\n5.4\n0.06\n75\n\n\n9\n5.7\n0.09\n79\n\n\n10\n6.2\n0.33\n55\n\n\n\n\nCodet3 |&gt; kbl(caption=\"Extreme Groups\")\n\n\nExtreme Groups\n\nsim_group\nAvg. Similarity Rating\nsd\nn_ratings\n\n\n\nVery Dissimilar\n3.3\n0.49\n83\n\n\nMedium\n4.8\n0.45\n270\n\n\nVery Similar\n5.9\n0.36\n111\n\n\n\n\n\n\nCodeg1 &lt;- cat_sim_test |&gt; \n  group_by(sbjCode,condit) |&gt;\n  summarize(resp=mean(resp)) |&gt; \n  ggplot(aes(x=condit,y=resp)) + \n  #stat_bar + \n  geom_boxplot() +\n  labs(y=\"Similarity Rating\",x=\"2024 - Training Condition\")\n\n\ng2 &lt;- cat_sim_test |&gt; \n  group_by(sbjCode,condit,Category) |&gt;\n  summarize(resp=mean(resp)) |&gt; \n  mutate(Category=as.factor(Category)) |&gt; \n  ggplot(aes(x=condit,y=resp,fill=Category)) + \n  geom_boxplot() +\n  labs(y=\"Similarity Rating\",x=\"2024 - Training Condition\")\n\n\n\ng3 &lt;- cat_sim_test |&gt; \n  group_by(sbjCode,condit,Category,quartile) |&gt;\n  summarize(resp=mean(resp)) |&gt; \n  mutate(Category=as.factor(Category),quartile=factor(quartile,levels=c(1,2,3,4))) |&gt; \n  ggplot(aes(x=quartile,y=resp,fill=quartile)) + \n  stat_bar+\n # geom_boxplot() +\n  facet_wrap(~condit) +\n  labs(y=\"Similarity Rating\",x=\"Performance Quartile\")\n\n(g1/g2/g3) + plot_annotation(title=\"Similarity Rating breakdowns\") +\n  plot_layout(heights = c(1,1,2))\n\n\n\n\n\n\n\nRelationship between catLearn accuracy and binnings of similarity rating\n\ngenerally a negative correlation - higher simimlarity rating -&gt; lower accuracy\nquartiles and deciles are roughly evenly grouped bins, while the extreme similarity grouping has the bulk of the ratings in the medium group\n\nQuartiles and Deciles\n\nCodep3 &lt;- cat_sim_test |&gt; \n  mutate(Quartile = as.factor(ntile(resp, 4))) |&gt; \n  ggplot(aes(x=Quartile,y=Corr,fill=Quartile)) + \n  stat_bar + \n  facet_wrap(~Pattern.Type) + \n  labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Quartile\", title=\"Effect by Pattern Type\",fill=\"Similarity Rating Quartile\")\n\n\np4 &lt;- cat_sim_test |&gt; \n  mutate(Decile = as.factor(ntile(resp, 10))) |&gt; \n  ggplot(aes(x=Decile,y=Corr,fill=Decile)) + \n  stat_bar + \n  facet_wrap(~Pattern.Type) + \n  labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Decile\", title=\"Effect by Pattern Type\", fill=\"Similarity Rating Decile\")\n\np5 &lt;- cat_sim_test |&gt; \n  mutate(Quartile = as.factor(ntile(resp, 4))) |&gt; \n  ggplot(aes(x=Quartile,y=Corr,fill=Quartile)) + \n  stat_bar + \n  facet_wrap(~condit) + labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Quartile\", title=\"Effect by Training Condition\", fill=\"Similarity Rating Quartile\")\n\n\np6 &lt;- cat_sim_test |&gt; \n  mutate(Decile = as.factor(ntile(resp, 10))) |&gt; \n  ggplot(aes(x=Decile,y=Corr,fill=Decile)) + \n  stat_bar + \n  facet_wrap(~condit) + labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Decile\", title=\"Effect by Training Condition\", fill=\"Similarity Rating Decile\")\n\n\np7 &lt;- cat_sim_test |&gt; \n  mutate(Quartile = as.factor(ntile(resp, 4))) |&gt; \n  ggplot(aes(x=Quartile,y=Corr,fill=Quartile)) + \n  stat_bar + \n  facet_nested_wrap(~condit+Pattern.Type) + labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Quintile\", title=\"Effect by Training Condition and Pattern Type\")\n\np3 + p4\np5 + p6\np7\n\n\n\n\n\n\nFigureÂ 1: 2024 CatLearn accuracy by different similarity rating groups\n\n\n\n\n\n\n\n\n\nFigureÂ 2: 2024 CatLearn accuracy by different similarity rating groups\n\n\n\n\n\n\n\n\n\nFigureÂ 3: 2024 CatLearn accuracy by different similarity rating groups\n\n\n\n\nExtreme similarity rating groups\n\nCodep9 &lt;- cat_sim_test |&gt; \n  ggplot(aes(y=Corr,x=Pattern.Type, fill=sim_group)) + \n  stat_bar + labs(title=\"Group by Pattern Type\",y=\"CatLearn Accuracy\", fill=\"Similarity Rating Group\")\n\np10 &lt;- cat_sim_test |&gt; \n  ggplot(aes(y=Corr,x=condit, fill=sim_group)) + \n  stat_bar + labs(title=\"Group by Condit\",y=\"CatLearn Accuracy\", fill=\"Similarity Rating Group\")\n\np11 &lt;- cat_sim_test |&gt; \n  ggplot(aes(y=Corr,x=sim_group, fill=sim_group)) + \n  stat_bar + \n  facet_nested_wrap(~condit+Pattern.Type) +\n  labs(title=\"Separate by Condit and Pattern Type\",y=\"CatLearn Accuracy\", fill=\"Similarity Rating Group\") +\n  theme(axis.text.x = element_text(size=5,angle = 45, hjust = 0.5, vjust = 0.5))\n\n\n (p9 / p10)/p11 + plot_annotation(title=\"CatLearn accuracy by extreme similarity rating groups\") +\n  plot_layout(heights = c(1,1,2))\n\n\n\n\n\n\nFigureÂ 4: 2024 CatLearn accuracy by different similarity rating groups\n\n\n\n\n\n\nlearning curves\nIndividual Learning Curves\n\n\n\n\nCode# trSim1 &lt;- cat_sim |&gt; filter(Phase==1) |&gt; \n#   group_by(condit,Block) |&gt; \n#   mutate(Quartile = as.factor(ntile(resp, 4))) |&gt; \n#   ggplot(aes(x=Block,y=Corr, fill=Quartile)) + stat_bar+  facet_wrap(~condit)  +\n#    labs(x=\"Training Block\", y=\"CatLearn Accuracy\",fill=\"Similarity Rating Quartile\")\n\n\n# trSim2 &lt;- cat_sim |&gt; filter(Phase==1) |&gt; \n#   group_by(condit,Block) |&gt; \n#   ggplot(aes(x=Block,y=Corr, fill=sim_group)) +\n#    stat_bar+  \n#    facet_wrap(~condit) +\n#   labs(x=\"Training Block\", y=\"CatLearn Accuracy\",fill=\"Similarity Rating Group\")\n\n\n\n\ntrSim1 &lt;- cat_sim |&gt; filter(Phase==1) |&gt; \n  group_by(condit,Block) |&gt; \n  mutate(Quartile = as.factor(ntile(resp, 4))) |&gt; \n  ggplot(aes(x=Block,y=Corr, col=Quartile)) + \n    stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\")+ \n   facet_wrap(~condit)  +\n   labs(x=\"Training Block\", y=\"CatLearn Accuracy\",fill=\"Similarity Rating Quartile\",title = \"Training Accuracy by Block and Similarity Quartile\")\n\ntrSim2 &lt;- cat_sim |&gt; filter(Phase==1) |&gt; \n  group_by(condit,Block) |&gt; \n  ggplot(aes(x=Block,y=Corr, col=sim_group)) +\n      stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\")+ \n   facet_wrap(~condit) +\n  labs(x=\"Training Block\", y=\"CatLearn Accuracy\",fill=\"Similarity Rating Group\", title=\"Training Accuracy by Block and Similarity Extreme similarity Grouping\")\n\n\ntrSim1/trSim2\n\n\n\n\n\n\nFigureÂ 5: Training accuracy by block and similarity rating\n\n\n\n\n\n\n\nCode trIndv &lt;- cat_sim |&gt; filter(Phase==1, !(sim_group==\"Medium\")) |&gt; \n  group_by(condit,Block) |&gt; \n  mutate(Quartile = as.factor(ntile(resp, 4))) |&gt; \n  ggplot(aes(x=Block,y=Corr, col=sim_group)) + \n      stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\")+ \n   facet_wrap2(~condit+sim_group+sbjCode) +\n  labs(x=\"Training Block\", y=\"CatLearn Accuracy\",fill=\"Similarity Rating Group\", title=\"Training Accuracy by Block and Similarity Extreme similarity Grouping\")\n\ntrIndv \n\n#cat_sim |&gt; filter(Phase==1) |&gt; group_by(id) |&gt; summarize(n_sim = n_distinct(sim_group)) |&gt; arrange(desc(n_sim)) |&gt; head(10)\n\n# cat_sim |&gt; filter(Phase==1) |&gt; group_by(id) |&gt; mutate(n_sim = n_distinct(sim_group)) |&gt; filter(n_sim&gt;1)  |&gt; group_by(condit,Block) |&gt; \n#   ggplot(aes(x=Block,y=Corr, col=sim_group)) + \n#       stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n#   stat_summary(geom=\"line\",fun=\"mean\")+ \n#    facet_wrap2(~condit+sbjCode)\n\n\n\n\n\n\nFigureÂ 6: Training accuracy by block and similarity rating\n\n\n\n\n\n\n\nCorrelations between similarity ratings and CatLearn accuracy\n\nCodep1 &lt;- cat_sim_test |&gt; ggplot(aes(x=resp,y=Corr,col=Pattern.Type,fill=Pattern.Type)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating\")\n\np2 &lt;- cat_sim_test |&gt; ggplot(aes(x=resp,y=Corr, col=Pattern.Type,fill=Pattern.Type)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  facet_wrap(~condit) + labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating\")\n\n\np3 &lt;- cat_sim_test |&gt; \nmutate(Decile = ntile(resp, 10)) |&gt; \nggplot(aes(x=Decile,y=Corr, col=Pattern.Type,fill=Pattern.Type)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Decile\")\n\n\np4 &lt;- cat_sim_test |&gt; \nmutate(Decile = ntile(resp, 10)) |&gt; \nggplot(aes(x=Decile,y=Corr, col=condit,fill=condit)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n labs(y=\"CatLearn Accuracy\", x=\"Similarity Rating Decile\", fill=\"Training Condition\", col=\"Training Condition\")\n\n\n(p1+p2) / (p3+p4)\n\n\n\n\n\n\nFigureÂ 7: Correlations between similarity ratings and CatLearn accuracy\n\n\n\n\n\nCode#cor(cat_sim$resp,cat_sim$Corr)\n\n m1 &lt;- lmer(Corr ~ resp + (1|sbjCode), data=cat_sim)\n summary(m1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Corr ~ resp + (1 | sbjCode)\n   Data: cat_sim\n\nREML criterion at convergence: -1609\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.792 -0.603  0.101  0.644  3.219 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n sbjCode  (Intercept) 0.0308   0.175   \n Residual             0.0482   0.220   \nNumber of obs: 13680, groups:  sbjCode, 303\n\nFixed effects:\n               Estimate  Std. Error          df t value            Pr(&gt;|t|)    \n(Intercept)     0.95976     0.02227  3208.81325    43.1 &lt;0.0000000000000002 ***\nresp           -0.06268     0.00412 10938.29368   -15.2 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nresp -0.888\n\nCode m1 &lt;- lmer(Corr ~ resp + (1|Pattern.Type) +  (1|sbjCode), data=cat_sim)\n summary(m1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Corr ~ resp + (1 | Pattern.Type) + (1 | sbjCode)\n   Data: cat_sim\n\nREML criterion at convergence: -2254\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-4.498 -0.561  0.128  0.651  3.023 \n\nRandom effects:\n Groups       Name        Variance Std.Dev.\n sbjCode      (Intercept) 0.03085  0.1756  \n Pattern.Type (Intercept) 0.00638  0.0799  \n Residual                 0.04589  0.2142  \nNumber of obs: 13680, groups:  sbjCode, 303; Pattern.Type, 5\n\nFixed effects:\n               Estimate  Std. Error          df t value             Pr(&gt;|t|)\n(Intercept)     0.99368     0.04196     7.49398    23.7          0.000000026\nresp           -0.06263     0.00403 11185.52704   -15.5 &lt; 0.0000000000000002\n               \n(Intercept) ***\nresp        ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nresp -0.461\n\nCode m1 &lt;- lmer(Corr ~ resp*condit +  (1|sbjCode) + (1+condit|Pattern.Type), data=cat_sim)\n summary(m1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Corr ~ resp * condit + (1 | sbjCode) + (1 + condit | Pattern.Type)\n   Data: cat_sim\n\nREML criterion at convergence: -2562\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-4.446 -0.556  0.133  0.637  3.038 \n\nRandom effects:\n Groups       Name         Variance Std.Dev. Corr             \n sbjCode      (Intercept)  0.01938  0.1392                    \n Pattern.Type (Intercept)  0.01211  0.1100                    \n              conditmedium 0.00465  0.0682   -0.81            \n              conditmixed  0.00372  0.0610   -0.58  0.95      \n              condithigh   0.00800  0.0895   -0.75  0.99  0.98\n Residual                  0.04514  0.2125                    \nNumber of obs: 13680, groups:  sbjCode, 303; Pattern.Type, 5\n\nFixed effects:\n                     Estimate  Std. Error          df t value     Pr(&gt;|t|)    \n(Intercept)           0.99306     0.06355    10.77285   15.63 0.0000000096 ***\nresp                 -0.03844     0.00760 10463.25384   -5.06 0.0000004253 ***\nconditmedium         -0.01335     0.06354    66.83902   -0.21      0.83427    \nconditmixed           0.03641     0.06391   107.52782    0.57      0.57006    \ncondithigh            0.00155     0.07088    36.96070    0.02      0.98262    \nresp:conditmedium    -0.02116     0.01064  9204.92771   -1.99      0.04664 *  \nresp:conditmixed     -0.04082     0.01106  9631.85840   -3.69      0.00022 ***\nresp:condithigh      -0.04022     0.01117  7914.81902   -3.60      0.00032 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) resp   cndtmd cndtmx cndthg rsp:cndtmd rsp:cndtmx\nresp        -0.575                                                  \nconditmedim -0.700  0.575                                           \nconditmixed -0.589  0.572  0.593                                    \ncondithigh  -0.686  0.515  0.630  0.608                             \nrsp:cndtmdm  0.411 -0.714 -0.797 -0.408 -0.368                      \nrsp:cndtmxd  0.395 -0.687 -0.395 -0.829 -0.358  0.491               \nrsp:cndthgh  0.391 -0.680 -0.391 -0.396 -0.757  0.486      0.469    \noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\nCode# m1 &lt;- lmer(Corr ~ sim_group +  (1|sbjCode), data=cat_sim)\n# summary(m1)\n\n# m1 &lt;- lmer(Corr ~ sim_group*condit +  (1|sbjCode), data=cat_sim)\n# summary(m1)\n\n# m1 &lt;- lmer(Corr ~ sim_group*condit*Pattern.Type +  (1|sbjCode), data=cat_sim)\n# summary(m1)\n\n\n\nCodecat_sim_test |&gt; \n  mutate(Quartile = as.factor(ntile(resp, 4))) |&gt; group_by(condit) |&gt; summarise(mean_rating=mean(resp),mean_acc=mean(Corr))\n\n# A tibble: 4 Ã 3\n  condit mean_rating mean_acc\n  &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 low           4.81    0.814\n2 medium        4.71    0.711\n3 mixed         4.81    0.710\n4 high          4.86    0.581\n\nCodecat_sim_test |&gt; \n  mutate(Quartile = as.factor(ntile(resp, 4))) |&gt; group_by(condit,Pattern.Type) |&gt; summarise(mean_rating=mean(resp),mean_acc=mean(Corr))\n\n# A tibble: 20 Ã 4\n# Groups:   condit [4]\n   condit Pattern.Type mean_rating mean_acc\n   &lt;fct&gt;  &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;\n 1 low    new_high            4.81    0.637\n 2 low    new_low             4.81    0.873\n 3 low    new_med             4.81    0.771\n 4 low    old                 4.81    0.860\n 5 low    prototype           4.81    0.926\n 6 medium new_high            4.71    0.631\n 7 medium new_low             4.71    0.745\n 8 medium new_med             4.71    0.692\n 9 medium old                 4.71    0.698\n10 medium prototype           4.71    0.791\n11 mixed  new_high            4.81    0.593\n12 mixed  new_low             4.81    0.760\n13 mixed  new_med             4.81    0.696\n14 mixed  old                 4.81    0.697\n15 mixed  prototype           4.81    0.806\n16 high   new_high            4.86    0.512\n17 high   new_low             4.86    0.637\n18 high   new_med             4.86    0.587\n19 high   old                 4.86    0.532\n20 high   prototype           4.86    0.636",
    "crumbs": [
      "Dot Patterns",
      "Group Comparison"
    ]
  },
  {
    "objectID": "Simulation/dp_24_model.html",
    "href": "Simulation/dp_24_model.html",
    "title": "exemplar_baseline",
    "section": "",
    "text": "Codepacman::p_load(dplyr, purrr, tidyr, ggplot2, here, patchwork, conflicted, knitr, grateful)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n\n\nCode# Distance function using Euclidean distance\ndist.euclidean &lt;- function(e, p) {\n  sqrt(sum((e - p)^2))\n}\n\n# Similarity function using exponential decay\nsimilarity &lt;- function(e, p, c) {\n  exp(-c * dist.euclidean(e, p))\n}\n\n# Generating Prototypes\ngenerate_prototypes &lt;- function(num_categories, num_dimensions, between) {\n  matrix(runif(num_categories * num_dimensions, min = 0, max = between), \n         nrow = num_categories, ncol = num_dimensions)\n}\n\ngenerate_distorted_patterns &lt;- function(prototype, num_samples, distortion_level, within) {\n  num_dimensions &lt;- length(prototype)\n  t(sapply(1:num_samples, function(x) {\n    noise &lt;- rnorm(num_dimensions) * within * distortion_level\n    prototype + noise\n  }))\n}\n\n# Categorization Probability Function\ncategorization_probability &lt;- function(test_pattern, training_patterns, gamma, c) {\n  # Calculate the summed similarities for each category\n  summed_similarities &lt;- apply(training_patterns, 3,function(category_patterns) {\n    sum(sapply(1:nrow(category_patterns), function(i) {\n      similarity(test_pattern, category_patterns[i, ], c)\n    }))\n  })\n  # Raise the summed similarities to the power of gamma\n  numerator &lt;- summed_similarities^gamma\n  denominator &lt;- sum(summed_similarities^gamma)\n  \n  # Return the probability of the test_pattern being in category A\n  probs &lt;- numerator / denominator\n  return (probs)\n}\n\n\n# Simulation Function\nsimulate &lt;- function(num_categories, num_samples, training_distortion_level, within, between, c, gamma, nd=6) {\n  prototypes &lt;- generate_prototypes(num_categories, num_dimensions=nd, between=between)\n  training_patterns &lt;- array(dim = c(num_samples, ncol(prototypes), num_categories))\n  \n  for (cat in 1:num_categories) {\n    training_patterns[,,cat] &lt;- generate_distorted_patterns(prototypes[cat,], num_samples, training_distortion_level, within)\n  }\n  \n  # Assess Testing Performance Here\n  test_performance &lt;- list()\n  categories &lt;- seq_len(num_categories)\n  types_of_patterns &lt;- c(\"old\", \"prototype\", \"new_low\", \"new_medium\", \"new_high\")\n  distortion_levels_test &lt;- c(1.20, 2.80, 4.60) # low, medium, high distortion levels\n  #distortion_levels_test &lt;- c(4, 6, 7.7)\n  \n  for (type in types_of_patterns) {\n    for (cat in categories) {\n      if (type == \"old\") {\n        test_patterns &lt;- matrix(training_patterns[sample(1:num_samples, 27),,cat])\n        #colMeans(test_patterns)\n      } else if (type == \"prototype\") {\n        test_patterns &lt;- matrix(prototypes[cat,], nrow = 1, ncol = ncol(prototypes), byrow = TRUE)\n      } else {\n        distortion_level &lt;- switch(type,\n                                   \"new_low\" = distortion_levels_test[1],\n                                   \"new_medium\" = distortion_levels_test[2],\n                                   \"new_high\" = distortion_levels_test[3])\n        test_patterns &lt;- generate_distorted_patterns(prototypes[cat,], 27, distortion_level, within)\n      }\n      # Calculate categorization probabilities for the test patterns\n      probs &lt;- apply(test_patterns, 1, categorization_probability, training_patterns = training_patterns, gamma = gamma, c = c)\n      # Count correct classifications\n      #correct_classifications &lt;- sum(apply(probs, 2, which.max) == cat)\n      prob_cat &lt;- probs[cat,]\n      \n      test_performance[[paste(type, \"cat\", cat, sep = \"_\")]] &lt;- mean(prob_cat) #correct_classifications / nrow(test_patterns)\n    }\n  }\n  \n  # Combine results into a single data frame\n  test_performance_df &lt;- data.frame(\n    type = rep(types_of_patterns, each = num_categories),\n    category = rep(categories, times = length(types_of_patterns)),\n    correct_classifications = unlist(test_performance)\n  )\n  \n  return(test_performance_df)\n}\n\n\n\nCode# Simulation Parameters\nnum_categories &lt;- 3\nnum_dimensions &lt;- 8\nnum_samples &lt;- 300 # number of samples per category\nbetween &lt;- 2\nwithin &lt;- 0.210\ngamma &lt;- 5.0\nc &lt;- 0.475\ndistortion_levels &lt;- c(4, 6, 7.7) # low, medium, high distortion levels\n#distortion_levels &lt;- c(1, 5, 7.7)\nnsim &lt;- 100\n\n\n\n# List to store performance results from each distortion level\nperformance_results &lt;- list()\n\n# Simulate for each distortion level\nfor (distortion_level in distortion_levels) {\n  results &lt;- replicate(nsim, simulate(num_categories, num_samples, distortion_level, within, between, c, gamma, nd=num_dimensions), simplify = FALSE)\n  performance_results[[as.character(distortion_level)]] &lt;- do.call(rbind, results)\n}\n\n# Combining results\ncombined_results &lt;- bind_rows(\n  lapply(names(performance_results), function(name) {\n    transform(performance_results[[name]], distortion_level = as.numeric(name))\n  }),\n  .id = \"distortion_level\"\n) |&gt; mutate(Pattern_Token = factor(type,levels=c(\"old\",\"prototype\",\"new_low\",\"new_medium\",\"new_high\")))\n\n\n\nyt &lt;- round(seq(0,1,length.out=7), 2)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),scale_y_continuous(breaks=yt))\n# Visualizing the results\nggplot(combined_results, aes(x = Pattern_Token, y = correct_classifications, fill = factor(distortion_level))) +\n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(x = \"Pattern Type\", y = \"Correct Classifications (%)\", fill = \"Training Distortion Level\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set1\") +ggtitle(paste0(\"nsim: \",nsim,\"; gamma: \",gamma,\"; c: \",c,\"; within: \",within,\"; between: \",between,\"; num_samples: \",num_samples, \" nd: \", num_dimensions)) +eg\n\n\n\nCodesaveRDS(sim_nosof1000, file = \"sim_nosof1000.rds\")\n\n\ngenerate_distorted_patterns &lt;- function(prototype, num_samples, distortion_level, within) { num_dimensions &lt;- length(prototype) noise &lt;- matrix(rnorm(num_samples * num_dimensions), nrow = num_samples) * within * distortion_level matrix(rep(prototype, each = num_samples), nrow = num_samples, ncol = num_dimensions) + noise }\ncategorization_probability &lt;- function(test_pattern, training_patterns, gamma, c) { # Compute all similarities at once using matrix operations differences = array(dim = dim(training_patterns)) for (i in 1:dim(training_patterns)[3]) { differences[,,i] = training_patterns[,,i] - test_pattern } distances = sqrt(rowSums(differences^2, dims = 2)) summed_similarities = exp(-c * distances) summed_similarities = apply(summed_similarities, 2, sum)\n# Calculate probabilities numerator &lt;- summed_similarities^gamma denominator &lt;- sum(numerator)\nprobs &lt;- numerator / denominator return(probs) }"
  },
  {
    "objectID": "Analysis/all_exp.html",
    "href": "Analysis/all_exp.html",
    "title": "Combined Experiments",
    "section": "",
    "text": "Display codepacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table,readr,here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\nlmc22 &lt;- readRDS(here(\"data\",\"lmc22.rds\")) |&gt; mutate(Pattern_Token = case_when(\n      Pattern.Type2 == \"Trained.Med\" ~ \"old\",\n      Pattern.Type2 == \"Prototype\"~ \"prototype\",\n      Pattern.Type2 == \"New.Low\"  ~ \"new_low\",\n      Pattern.Type2 == \"New.Med\" ~ \"new_med\",\n      Pattern.Type2 == \"New.High\" ~ \"new_high\"\n    )) #rename(\"Pattern_Token\"=Pattern.Type2)\nmc24 &lt;- readRDS(here(\"data\",\"mc24.rds\"))\nfp24 &lt;- readRDS(here(\"data\",\"fixed_proto24.rds\"))\n\nall_data &lt;- fp24 |&gt; select(-pool_index) |&gt; rbind(mc24) |&gt; rbind(lmc22)\nall_data$Pattern_Token = factor(all_data$Pattern_Token,levels=c(\"old\",\"prototype\",\"new_low\",\"new_med\",\"new_high\",\"special\")) \nall_data$condit = factor(all_data$condit,levels=c(\"low\",\"medium\",\"mixed\",\"high\",\"nrep\",\"rep\"))\n\ntheme_nice &lt;- function() {\n  theme_minimal(base_family = \"Manrope\") +\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.title = element_text(family = \"Manrope Extrabold\", face = \"plain\", size = rel(1.35)),\n      plot.subtitle = element_text(family = \"Manrope Medium\", face = \"plain\", size = rel(1.2)),\n      axis.title = element_text(family = \"Manrope SemiBold\", face = \"plain\", size = rel(1)),\n      axis.title.x = element_text(hjust = .5),\n      axis.title.y = element_text(hjust = .5),\n      axis.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(0.8)),\n      strip.text = element_text(\n        family = \"Manrope\", face = \"bold\",\n        size = rel(.95), hjust = 0\n      ),\n      legend.position = \"top\",\n      legend.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(0.95)),\n      strip.background = element_rect(fill = \"grey90\", color = NA)\n    )\n}\n\ntheme_nice_b &lt;- function() {\n  theme_minimal(base_family = \"Manrope\") +\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.title = element_text(family = \"Manrope Extrabold\", face = \"plain\", size = rel(1.55)),\n      plot.subtitle = element_text(family = \"Manrope Medium\", face = \"plain\", size = rel(1.2)),\n      axis.title = element_text(family = \"Manrope SemiBold\", face = \"plain\", size = rel(1)),\n      axis.title.x = element_text(hjust = .5),\n      axis.title.y = element_text(hjust = .5),\n      axis.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(0.9)),\n      strip.text = element_text(\n        family = \"Manrope\", face = \"bold\",\n        size = rel(1.2), hjust = 0\n      ),\n      legend.position = \"top\",\n      legend.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(1.3)),\n      strip.background = element_rect(fill = \"grey90\", color = NA)\n    )\n}\n\n\n\n\ntheme_set(theme_nice())\n\nyt &lt;- round(seq(0,1,length.out=7), 2)\nxt &lt;- seq(1,10,1)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),\n           scale_y_continuous(breaks=yt,limits=c(0,1)),\n           scale_x_continuous(breaks=xt))",
    "crumbs": [
      "Learning Analysis",
      "Combo"
    ]
  },
  {
    "objectID": "Task/Task.html",
    "href": "Task/Task.html",
    "title": "Task",
    "section": "",
    "text": "A preview of the judgement task is included below. The task can be restarted by refreshing the page.\nClick here to open the task in a new window: dot_task",
    "crumbs": [
      "Task",
      "Task"
    ]
  },
  {
    "objectID": "Task/Task.html#pattern-judgement-task",
    "href": "Task/Task.html#pattern-judgement-task",
    "title": "Task",
    "section": "Pattern Judgement Task",
    "text": "Pattern Judgement Task\n\n\n\n\ndot_task",
    "crumbs": [
      "Task",
      "Task"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dot Pattern Similarity Project",
    "section": "",
    "text": "Dot Pattern Plots\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDot Pattern Ratings - data checks\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDot Pattern Similarity Analysis\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHu & Nosofsky 2022\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHu & Nosofsky 2024\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2024\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "Stimulii/check_dots.html",
    "href": "Stimulii/check_dots.html",
    "title": "Dot Pattern Variability",
    "section": "",
    "text": "pacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\ncol.names = c(\"Phase\",\"Block\",\"BlockTrial\",\"Pattern\",\"Category\",\"Pattern.Token\",\"distortion\",\"Response\",\"Corr\",\"rt\",\n              \"x1\",\"y1\",\"x2\",\"y2\",\"x3\",\"y3\",\"x4\",\"y4\",\"x5\",\"y5\",\"x6\",\"y6\",\"x7\",\"y7\",\"x8\",\"y8\",\"x9\",\"y9\", \"file\", \"condit\", \"sbjCode\")\n\nd &lt;- read.table(here::here(\"data/dot_4conds_random/dot_cond4_sub99.txt\")) |&gt;\n  mutate(file=\"dot_cond4_sub99\",condit=\"4\",sbjCode=\"tgtest\") |&gt; purrr::set_names(col.names) |&gt; group_by(sbjCode, condit) |&gt;\n  mutate(trial = row_number()) |&gt; \n  relocate(\"sbjCode\", \"condit\", \"trial\") \n\n\ndCat &lt;- d |&gt; \n  mutate(\n    phase = case_when(\n      Phase == \"1\" ~ \"Training\",\n      Phase == \"2\" ~ \"Test\"\n    ), \n    Stage = case_when(\n      trial %in% 1:90 ~ \"Start\",\n      trial %in% 91:180 ~ \"Middle\",\n      trial %in% 181:270 ~ \"End\",\n      trial %in% 271:354 ~ \"Test\"\n    ),\n    pattern = case_when(\n      Pattern == \"1\" ~ \"old\",\n      Pattern == \"2\" ~ \"prototype\",\n      Pattern == \"3\" ~ \"new_low\",\n      Pattern == \"4\" ~ \"new_med\",\n      Pattern == \"5\" ~ \"new_high\"\n    ),\n    distortion = recode(distortion,\n                        `0` = \"prototype\",\n                        `1` = \"low\",\n                        `2` = \"med\",\n                        `3` = \"high\"),\n    Pattern_Token = case_when(\n      pattern == \"old\" & Pattern.Token %in% 1:90 ~ \"old\",\n      pattern == \"prototype\" & Pattern.Token == 0 ~ \"prototype\",\n      pattern == \"new_low\" & Pattern.Token %in% 1:3 ~ \"new_low\",\n      pattern == \"new_med\" & Pattern.Token %in% 1:6 ~ \"new_med\",\n      pattern == \"new_high\" & Pattern.Token %in% 1:9 ~ \"new_high\"\n    ),\n    condit = recode(condit,\n                    \"cond1\" = \"low\",\n                    \"cond2\" = \"medium\",\n                    \"cond3\" = \"high\",\n                    \"cond4\" = \"mixed\")\n  ) |&gt; \n  relocate(Stage, .after=trial) |&gt; relocate(Pattern_Token, pattern, .after=Pattern.Token)\n\ndCat$Pattern_Token = factor(dCat$Pattern_Token,levels=c(\"old\",\"prototype\",\"new_low\",\"new_med\",\"new_high\")) \ndCat &lt;- dCat |&gt; mutate(exp=\"mc24\",\n                       id=paste0(sbjCode,\".\",condit))  |&gt;\n  relocate(id,sbjCode,exp,condit,Phase,phase,Stage,trial,\n           Block,BlockTrial,Pattern_Token,Pattern.Token,Pattern,pattern,distortion,\n           Category,Response,Corr,rt)\n  \n\nteg_test_patterns &lt;- dCat |&gt; \n  ungroup() |&gt;\n  rename(Pattern.Type=\"Pattern_Token\") |&gt;\n  mutate(Pattern.Type=forcats::fct_relevel(Pattern.Type,\"prototype\",\"old\",\"new_low\",\"new_med\",\"new_high\")) |&gt;\n  mutate(item_label = paste(sbjCode,condit,Category,trial,sep=\"_\")) |&gt;\n  select(id,sbjCode,item_label,condit,exp,file,Phase,trial,Block,Pattern.Type,Category,Response,Corr,x1:y9) |&gt;\n  arrange(sbjCode,trial,condit,Category)\n\n\n\nwrite.csv(teg_test_patterns |&gt; slice_head(n=9),here(\"Stimulii\",\"teg_test_patterns.csv\"), row.names = FALSE)\n\n\n\nids &lt;- unique(teg_test_patterns$id)\npat_themes &lt;- list(theme_minimal(),xlim(-25, 25),ylim(-25, 25),\n                        labs(x = \"X Coordinate\", y = \"Y Coordinate\"),\n                   coord_fixed(),guides(alpha = FALSE))\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n pat_long &lt;- teg_test_patterns |&gt; \n    filter(Block==1,Phase==1) |&gt;\n   select(id, condit, Category,Phase, item_label,trial,Block,Pattern.Type, x1:y9) |&gt;\n   group_by(id, trial,item_label,condit, Category,Phase, Pattern.Type) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -id,-Phase,-Block, -condit,-trial,-item_label, -Category,-Pattern.Type) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number))\n \n pat_long |&gt; \n   ggplot(aes(x = x, y = y,col=Pattern.Type)) +\n   geom_point() + # Add dots\n   ggh4x::facet_wrap2(~trial+item_label) + # Create a grid of plots, with subjects by rows and categories by columns\n   pat_themes + labs(title=\"Prototypes from Category 1 - with distortions\")\n\n\n\n\n\n\n\nAttempt flip to match MATLAB - this works\n\npat_long |&gt; \n   mutate(y=-y) |&gt;\n   ggplot(aes(x = x, y = y,col=Pattern.Type)) +\n   geom_point() + # Add dots\n   ggh4x::facet_wrap2(~trial+item_label) + # Create a grid of plots, with subjects by rows and categories by columns\n   pat_themes + labs(title=\"Prototypes from Category 1 - with distortions\")\n\n\n\n\n\n\n\n\n\ncat-learn24",
    "crumbs": [
      "Dot Patterns",
      "basic"
    ]
  },
  {
    "objectID": "Stimulii/instruction_examples.html",
    "href": "Stimulii/instruction_examples.html",
    "title": "Dot Pattern Plots",
    "section": "",
    "text": "Display codepacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table,readr,here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n# lmc22 &lt;- readRDS(here(\"data\",\"lmc22.rds\"))\n# mc24 &lt;- readRDS(here(\"data\",\"mc24.rds\"))\n\nlmc22_prototypes &lt;- read.csv(here(\"Stimulii\",\"lmc22_prototypes.csv\"))\nmc24_prototypes &lt;- read.csv(here(\"Stimulii\",\"mc24_prototypes.csv\"))\n\npat_themes &lt;- list(theme_minimal(),xlim(-25, 25),ylim(-25, 25),\n                        labs(x = \"X Coordinate\", y = \"Y Coordinate\"),\n                   coord_fixed(),guides(alpha = FALSE))\n\n\n\n\nDisplay codeproto_long &lt;- lmc22_prototypes |&gt; \n   select(item_label, x1:y9) |&gt;\n   group_by(item_label) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -item_label) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number))\n \nproto_long |&gt; \n  filter(item_label %in% unique(proto_long$item_label)[1:100]) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=.75) + \n   ggh4x::facet_nested_wrap(~item_label) +\n   pat_themes + labs(title=\"Prototypes from Category 1 - with distortions\")\n\n\n\nPrototypes and their distortions\n\n\n\n\n\nDisplay codecircle &lt;- c(\"10_nrep_2_287\",\"12_nrep_3_270\", \"27_rep_3_263\")\nhsplit &lt;- c(\"14_nrep_2_258\",\"13_rep_1_227\", \"2_nrep_3_261\", \"14_nrep_1_245\",\"34_nrep_3_229\")\nvsplit &lt;- c(\"1_rep_2_262\", \"22_nrep_2_239\", \"12_nrep_1_248\", \"11_rep_3_264\",\"38_nrep_3_288\",\"32_rep_3_286\")\ndsplit &lt;- c(\"20_nrep_2_236\", \"20_rep_3_247\")\ntower &lt;- c(\"11_rep_2_281\",\"25_rep_3_248\",\"47_rep_3_235\")\ntree &lt;- c(\"28_nrep_1_234\",\"41_nrep_2_285\",\"40_rep_2_272\")\nqmark &lt;- c(\"12_nrep_2_258\",\"20_nrep_1_267\",\"35_nrep_1_238\")\ndiag &lt;- c(\"24_nrep_1_242\",\"16_nrep_3_276\", \"26_nrep_3_263\",\"48_nrep_3_233\",\"47_nrep_1_227\")\nvert &lt;- c(\"11_rep_1_257\", \"25_rep_2_250\",\"48_nrep_3_233\")\nhoriz &lt;- c(\"22_rep_1_263\",\"4_nrep_2_236\")\nonemass &lt;- c(\"13_rep_1_227\", \"16_rep_1_241\",\"18_nrep_2_253\",\"47_nrep_2_264\")\ntriag &lt;- c(\"18_nrep_3_254\",\"46_rep_3_246\")\nincomp &lt;- c(\"22_nrep_3_235\",\"12_rep_1_282\",\"33_rep_2_282\", \"44_nrep_1_263\")\n\n\nproto_long |&gt; \n  filter(item_label %in% c(circle, hsplit, vsplit, dsplit, tower, \n                           qmark, diag, vert, horiz, onemass, triag, incomp,tree)) |&gt;\n  mutate(plabel = case_when(\n    item_label %in% circle ~ \"Circle\",\n    item_label %in% hsplit ~ \"Horizontal Split\",\n    item_label %in% vsplit ~ \"Vertical Split\",\n    item_label %in% dsplit ~ \"Diagonal Split\",\n    item_label %in% tower ~ \"Tower\",\n    item_label %in% triag ~ \"triag\",\n    item_label %in% tree ~ \"tree\",\n    item_label %in% triag ~ \"Trianglish\",\n    item_label %in% qmark ~ \"Question Mark\",\n    item_label %in% diag ~ \"Diagonal\",\n    item_label %in% vert ~ \"Vertical\",\n    item_label %in% horiz ~ \"Horizontal\",\n    item_label %in% incomp ~ \"incomp\",\n    item_label %in% onemass ~ \"One Mass\")) |&gt;\n   ggplot(aes(x = x, y = y,col=plabel)) +\n   geom_point(size=.75) + \n   ggh4x::facet_nested_wrap(~plabel+item_label) +\n   pat_themes + labs(title=\"Prototypes with Distinctive Patterns\") +\n  theme(legend.position = \"top\")\n\n\n\nPrototypes with distinctive patterns\n\n\n\n\n\nDisplay codehsim1 &lt;- circle[2:3]\nhsim2 &lt;- onemass[3:4]\nmsim1 &lt;- vsplit[1:2]\nlsim1 &lt;- c(diag[1],hsplit[3])\nlsim2 &lt;- c(circle[1],tower[3])\n\nproto_long |&gt; \n  filter(item_label %in% c(hsim1, hsim2, msim1, lsim1, lsim2)) |&gt;\n  mutate(plabel = case_when(\n    item_label %in% hsim1 ~ \"High Similarity 1\",\n    item_label %in% hsim2 ~ \"High Similarity 2\",\n    item_label %in% msim1 ~ \"Slight Similarity\",\n    item_label %in% lsim1 ~ \"Low Similarity 1\",\n    item_label %in% lsim2 ~ \"Low Similarity\")) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n    ggh4x::facet_nested_wrap(~plabel+item_label,ncol=2) + \n    theme(panel.background = element_blank(),\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank()) +xlim(-25, 25) + ylim(-25,25)\n\n\n\nPrototype pairs with different similarity levels\n\n\n\n\n\nDisplay codeblank_theme &lt;- list( theme(panel.background = element_blank(),\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        panel.grid = element_blank(),\n        # no facet labels\n        strip.background = element_blank(),\n        strip.text.x = element_blank(),\n        panel.spacing = unit(12, \"lines\")), \n        xlim(-25, 25), ylim(-25,25))\n\n\nphsim1 &lt;- proto_long |&gt; \n  filter(item_label %in% hsim1) |&gt; \n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme \n  \nphsim2 &lt;- proto_long |&gt;\n  filter(item_label %in% hsim2) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\npmsim1 &lt;- proto_long |&gt;\n  filter(item_label %in% msim1) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\n\nplsim1 &lt;- proto_long |&gt;\n  filter(item_label %in% lsim1) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\nplsim2 &lt;- proto_long |&gt;\n  filter(item_label %in% lsim2) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\n\n\n# phsim1\n# phsim2\n# pmsim1\n# plsim1\n# plsim2\n\n\nvery_similar &lt;- (phsim1/phsim2) \nnot_similar &lt;- (plsim1/plsim2)\n\nvery_similar +  plot_annotation(subtitle = 'Examples of Very Similar Pairs')\n\n\n\n\n\n\nDisplay codenot_similar  +  plot_annotation(subtitle = 'Examples of Not Similar Pairs')\n\n\n\n\n\n\nDisplay code# save_plots\n# ggsave(here(\"Task/assets/high_sim.png\"),very_similar)\n# ggsave(here(\"Task/assets/low_sim.png\"),not_similar)",
    "crumbs": [
      "Dot Patterns",
      "Instructions"
    ]
  },
  {
    "objectID": "Stimulii/instruction_examples.html#find-instruction-patterns",
    "href": "Stimulii/instruction_examples.html#find-instruction-patterns",
    "title": "Dot Pattern Plots",
    "section": "",
    "text": "Display codepacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table,readr,here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n# lmc22 &lt;- readRDS(here(\"data\",\"lmc22.rds\"))\n# mc24 &lt;- readRDS(here(\"data\",\"mc24.rds\"))\n\nlmc22_prototypes &lt;- read.csv(here(\"Stimulii\",\"lmc22_prototypes.csv\"))\nmc24_prototypes &lt;- read.csv(here(\"Stimulii\",\"mc24_prototypes.csv\"))\n\npat_themes &lt;- list(theme_minimal(),xlim(-25, 25),ylim(-25, 25),\n                        labs(x = \"X Coordinate\", y = \"Y Coordinate\"),\n                   coord_fixed(),guides(alpha = FALSE))\n\n\n\n\nDisplay codeproto_long &lt;- lmc22_prototypes |&gt; \n   select(item_label, x1:y9) |&gt;\n   group_by(item_label) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -item_label) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number))\n \nproto_long |&gt; \n  filter(item_label %in% unique(proto_long$item_label)[1:100]) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=.75) + \n   ggh4x::facet_nested_wrap(~item_label) +\n   pat_themes + labs(title=\"Prototypes from Category 1 - with distortions\")\n\n\n\nPrototypes and their distortions\n\n\n\n\n\nDisplay codecircle &lt;- c(\"10_nrep_2_287\",\"12_nrep_3_270\", \"27_rep_3_263\")\nhsplit &lt;- c(\"14_nrep_2_258\",\"13_rep_1_227\", \"2_nrep_3_261\", \"14_nrep_1_245\",\"34_nrep_3_229\")\nvsplit &lt;- c(\"1_rep_2_262\", \"22_nrep_2_239\", \"12_nrep_1_248\", \"11_rep_3_264\",\"38_nrep_3_288\",\"32_rep_3_286\")\ndsplit &lt;- c(\"20_nrep_2_236\", \"20_rep_3_247\")\ntower &lt;- c(\"11_rep_2_281\",\"25_rep_3_248\",\"47_rep_3_235\")\ntree &lt;- c(\"28_nrep_1_234\",\"41_nrep_2_285\",\"40_rep_2_272\")\nqmark &lt;- c(\"12_nrep_2_258\",\"20_nrep_1_267\",\"35_nrep_1_238\")\ndiag &lt;- c(\"24_nrep_1_242\",\"16_nrep_3_276\", \"26_nrep_3_263\",\"48_nrep_3_233\",\"47_nrep_1_227\")\nvert &lt;- c(\"11_rep_1_257\", \"25_rep_2_250\",\"48_nrep_3_233\")\nhoriz &lt;- c(\"22_rep_1_263\",\"4_nrep_2_236\")\nonemass &lt;- c(\"13_rep_1_227\", \"16_rep_1_241\",\"18_nrep_2_253\",\"47_nrep_2_264\")\ntriag &lt;- c(\"18_nrep_3_254\",\"46_rep_3_246\")\nincomp &lt;- c(\"22_nrep_3_235\",\"12_rep_1_282\",\"33_rep_2_282\", \"44_nrep_1_263\")\n\n\nproto_long |&gt; \n  filter(item_label %in% c(circle, hsplit, vsplit, dsplit, tower, \n                           qmark, diag, vert, horiz, onemass, triag, incomp,tree)) |&gt;\n  mutate(plabel = case_when(\n    item_label %in% circle ~ \"Circle\",\n    item_label %in% hsplit ~ \"Horizontal Split\",\n    item_label %in% vsplit ~ \"Vertical Split\",\n    item_label %in% dsplit ~ \"Diagonal Split\",\n    item_label %in% tower ~ \"Tower\",\n    item_label %in% triag ~ \"triag\",\n    item_label %in% tree ~ \"tree\",\n    item_label %in% triag ~ \"Trianglish\",\n    item_label %in% qmark ~ \"Question Mark\",\n    item_label %in% diag ~ \"Diagonal\",\n    item_label %in% vert ~ \"Vertical\",\n    item_label %in% horiz ~ \"Horizontal\",\n    item_label %in% incomp ~ \"incomp\",\n    item_label %in% onemass ~ \"One Mass\")) |&gt;\n   ggplot(aes(x = x, y = y,col=plabel)) +\n   geom_point(size=.75) + \n   ggh4x::facet_nested_wrap(~plabel+item_label) +\n   pat_themes + labs(title=\"Prototypes with Distinctive Patterns\") +\n  theme(legend.position = \"top\")\n\n\n\nPrototypes with distinctive patterns\n\n\n\n\n\nDisplay codehsim1 &lt;- circle[2:3]\nhsim2 &lt;- onemass[3:4]\nmsim1 &lt;- vsplit[1:2]\nlsim1 &lt;- c(diag[1],hsplit[3])\nlsim2 &lt;- c(circle[1],tower[3])\n\nproto_long |&gt; \n  filter(item_label %in% c(hsim1, hsim2, msim1, lsim1, lsim2)) |&gt;\n  mutate(plabel = case_when(\n    item_label %in% hsim1 ~ \"High Similarity 1\",\n    item_label %in% hsim2 ~ \"High Similarity 2\",\n    item_label %in% msim1 ~ \"Slight Similarity\",\n    item_label %in% lsim1 ~ \"Low Similarity 1\",\n    item_label %in% lsim2 ~ \"Low Similarity\")) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n    ggh4x::facet_nested_wrap(~plabel+item_label,ncol=2) + \n    theme(panel.background = element_blank(),\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank()) +xlim(-25, 25) + ylim(-25,25)\n\n\n\nPrototype pairs with different similarity levels\n\n\n\n\n\nDisplay codeblank_theme &lt;- list( theme(panel.background = element_blank(),\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        panel.grid = element_blank(),\n        # no facet labels\n        strip.background = element_blank(),\n        strip.text.x = element_blank(),\n        panel.spacing = unit(12, \"lines\")), \n        xlim(-25, 25), ylim(-25,25))\n\n\nphsim1 &lt;- proto_long |&gt; \n  filter(item_label %in% hsim1) |&gt; \n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme \n  \nphsim2 &lt;- proto_long |&gt;\n  filter(item_label %in% hsim2) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\npmsim1 &lt;- proto_long |&gt;\n  filter(item_label %in% msim1) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\n\nplsim1 &lt;- proto_long |&gt;\n  filter(item_label %in% lsim1) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\nplsim2 &lt;- proto_long |&gt;\n  filter(item_label %in% lsim2) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(size=2) + \n   facet_wrap(~item_label) +\n  blank_theme\n\n\n\n# phsim1\n# phsim2\n# pmsim1\n# plsim1\n# plsim2\n\n\nvery_similar &lt;- (phsim1/phsim2) \nnot_similar &lt;- (plsim1/plsim2)\n\nvery_similar +  plot_annotation(subtitle = 'Examples of Very Similar Pairs')\n\n\n\n\n\n\nDisplay codenot_similar  +  plot_annotation(subtitle = 'Examples of Not Similar Pairs')\n\n\n\n\n\n\nDisplay code# save_plots\n# ggsave(here(\"Task/assets/high_sim.png\"),very_similar)\n# ggsave(here(\"Task/assets/low_sim.png\"),not_similar)",
    "crumbs": [
      "Dot Patterns",
      "Instructions"
    ]
  },
  {
    "objectID": "Stimulii/plotDots.html",
    "href": "Stimulii/plotDots.html",
    "title": "Dot Pattern Plots",
    "section": "",
    "text": "Display codepacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table,readr,here, patchwork, conflicted)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\nlmc22 &lt;- readRDS(here(\"data\",\"lmc22.rds\"))\nmc24 &lt;- readRDS(here(\"data\",\"mc24.rds\"))\n\n\n# mc24_patterns &lt;- mc24 |&gt; \n#   ungroup() |&gt;\n#   rename(Pattern.Type=\"Pattern_Token\") |&gt;\n#   mutate(Pattern.Type=forcats::fct_relevel(Pattern.Type,\"prototype\",\"old\",\"new_low\",\"new_med\",\"new_high\")) |&gt;\n#   select(id,sbjCode,condit,exp,file,Phase,trial,Block,Pattern.Type,Category,Response,Corr,x1:y9) |&gt;\n#   arrange(sbjCode,condit,Category)\n# \n# lmc22_patterns &lt;- lmc22 |&gt; \n#   ungroup() |&gt; \n#   mutate(Pattern.Type = as.character(Pattern.Type)) |&gt; # Convert to character first\n#   mutate(Pattern.Type = factor(case_match(Pattern.Type,\n#                                           \"Trained.Med\" ~ \"old\",\n#                                           \"Prototype\" ~ \"prototype\",\n#                                           \"New.Low\" ~ \"new_low\",\n#                                           \"New.Med\" ~ \"new_med\",\n#                                           \"New.High\" ~ \"new_high\",\n#                                           .default = Pattern.Type), # Include a default case\n#                                levels = c(\"prototype\", \"old\", \"new_low\", \"new_med\", \"new_high\"))) |&gt;\n#   select(id,sbjCode,condit,exp,file,Phase,trial,Block,Pattern.Type,Category,Response,Corr,x1:y9) |&gt;\n#   arrange(sbjCode,condit,Category)\n\n\nmc24_patterns &lt;- read.csv(here(\"Stimulii\",\"mc24_patterns.csv\"))\nlmc22_patterns &lt;- read.csv(here(\"Stimulii\",\"lmc22_patterns.csv\"))\n\n  \nmc24_prototypes &lt;- mc24_patterns |&gt; \n  filter(Pattern.Type==\"prototype\") |&gt;\n  select(sbjCode,condit,exp,file,Category,x1:y9)\n\nlmc22_prototypes &lt;- lmc22_patterns |&gt;\n  filter(Pattern.Type==\"prototype\") |&gt;\n  select(sbjCode,condit,exp,file,Category,x1:y9)\n\n\n\nids &lt;- unique(mc24_patterns$id)\npat_themes &lt;- list(theme_minimal(),xlim(-25, 25),ylim(-25, 25),\n                        labs(x = \"X Coordinate\", y = \"Y Coordinate\"),\n                   coord_fixed(),guides(alpha = FALSE))",
    "crumbs": [
      "Dot Patterns",
      "Dot Patterns"
    ]
  },
  {
    "objectID": "Stimulii/plotDots.html#pattern-visuals",
    "href": "Stimulii/plotDots.html#pattern-visuals",
    "title": "Dot Pattern Plots",
    "section": "Pattern Visuals",
    "text": "Pattern Visuals\n\nDisplay code# mc24_prototypes_long &lt;- mc24_patterns |&gt; \n#   filter(Pattern.Type==\"prototype\") |&gt;\n#   gather(key = \"coordinate\", value = \"value\", -id, -condit, -exp, -file, -Category) %&gt;%\n#   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n#   spread(key = axis, value = value) %&gt;%\n#   mutate(number = as.integer(number))\n# mc24_prototypes_long |&gt;\n#   filter(id %in% c(\"1.low\",\"10.medium\",\"112.high\")) |&gt;\n#   ggplot(aes(x = x, y = y)) +\n#   geom_point() + # Add dots\n#   facet_grid(id ~ Category) + # Create a grid of plots, with subjects by rows and categories by columns\n#   pat_themes\n\n\n\nDisplay code pat_long &lt;- mc24_patterns |&gt; \n   filter(Phase==2) |&gt; \n   select(id, condit, Category, Pattern.Type, x1:y9) |&gt;\n   group_by(id, condit, Category, Pattern.Type) |&gt; \n   slice_head(n=1) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -id, -condit, -Category,-Pattern.Type) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number))\n \n pat_long |&gt; \n   filter(Category==1, id %in%  c(\"1.low\",\"10.medium\",\"112.high\"),\n          Pattern.Type!=\"old\") |&gt;\n   ggplot(aes(x = x, y = y,col=Pattern.Type)) +\n   geom_point() + # Add dots\n   ggh4x::facet_grid2(id ~ Pattern.Type, margins=c(\"Pattern.Type\")) + # Create a grid of plots, with subjects by rows and categories by columns\n   pat_themes + labs(title=\"Prototypes from Category 1 - with distortions\")\n\n\n\nPrototypes and their distortions\n\n\n\n\nDisplay code pat_long |&gt; \n   mutate(Category = as.factor(Category)) |&gt;\n   filter(id %in%  c(\"1.low\",\"10.medium\"),\n          Pattern.Type!=\"old\") |&gt;\n   ggplot(aes(x = x, y = y,col=Category)) +\n   geom_point() + # Add dots\n   #ggh4x::facet_nested_wrap(id~Category~Pattern.Type) + \n   #ggh4x::facet_grid2(id ~ Category ~ Pattern.Type) +\n   ggh4x::facet_nested(~id + Category ~ Pattern.Type) +\n   pat_themes + labs(title=\"all 3 Category Prototypes and their distortions\") \n\n\n\nall 3 Category Prototypes and their distortions\n\n\n\n\nDisplay code pat_long |&gt; \n   filter(id %in%  c(\"1.low\",\"10.medium\",\"112.high\"),\n          Pattern.Type!=\"old\") |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color = Pattern.Type, alpha = Pattern.Type)) + \n   scale_color_manual(values = c(\"prototype\" = \"black\",  # Black for prototype\n                                 \"old\" = \"#E69F00\",      # Orange for old\n                                 \"new_low\" = \"#56B4E9\",  # Blue for new_low\n                                 \"new_med\" = \"#009E73\",  # Green for new_med\n                                 \"new_high\" = \"red\")) +# Yellow for new_high   scale_alpha_manual(values = c(\"prototype\" = 1, \"old\" = 0.5, \"new_low\" = 0.5, \"new_med\" = 0.5, \"new_high\" = 0.5)) +\n   scale_alpha_manual(values = c(\"prototype\" = 1, \"old\" = 0.2, \"new_low\" = 0.6, \"new_med\" = 0.4, \"new_high\" = 0.4)) +\n    facet_grid(id ~ Category) + pat_themes + labs(title=\"Prototypes with 1 disortion overlaid\")\n\n\n\nPrototypes with 1 disortion overlaid\n\n\n\n\nDisplay code pat_long &lt;- mc24_patterns |&gt; \n   filter(Phase==2) |&gt; \n   select(id, condit,trial, item_label,Category, Pattern.Type, x1:y9) |&gt;\n   group_by(id, condit, Category, Pattern.Type) |&gt; \n   slice_head(n=10) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -id, -condit,-trial,-item_label, -Category,-Pattern.Type) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number)) \n\n pat_long |&gt; \n   filter(id %in%  c(\"1.low\",\"10.medium\",\"112.high\"),Pattern.Type!=\"old\") |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color = Pattern.Type, alpha = Pattern.Type, size= Pattern.Type)) + \n   scale_color_manual(values = c(\"prototype\" = \"black\",  # Black for prototype\n                                 \"old\" = \"#E69F00\",      # Orange for old\n                                 \"new_low\" = \"#56B4E9\",  # Blue for new_low\n                                 \"new_med\" = \"#009E73\",  # Green for new_med\n                                 \"new_high\" = \"red\")) +# Yellow for new_high   scale_alpha_manual(values = c(\"prototype\" = 1, \"old\" = 0.5, \"new_low\" = 0.5, \"new_med\" = 0.5, \"new_high\" = 0.5)) +\n   scale_alpha_manual(values = c(\"prototype\" = 4,  \"new_low\" = 0.5, \"new_med\" = 0.4, \"new_high\" = 0.2)) +\n   scale_size_manual(values = c(\"prototype\" = 1.5,  \"new_low\" = 1, \"new_med\" = 1, \"new_high\" = 1)) +\n   facet_grid(id ~ Category) + pat_themes + labs(title=\"Prototypes with 10 disortion overlaid\")\n\n\n\nPrototypes with 10 disortion overlaid\n\n\n\n\nDisplay code pat_long |&gt; \n mutate(Category=as.factor(Category)) |&gt;\n   filter(id %in%  c(\"1.low\",\"10.medium\",\"112.high\"),Pattern.Type!=\"old\") |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color = Category),alpha=.9) + \n   facet_grid(id ~ Pattern.Type) + pat_themes\n\n\n\nPrototype separability\n\n\n\n\nDisplay code pat_long_train &lt;- mc24_patterns |&gt; \n  mutate(Category=as.factor(Category)) |&gt;\n   filter(id %in% ids[1:16]) |&gt;\n   filter(Phase==1) |&gt; \n   select(id, condit,trial, Category, Pattern.Type, x1:y9) |&gt;\n   group_by(id, condit, Category, Pattern.Type) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -id, -condit,-trial, -Category,-Pattern.Type) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number))\n \n pat_long_train |&gt; \n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color = Category),alpha=.7) + \n   facet_wrap(~condit + id,ncol=4) + pat_themes\n\n\n\nTraining exemplar separability - 10 subjects\n\n\n\n\nDisplay codepat_long_train &lt;- mc24_patterns |&gt; \n  mutate(Category=as.factor(Category)) |&gt;\n   filter(id %in% ids[1:3]) |&gt;\n   filter(Phase==1 | Pattern.Type==\"prototype\") |&gt; \n   select(id, condit,trial, Category, Pattern.Type,Phase, x1:y9) |&gt;\n   group_by(id, condit, Category, Pattern.Type,Phase) |&gt; \n   gather(key = \"coordinate\", value = \"value\", -id, -condit,-trial, -Category,-Pattern.Type,-Phase) %&gt;%\n   separate(coordinate, into = c(\"axis\", \"number\"), sep = 1) %&gt;%\n   spread(key = axis, value = value) %&gt;%\n   mutate(number = as.integer(number), itemType= case_match(Phase,1 ~\"Trained\",2~\"Prototype\"))\n \n pat_long_train |&gt; \n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color = Category),alpha=.8) + \n   ggh4x::facet_nested_wrap(~condit + id+itemType,ncol=2) + pat_themes\n\n\n\nTraining exemplar separability compared to prototypes\n\n\n\n\nDisplay code pat_long |&gt; ungroup() |&gt;\n  filter(id %in% ids[1:5] & Pattern.Type==\"prototype\") |&gt;\n  droplevels() |&gt;\n mutate(Category=as.factor(Category)) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color=id),alpha=.9) + \n   facet_grid(id ~ Category) + pat_themes + labs(title=\"Prototypes from first 5 subjects - should match first 10 task trials\")\n\n\n\nPrototypes from first 5 subjects - should match first 10 task trials\n\n\nDisplay code  pat_long |&gt; ungroup() |&gt;\n  filter(id %in% ids[1:5] & Pattern.Type==\"prototype\") |&gt;\n  droplevels() |&gt;\n mutate(Category=as.factor(Category)) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color=id),alpha=.9) + \n   ggh4x::facet_wrap2(~id+item_label) + pat_themes + labs(title=\"Prototypes from first 5 subjects - should match first 10 task trials\")\n\n\n\nPrototypes from first 5 subjects - should match first 10 task trials\n\n\nDisplay code  pat_long |&gt; ungroup() |&gt;\n  filter(id==\"57.low\" & Pattern.Type==\"prototype\") |&gt;\n  droplevels() |&gt;\n mutate(Category=as.factor(Category)) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color=id),alpha=.9) + \n   ggh4x::facet_wrap2(~id+item_label) + pat_themes + labs(title=\"Prototypes from first 5 subjects - should match first 10 task trials\")\n\n\n\nPrototypes from first 5 subjects - should match first 10 task trials\n\n\nDisplay code  pat_long |&gt; ungroup() |&gt;\n  filter(id==\"57.low\" & Pattern.Type==\"prototype\") |&gt;\n  droplevels() |&gt;\n mutate(Category=as.factor(Category), y = -y) |&gt;\n   ggplot(aes(x = x, y = y)) +\n   geom_point(aes(color=id),alpha=.9) + \n   ggh4x::facet_wrap2(~id+item_label) + pat_themes + labs(title=\"Prototypes from first 5 subjects - should match first 10 task trials\")  \n\n\n\nPrototypes from first 5 subjects - should match first 10 task trials\n\n\n\n\nlink to instruction examples",
    "crumbs": [
      "Dot Patterns",
      "Dot Patterns"
    ]
  },
  {
    "objectID": "Analysis/dp_22.html",
    "href": "Analysis/dp_22.html",
    "title": "Hu & Nosofsky 2022",
    "section": "",
    "text": "Display codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted, knitr,grateful)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n#source(here::here(\"R/read_24.R\"))\n\n#https://fonts.google.com/specimen/Manrope\n# ~/Library/Fonts\ntheme_nice &lt;- function() {\n  theme_minimal(base_family = \"Manrope\") +\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.title = element_text(family = \"Manrope Extrabold\", face = \"plain\", size = rel(1.25)),\n      plot.subtitle = element_text(family = \"Manrope Medium\", face = \"plain\", size = rel(1.15)),\n      axis.title = element_text(family = \"Manrope SemiBold\", face = \"plain\", size = rel(1)),\n      axis.title.x = element_text(hjust = .5),\n      axis.title.y = element_text(hjust = .5),\n      axis.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(0.8)),\n      strip.text = element_text(\n        family = \"Manrope\", face = \"bold\",\n        size = rel(.75), hjust = 0\n      ),\n      strip.background = element_rect(fill = \"grey90\", color = NA)\n    )\n}\n\ntheme_nice_dist &lt;- function() {\n  theme_nice() +\n    theme(\n      panel.grid = element_blank(),\n      panel.spacing.x = unit(10, units = \"pt\"),\n      axis.ticks.x = element_line(linewidth = 0.25),\n      axis.text.y = element_blank()\n    )\n}\n\ntheme_set(theme_nice())\nDisplay codelibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(glue)\nlibrary(knitr)\n\nset.seed(42)\n\nknitr::opts_template$set(\n  code = list(echo = TRUE, eval = FALSE)\n)\n\n# load font for plots\n.font &lt;- \"Source Sans Pro\"\nif (!(.font %in% sysfonts::font_families()))\n  sysfonts::font_add_google(.font, .font)\nshowtext::showtext_auto()\n\n# set custom plot theme\ntheme_set(theme_bw(base_size = 14, base_family = .font))\ntheme_update(panel.grid = element_blank(),\n             strip.background = element_blank(),\n             legend.key = element_blank(),\n             panel.border = element_blank(),\n             axis.line = element_line(),\n             strip.text = element_text(face = \"bold\"))\n\n# set options for default color and fill scales\noptions(\"ggplot2.discrete.colour\"   = ggthemes::scale_colour_ptol   )\noptions(\"ggplot2.continuous.colour\" =  viridis::scale_colour_viridis)\noptions(\"ggplot2.discrete.fill\"     = ggthemes::scale_fill_ptol     )\noptions(\"ggplot2.continuous.fill\"   =  viridis::scale_fill_viridis  )\n\n# solarized colors for individual elements (like reference lines)\npal &lt;- list(\n  grey   = \"#93a1a1\",\n  red    = \"#dc322f\",\n  blue   = \"#268bd2\",\n  purple = \"#6c71c4\"\n)\n\n# from https://bookdown.org/yihui/rmarkdown-cookbook/font-color.html\ncolorize &lt;- function(x, color) {\n  if (knitr::is_latex_output()) {\n    glue(\"\\\\textcolor{&lt;color&gt;}{&lt;x&gt;}\", .open = \"&lt;\", .close = \"&gt;\")\n  } else if (knitr::is_html_output()) {\n    glue(\"&lt;span style='color: var(--{stringr::str_sub(color, 2)});'&gt;{x}&lt;/span&gt;\")\n  } else x\n}\nDisplay codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted, viridis, gghalves,grateful)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\n\nsource(here::here(\"R/read_22.R\"))\n#lmc22 &lt;- readRDS(here(\"data\",\"lmc22.rds\"))\n\n#theme_set(theme_bw())\n\ndcp &lt;- merge(dCatAvg2,sbjTrainAvg,by=c(\"id\",\"condit\",\"Condition\"))\n\n\ndc &lt;- dCatAvg2 %&gt;% select(id,condit,Condition,Pattern.Type2,Category,propCor) %&gt;% \n  pivot_wider(names_from = \"Pattern.Type2\",values_from = \"propCor\") %&gt;%\n  mutate(EndTrain.Minus.HighDistort= End.Training-New.High,\n         MedDistort.Minus.HighDistort=New.Med-New.High,\n         LowDistort.Minus.HighDistort=New.Low-New.High,\n         TrainedItem.Minus.HighDistort=Trained.Med-New.High,\n         Prototype.Minus.HighDistort=Prototype-New.High) \n\ndc &lt;- merge(dc,sbjTrainAvg,by=c(\"id\",\"condit\",\"Condition\"))\ndc2 &lt;- dc %&gt;% group_by(id,condit,Condition,cq) %&gt;% summarise(End.Training=mean(End.Training),New.High=mean(New.High)) %&gt;% as.data.frame()",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2022"
    ]
  },
  {
    "objectID": "Analysis/dp_22.html#testing---splitting-peformance-by-end-of-training",
    "href": "Analysis/dp_22.html#testing---splitting-peformance-by-end-of-training",
    "title": "Hu & Nosofsky 2022",
    "section": "Testing - Splitting Peformance by End of Training",
    "text": "Testing - Splitting Peformance by End of Training\n\n\nDisplay code##| column: page-inset-right\n\nlibrary(gghalves)\n\nps &lt;- dcp  %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~cq)+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n  xlab(\"Pattern-Type\")+ylab(\"Proportion Correct\")+ggtitle(\"Low vs High Performers (median split within condition - final training block) - Performance x Pattern Type\")\n\nhd&lt;- dcp  %&gt;% filter(Pattern.Type2==\"New-High\")%&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  geom_boxplot(outlier.shape=NA)+geom_jitter(alpha=.5)+facet_wrap(~cq)+xlab(\"Pattern-Type\")+\n  ggtitle(\"Low vs High Performers (median split within condition) - High Distortion Performance\")+ylab(\"Proportion Correct\")\n\n\n# dcp  %&gt;% filter(Pattern.Type2==\"New-High\") %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n#   geom_half_violin()+\n#   geom_jitter(alpha=.5)+\n#   facet_wrap(~cq)+ggtitle(\"Low vs High Performers (median split within condition) - High Distortion Performance\")\n\n#ps\n#gridExtra::grid.arrange(ps,hd)\n\n\np7&lt;- dcp  %&gt;% filter(endTrain&gt;.75) %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n  xlab(\"Pattern-Type\")+ylab(\"Proportion Correct\")+ggtitle(\"Performance x Pattern Type - Only retaining sbjs with &gt;75% accuracy in final training block\")\n\np5 &lt;-  dcp  %&gt;% filter(endTrain&gt;.50) %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n  xlab(\"Pattern-Type\")+ylab(\"Proportion Correct\")+ggtitle(\"Performance x Pattern Type - Only retaining sbjs with &gt;50% accuracy in final training block\")\n\n\ngridExtra::grid.arrange(ps,p7,p5)\n\n\n\n\n\n\nDisplay code# dCatAvg2  %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Condition))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~cq)+\n#   stat_summary(geom=\"point\")\n#    geom_hline(yintercept = .33,linetype=\"dashed\")+\n#  ggtitle(\"\")+ylab(\"Proportion Correct\")\n\n# dCatAvg2 %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Pattern.Type2))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~condit)+\n#    geom_hline(yintercept = .33,linetype=\"dashed\")+\n#  ggtitle(\"\")+ylab(\"Proportion Correct\")\n# \n# \n# dCatAvg3 %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type2,y=propCor,fill=Pattern.Type2))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~condit)+\n#    geom_hline(yintercept = .33,linetype=\"dashed\")+\n#  ggtitle(\"\")+ylab(\"Proportion Correct\")",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2022"
    ]
  },
  {
    "objectID": "Analysis/dp_22.html#controlling-for-end-of-training-performace",
    "href": "Analysis/dp_22.html#controlling-for-end-of-training-performace",
    "title": "Hu & Nosofsky 2022",
    "section": "Controlling for End of Training Performace",
    "text": "Controlling for End of Training Performace\n\nDisplay codelibrary(rstatix)\nlibrary(ggpubr)\nlibrary(emmeans)\nlibrary(cowplot)\n\n\n# dc2 %&gt;% filter() %&gt;% ggplot(aes(x=End.Training,y=New.High,color=condit))+geom_point()+geom_smooth(method=\"lm\")\n# dc2 %&gt;% filter(End.Training&gt;.33, New.High&gt;.33) %&gt;% ggplot(aes(x=End.Training,y=New.High,color=condit))+geom_point()+geom_smooth(method=\"lm\")\n\n(at1 &lt;- dc2 %&gt;% anova_test(dv=New.High,between=Condition,covariate = End.Training,wid=id,type=3))\n\nANOVA Table (type III tests)\n\n        Effect DFn DFd       F        p p&lt;.05   ges\n1 End.Training   1  86 128.607 9.21e-19     * 0.599\n2    Condition   1  86  12.249 7.40e-04     * 0.125\n\nDisplay code(at2 &lt;- dc2 %&gt;% filter(End.Training&gt;.33) %&gt;% anova_test(dv=New.High,between=Condition,covariate = End.Training,wid=id,type=3))\n\nANOVA Table (type III tests)\n\n        Effect DFn DFd       F        p p&lt;.05   ges\n1 End.Training   1  84 103.961 2.36e-16     * 0.553\n2    Condition   1  84  12.573 6.43e-04     * 0.130\n\nDisplay code(at3 &lt;- dc2 %&gt;% filter(End.Training&gt;.88) %&gt;% anova_test(dv=New.High,between=Condition,covariate = End.Training,wid=id,type=3))\n\nANOVA Table (type III tests)\n\n        Effect DFn DFd      F        p p&lt;.05   ges\n1 End.Training   1  49 13.847 0.000511     * 0.220\n2    Condition   1  49 13.131 0.000689     * 0.211\n\nDisplay code#dc2 %&gt;% anova_test(New.High ~condit*End.Training) # no sig. interaction\npwc1 &lt;- dc2 %&gt;% emmeans_test(New.High ~ Condition,covariate=End.Training,p.adjust.method=\"bonferroni\")%&gt;% add_xy_position(x = \"condit\", fun = \"mean_se\")\nget_emmeans(pwc1)\n\n# A tibble: 2 Ã 8\n  End.Training Condition emmean     se    df conf.low conf.high method      \n         &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       \n1        0.830 rep        0.673 0.0198    86    0.634     0.713 Emmeans test\n2        0.830 nrep       0.772 0.0191    86    0.734     0.810 Emmeans test\n\nDisplay codepwc2 &lt;- dc2 %&gt;% filter(End.Training&gt;.33) %&gt;% emmeans_test(New.High ~ Condition,covariate=End.Training,p.adjust.method=\"bonferroni\")%&gt;% add_xy_position(x = \"condit\", fun = \"mean_se\")\npwc3 &lt;- dc2 %&gt;% filter(End.Training&gt;.88) %&gt;% emmeans_test(New.High ~ Condition,covariate=End.Training,p.adjust.method=\"bonferroni\")%&gt;% add_xy_position(x = \"condit\", fun = \"mean_se\")\n\n\n\nep1&lt;-ggline(get_emmeans(pwc1), x = \"Condition\", y = \"emmean\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + \n  stat_pvalue_manual(pwc1, hide.ns = TRUE, tip.length = FALSE) +\n  labs(subtitle = get_test_label(at1, detailed = TRUE),caption = get_pwc_label(pwc1),title=\"Estimated Marginal Means from ANCOVA - All Sbj. (n=89)\" )\n\nep2&lt;-ggline(get_emmeans(pwc2), x = \"Condition\", y = \"emmean\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + \n  stat_pvalue_manual(pwc2, hide.ns = TRUE, tip.length = FALSE) +\n  labs(subtitle = get_test_label(at2, detailed = TRUE),caption = get_pwc_label(pwc2), title= \"Estimated Marginal Means from ANCOVA - Only above chance sbj (&gt;.33,n=87)\")\n\nep3&lt;-ggline(get_emmeans(pwc3), x = \"Condition\", y = \"emmean\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + \n  stat_pvalue_manual(pwc3, hide.ns = TRUE, tip.length = FALSE) +\n  labs(subtitle = get_test_label(at3, detailed = TRUE),caption = get_pwc_label(pwc3), title= \"Estimated Marginal Means from ANCOVA - Only strong learners (&gt;.88; n=52)\")\n\n\n\ngg.ac1 &lt;- ggscatter(dc2,x=\"End.Training\",y=\"New.High\",color=\"Condition\",add=\"reg.line\",add.params = list(size=.3))+\n  stat_regline_equation(aes(label=paste(..eq.label.., ..rr.label..,sep=\"~~~~\"),color=Condition))+\n  ggtitle(\"Including All Subjects (n=89)\")+ylab(\"High Distortions - Proportion Correct\")+xlab(\"End of Training - Proportion Correct\")\n\ngg.ac2 &lt;- dc2 %&gt;% filter(End.Training&gt;.33) %&gt;% ggscatter(.,x=\"End.Training\",y=\"New.High\",color=\"Condition\",add=\"reg.line\",add.params = list(size=.3))+\n  stat_regline_equation(aes(label=paste(..eq.label.., ..rr.label..,sep=\"~~~~\"),color=Condition))+\n  ggtitle(\"Retain Sbj's above chance (&gt;.33) at train end (n=87). \")+ylab(\"High Distortions - Proportion Correct\")+xlab(\"End of Training - Proportion Correct\")\n\ngg.ac3 &lt;- dc2 %&gt;% filter(End.Training&gt;.88) %&gt;% ggscatter(.,x=\"End.Training\",y=\"New.High\",color=\"Condition\",add=\"reg.line\",add.params = list(size=.3))+\n  stat_regline_equation(aes(label=paste(..eq.label.., ..rr.label..,sep=\"~~~~\"),color=Condition))+\n  ggtitle(\"Retain only stronger learners (&gt;.88) at train end (n=52). \")+ylab(\"High Distortions - Proportion Correct\")+xlab(\"End of Training - Proportion Correct\")\n\n\n\ngtitle=\" Hu & Nosofsky 2020 - Experiment 2. Effect of Condition on High Distortions - Controlling for End of Training Performance\"\ntitle = ggdraw()+draw_label(gtitle,fontface = 'bold',x=0,hjust=0)+theme(plot.margin = margin(0, 0, 0, 7))\n\nplot_grid(title,NULL,gg.ac1,ep1,gg.ac2,ep2,gg.ac3,ep3,ncol=2,rel_heights=c(.1,1,1,1))",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2022"
    ]
  },
  {
    "objectID": "Analysis/dp_22.html#individual-learning-curves",
    "href": "Analysis/dp_22.html#individual-learning-curves",
    "title": "Hu & Nosofsky 2022",
    "section": "Individual Learning Curves",
    "text": "Individual Learning Curves\n\n\nDisplay code###| column: screen-inset-right\n\n\ndCatTrainAvg %&gt;% filter(condit==\"rep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+\n  stat_summary(shape=0,geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"red\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Hu & Nosofsky Experiment 2 - Learning. Rep Subjects - Average Accuracy Per Block.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))\n\n\n\n\n\n\nDisplay codedCatTrainAvg %&gt;% filter(condit==\"nrep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=condit))+\n  stat_summary(shape=2, geom=\"point\",fun=\"mean\",col=\"lightblue\")+\n  stat_summary(geom=\"line\",fun=\"mean\",col=\"lightblue\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  facet_wrap(~id)+ggtitle(\"Hu & Nosofsky Experiment 2 - Learning. NRep Subjects - Average Accuracy Per Block.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2022"
    ]
  },
  {
    "objectID": "Analysis/dp_22.html#experiment-2---separate-category---learning-curves",
    "href": "Analysis/dp_22.html#experiment-2---separate-category---learning-curves",
    "title": "Hu & Nosofsky 2022",
    "section": "Experiment 2 - separate category - learning curves",
    "text": "Experiment 2 - separate category - learning curves\n\n\nDisplay code##| column: screen-inset-right\n \ndCatTrainAvg2 %&gt;% filter(condit==\"rep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=Category,shape=Category))+\n  stat_summary(geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  ggtitle(\"Hu & Nosofsky Experiment 2 - Learning Curves. Rep Subjects - Separated Categories.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))\n\n\n\n\n\n\nDisplay codedCatTrainAvg2 %&gt;% filter(condit==\"nrep\") %&gt;% ggplot(aes(x=Block,y=propCor,col=Category,shape=Category))+\n  stat_summary(geom=\"point\",fun=\"mean\")+\n  stat_summary(geom=\"line\",fun=\"mean\")+facet_wrap(~id)+ylim(c(0,1))+\n  geom_hline(yintercept = .33,linetype=\"dashed\")+\n  facet_wrap(~id)+ggtitle(\"Hu & Nosofsky Experiment 2 - Learning Curves. NRep Subjects - Separated Categories.\")+\n  xlab(\"Training Block\")+ylab(\"Proportion Correct\")+scale_x_continuous(breaks=seq(1,15))",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2022"
    ]
  },
  {
    "objectID": "Analysis/dp_22.html#experiment-2---3-training-stages-transfer-patterns",
    "href": "Analysis/dp_22.html#experiment-2---3-training-stages-transfer-patterns",
    "title": "Hu & Nosofsky 2022",
    "section": "Experiment 2 - 3 Training Stages + Transfer Patterns",
    "text": "Experiment 2 - 3 Training Stages + Transfer Patterns\n\nDisplay codedCatAvg %&gt;% filter(condit==\"rep\") %&gt;% ggplot(aes(x=Stage,y=propCor,fill=Pattern.Type))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~id)+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n ggtitle(\"REP - 3 training bins (75 trials each) + Transfer Patterns\")+ylab(\"Proportion Correct\")\n\n\n\n\n\n\nDisplay codedCatAvg %&gt;% filter(condit==\"nrep\") %&gt;% ggplot(aes(x=Stage,y=propCor,fill=Pattern.Type))+\n  stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~id)+\n   geom_hline(yintercept = .33,linetype=\"dashed\")+\n ggtitle(\"NREP - 3 training bins (75 trials each) + Transfer Patterns\")+ylab(\"Proportion Correct\")\n\n\n\n\n\n\nDisplay code# \n# dCatAvg %&gt;% filter() %&gt;% ggplot(aes(x=Stage,y=propCor,fill=Pattern.Type))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~condit)+ggtitle(\"nrep\")\n# \n# dCatAvg %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type,y=propCor,fill=condit))+\n#   stat_summary(geom=\"bar\",fun=mean,position=position_dodge())+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,position=position_dodge())+facet_wrap(~Stage)+ggtitle(\"\")\n# \n# dCatAvg %&gt;% filter() %&gt;% ggplot(aes(x=Pattern.Type,y=propCor,col=condit))+\n#   geom_boxplot(position=position_dodge())+facet_wrap(~Stage)",
    "crumbs": [
      "Learning Analysis",
      "Hu & Nosofsky 2022"
    ]
  },
  {
    "objectID": "assets/setup.html",
    "href": "assets/setup.html",
    "title": "Dot Pattern Variability",
    "section": "",
    "text": "pacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted, knitr,grateful)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n#source(here::here(\"R/read_24.R\"))\n\n#https://fonts.google.com/specimen/Manrope\n# ~/Library/Fonts\ntheme_nice &lt;- function() {\n  theme_minimal(base_family = \"Manrope\") +\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.title = element_text(family = \"Manrope Extrabold\", face = \"plain\", size = rel(1.25)),\n      plot.subtitle = element_text(family = \"Manrope Medium\", face = \"plain\", size = rel(1.15)),\n      axis.title = element_text(family = \"Manrope SemiBold\", face = \"plain\", size = rel(1)),\n      axis.title.x = element_text(hjust = .5),\n      axis.title.y = element_text(hjust = .5),\n      axis.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(0.8)),\n      strip.text = element_text(\n        family = \"Manrope\", face = \"bold\",\n        size = rel(.75), hjust = 0\n      ),\n      strip.background = element_rect(fill = \"grey90\", color = NA)\n    )\n}\n\ntheme_nice_dist &lt;- function() {\n  theme_nice() +\n    theme(\n      panel.grid = element_blank(),\n      panel.spacing.x = unit(10, units = \"pt\"),\n      axis.ticks.x = element_line(linewidth = 0.25),\n      axis.text.y = element_blank()\n    )\n}\n\ntheme_set(theme_nice())\n\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(glue)\nlibrary(knitr)\n\nset.seed(42)\n\nknitr::opts_template$set(\n  code = list(echo = TRUE, eval = FALSE)\n)\n\n# load font for plots\n.font &lt;- \"Source Sans Pro\"\nif (!(.font %in% sysfonts::font_families()))\n  sysfonts::font_add_google(.font, .font)\nshowtext::showtext_auto()\n\n# set custom plot theme\ntheme_set(theme_bw(base_size = 14, base_family = .font))\ntheme_update(panel.grid = element_blank(),\n             strip.background = element_blank(),\n             legend.key = element_blank(),\n             panel.border = element_blank(),\n             axis.line = element_line(),\n             strip.text = element_text(face = \"bold\"))\n\n# set options for default color and fill scales\noptions(\"ggplot2.discrete.colour\"   = ggthemes::scale_colour_ptol   )\noptions(\"ggplot2.continuous.colour\" =  viridis::scale_colour_viridis)\noptions(\"ggplot2.discrete.fill\"     = ggthemes::scale_fill_ptol     )\noptions(\"ggplot2.continuous.fill\"   =  viridis::scale_fill_viridis  )\n\n# solarized colors for individual elements (like reference lines)\npal &lt;- list(\n  grey   = \"#93a1a1\",\n  red    = \"#dc322f\",\n  blue   = \"#268bd2\",\n  purple = \"#6c71c4\"\n)\n\n# from https://bookdown.org/yihui/rmarkdown-cookbook/font-color.html\ncolorize &lt;- function(x, color) {\n  if (knitr::is_latex_output()) {\n    glue(\"\\\\textcolor{&lt;color&gt;}{&lt;x&gt;}\", .open = \"&lt;\", .close = \"&gt;\")\n  } else if (knitr::is_html_output()) {\n    glue(\"&lt;span style='color: var(--{stringr::str_sub(color, 2)});'&gt;{x}&lt;/span&gt;\")\n  } else x\n}"
  },
  {
    "objectID": "Analysis/all_exp.html#comparison",
    "href": "Analysis/all_exp.html#comparison",
    "title": "Combined Experiments",
    "section": "Comparison",
    "text": "Comparison\nDisplay codeall_data |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \nall_data |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token,exp) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  facet_wrap(~exp,scales=\"free_x\") +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \nall_data |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token,exp) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=exp, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  facet_wrap(~condit,scales=\"free_x\") +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \nall_data |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token,exp) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=exp, group=exp)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  facet_wrap(~Pattern_Token,scales=\"free_x\") +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \n\n\n\n\n\nLine Plot 1\n\n\n\n\n\nLine Plot 2\n\n\n\n\n\n\n\nLine Plot 4\n\n\n\n\n\nLine Plot 5",
    "crumbs": [
      "Learning Analysis",
      "Combo"
    ]
  },
  {
    "objectID": "Analysis/all_exp.html#training-comparison",
    "href": "Analysis/all_exp.html#training-comparison",
    "title": "Combined Experiments",
    "section": "Training Comparison",
    "text": "Training Comparison\nDisplay codeall_data |&gt; filter(Phase==1) |&gt;\n  group_by(sbjCode, condit, Pattern_Token,Block,exp) |&gt;\n  summarize(Corr=mean(Corr),.groups=\"keep\") |&gt;\n  ggplot(aes(x=Block, y=Corr, color=interaction(condit,exp))) +  \n  stat_summary(geom=\"line\",fun=mean)+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se,width=.1) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") +\n  #eg +  \n  theme(legend.position = \"top\") + list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),\n           scale_y_continuous(breaks=yt,limits=c(0,1)),\n           scale_x_continuous(breaks=seq(1:15)))\nall_data |&gt; filter(Phase==1) |&gt;\n  group_by(sbjCode, condit, Pattern_Token,Block,exp) |&gt;\n  summarize(Corr=mean(Corr),.groups=\"keep\") |&gt;\n  ggplot(aes(x=Block, y=Corr, color=condit)) +  \n  stat_summary(geom=\"line\",fun=mean)+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se,width=.1) +\n  facet_wrap(~exp,scales=\"free_x\") + \n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") +\n  #eg +  \n  theme(legend.position = \"top\") + list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),\n           scale_y_continuous(breaks=yt,limits=c(0,1)),\n           scale_x_continuous(breaks=seq(1:15)))",
    "crumbs": [
      "Learning Analysis",
      "Combo"
    ]
  },
  {
    "objectID": "Analysis/all_exp.html#separated-by-experiment",
    "href": "Analysis/all_exp.html#separated-by-experiment",
    "title": "Combined Experiments",
    "section": "Separated by Experiment",
    "text": "Separated by Experiment\nDisplay codefp24 |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \nfp24 |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \nfp24 |&gt; filter(Phase==1) |&gt;\n  group_by(sbjCode, condit, Pattern_Token,Block) |&gt;\n  summarize(Corr=mean(Corr),.groups=\"keep\") |&gt;\n  ggplot(aes(x=Block, y=Corr, col=condit, group=condit)) +  \n  stat_summary(geom=\"line\",fun=mean)+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se,width=.1) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") +\n  #eg +  \n  theme(legend.position = \"top\") + eg\nlmc22 |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\")",
    "crumbs": [
      "Learning Analysis",
      "Combo"
    ]
  },
  {
    "objectID": "Analysis/all_exp.html#compare-experiments",
    "href": "Analysis/all_exp.html#compare-experiments",
    "title": "Combined Experiments",
    "section": "Compare Experiments",
    "text": "Compare Experiments\nDisplay codetheme_set(theme_nice_b())\n\nall_data |&gt; filter(Phase==2, Pattern_Token != \"special\") |&gt;\n  group_by(sbjCode, condit, Pattern_Token,exp) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  group_by(condit,Pattern_Token,exp) |&gt; \n  summarise(empirical_stat = mean(Corr), \n            sem = sd(Corr)/sqrt(length(Corr)),\n            ci_lower = mean(Corr) - sem,\n            ci_upper = mean(Corr) + sem) |&gt;\n  mutate(method = \"standard error\") |&gt; \n  ggplot(aes(x=Pattern_Token, y=empirical_stat, col=condit, group=condit)) +  \n  geom_point() +\n  geom_line(aes(group = condit)) +\n  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)\n                ) +\n  facet_wrap(~exp)\nall_data |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token,exp) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=condit, y=Corr, col=exp, group=exp)) +  \n  stat_summary(geom=\"line\",fun=mean)+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se) +\n  facet_wrap(~Pattern_Token,scales=\"free_x\") +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\") \nall_data |&gt; filter(Phase==2, Pattern_Token != \"special\") |&gt;\n  group_by(sbjCode, condit, Pattern_Token,exp) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, col=condit, group=condit)) +  \n  stat_summary(geom=\"line\",fun=mean)+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se) +\n  facet_wrap(~exp,scales=\"free_x\") +\n  labs(title=\"Testing Performance - All Sbjs.\", y=\"Accuracy\")",
    "crumbs": [
      "Learning Analysis",
      "Combo"
    ]
  },
  {
    "objectID": "Analysis/fixed_proto_pilot.html",
    "href": "Analysis/fixed_proto_pilot.html",
    "title": "Fixed Prototype Pilot",
    "section": "",
    "text": "Mingjiaâs Report  \n\nDisplay codepacman::p_load(dplyr,purrr,tidyr,ggplot2, here, patchwork, conflicted, knitr,grateful)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\n\nfp24 &lt;- readRDS(here(\"data\",\"fixed_proto24.rds\"))\n\n\n\ntheme_nice_b &lt;- function() {\n  theme_minimal(base_family = \"Manrope\") +\n    theme(\n      panel.grid.minor = element_blank(),\n      plot.title = element_text(family = \"Manrope Extrabold\", face = \"plain\", size = rel(1.55)),\n      plot.subtitle = element_text(family = \"Manrope Medium\", face = \"plain\", size = rel(1.2)),\n      axis.title = element_text(family = \"Manrope SemiBold\", face = \"plain\", size = rel(1)),\n      axis.title.x = element_text(hjust = .5),\n      axis.title.y = element_text(hjust = .5),\n      axis.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(0.9)),\n      strip.text = element_text(\n        family = \"Manrope\", face = \"bold\",\n        size = rel(1.2), hjust = 0\n      ),\n      legend.position = \"top\",\n      legend.text = element_text(family = \"Manrope Light\", face = \"plain\", size = rel(1.3)),\n      strip.background = element_rect(fill = \"grey90\", color = NA)\n    )\n}\n\n\n\n\ntheme_set(theme_nice_b())\n\nyt &lt;- round(seq(0,1,length.out=7), 2)\nxt &lt;- seq(1,10,1)\neg &lt;- list(geom_hline(yintercept = c(.33, .66),linetype=\"dashed\", alpha=.5),\n           scale_y_continuous(breaks=yt,limits=c(0,1)),\n           scale_x_continuous(breaks=xt))\n\n\nDisplay codefp24 |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=Pattern_Token, y=Corr, fill=condit, group=condit)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Fixed Proto.\", y=\"Accuracy\") \nfp24 |&gt; filter(Phase==2) |&gt;\n  group_by(sbjCode, condit, Pattern_Token) |&gt;\n  summarize(Corr=mean(Corr)) |&gt;\n  ggplot(aes(x=condit, y=Corr, fill=Pattern_Token, group=Pattern_Token)) +  \n  stat_summary(geom=\"bar\",fun=mean, position=position_dodge())+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se, position=position_dodge()) +\n  labs(title=\"Testing Performance - Fixed Proto.\", y=\"Accuracy\") \nfp24 |&gt; filter(Phase==1) |&gt;\n  group_by(sbjCode, condit, Pattern_Token,Block) |&gt;\n  summarize(Corr=mean(Corr),.groups=\"keep\") |&gt;\n  ggplot(aes(x=Block, y=Corr, col=condit, group=condit)) +  \n  stat_summary(geom=\"line\",fun=mean)+\n  stat_summary(geom=\"errorbar\", fun.data=mean_se,width=.1) +\n  labs(title=\"Training Performance.\", y=\"Accuracy\") +\n  #eg +  \n  theme(legend.position = \"top\") + eg",
    "crumbs": [
      "Learning Analysis",
      "Fixed Prototype Pilot"
    ]
  }
]